{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.read_csv('papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20286, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Bit-Serial Neural Networks</td>\n",
       "      <td>573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>Connectivity Versus Entropy</td>\n",
       "      <td>1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>The Hopfield Model with Multi-Level Neurons</td>\n",
       "      <td>278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>How Neural Nets Work</td>\n",
       "      <td>442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>Spatial Organization of Neural Networks: A Pro...</td>\n",
       "      <td>740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                               name  \\\n",
       "0  1987                         Bit-Serial Neural Networks   \n",
       "1  1987                        Connectivity Versus Entropy   \n",
       "2  1987        The Hopfield Model with Multi-Level Neurons   \n",
       "3  1987                               How Neural Nets Work   \n",
       "4  1987  Spatial Organization of Neural Networks: A Pro...   \n",
       "\n",
       "                                                text  \n",
       "0  573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...  \n",
       "1  1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...  \n",
       "2  278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...  \n",
       "3  442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...  \n",
       "4  740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20281</th>\n",
       "      <td>2023</td>\n",
       "      <td>Optimal testing using combined test statistics...</td>\n",
       "      <td>Optimal testing using combined test statistics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20282</th>\n",
       "      <td>2023</td>\n",
       "      <td>Regret-Optimal Model-Free Reinforcement Learni...</td>\n",
       "      <td>Regret-Optimal Model-Free Reinforcement Learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20283</th>\n",
       "      <td>2023</td>\n",
       "      <td>Convolutional State Space Models for Long-Rang...</td>\n",
       "      <td>Convolutional State Space Models for\\nLong-Ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20284</th>\n",
       "      <td>2023</td>\n",
       "      <td>CRoSS: Diffusion Model Makes Controllable, Rob...</td>\n",
       "      <td>CRoSS: Diffusion Model Makes\\nControllable, Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20285</th>\n",
       "      <td>2023</td>\n",
       "      <td>American Stories: A Large-Scale Structured Tex...</td>\n",
       "      <td>American Stories: A Large-Scale Structured Tex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year                                               name  \\\n",
       "20281  2023  Optimal testing using combined test statistics...   \n",
       "20282  2023  Regret-Optimal Model-Free Reinforcement Learni...   \n",
       "20283  2023  Convolutional State Space Models for Long-Rang...   \n",
       "20284  2023  CRoSS: Diffusion Model Makes Controllable, Rob...   \n",
       "20285  2023  American Stories: A Large-Scale Structured Tex...   \n",
       "\n",
       "                                                    text  \n",
       "20281  Optimal testing using combined test statistics...  \n",
       "20282  Regret-Optimal Model-Free Reinforcement Learni...  \n",
       "20283  Convolutional State Space Models for\\nLong-Ran...  \n",
       "20284  CRoSS: Diffusion Model Makes\\nControllable, Ro...  \n",
       "20285  American Stories: A Large-Scale Structured Tex...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papers from 1987-2019 were downloaded as plaintext directly from the NeurIPS conference website. Papers from 2020 onward were downloaded as PDFs and then converted to plaintext using PyMuPDF. This may have resulted in some formatting differences. Let's take a look at the plaintext of a few papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Stories: A Large-Scale Structured Text\n",
      "Dataset of Historical U.S. Newspapers\n",
      "Melissa Dell1,2∗, Jacob Carlson1, Tom Bryan1, Emily Silcock1, Abhishek Arora1, Zejiang Shen3,\n",
      "Luca D’Amico-Wong1, Quan Le4, Pablo Querubin2,5, Leander Heldring6\n",
      "1Harvard University; Cambridge, MA, USA.\n",
      "2National Bureau of Economic Research; Cambridge, MA, USA.\n",
      "3Massachusetts Institute of Technology; Cambridge, MA, USA.\n",
      "4Princeton University; Princeton, NJ, USA.\n",
      "5New York University; New York, NY, USA.\n",
      "6Kellogg School of Management, Northwestern University, Evanston, IL, USA.\n",
      "∗Corresponding author: melissadell@fas.harvard.edu.\n",
      "Abstract\n",
      "Existing full text datasets of U.S. public domain newspapers do not recognize the\n",
      "often complex layouts of newspaper scans, and as a result the digitized content\n",
      "scrambles texts from articles, headlines, captions, advertisements, and other lay-\n",
      "out regions. OCR quality can also be low. This study develops a novel, deep learn-\n",
      "ing pipeline for extracting full article texts from newspaper images and applies it\n",
      "to the nearly 20 million scans in Library of Congress’s public domain Chronicling\n",
      "America collection. The pipeline includes layout detection, legibility classifica-\n",
      "tion, custom OCR, and association of article texts spanning multiple bounding\n",
      "boxes. To achieve high scalability, it is built with efficient architectures designed\n",
      "for mobile phones. The resulting American Stories dataset provides high quality\n",
      "data that could be used for pre-training a large language model to achieve better\n",
      "understanding of historical English and historical world knowledge. The dataset\n",
      "could also be added to the external database of a retrieval-augmented language\n",
      "model to make historical information - ranging from interpretations of political\n",
      "events to minutiae about the lives of people’s ancestors - more widely accessible.\n",
      "Furthermore, structured article texts facilitate using transformer-based methods\n",
      "for popular social science applications like topic classification, detection of repro-\n",
      "duced content, and news story clustering. Finally, American Stories provides a\n",
      "massive silver quality dataset for innovating multimodal layout analysis models\n",
      "and other multimodal applications.\n",
      "1\n",
      "Introduction\n",
      "Historical local newspapers provide a massive repository of texts about American communities and\n",
      "their inhabitants that can elucidate topics ranging from semantic change to political polarization\n",
      "to the construction of national and cultural identities to the minutiae of the daily lives of people’s\n",
      "ancestors. Given the enormous breadth and depth of content, historical newspapers have been widely\n",
      "studied, yet existing open source U.S. newspaper datasets have significant limitations that complicate\n",
      "the extent to which modern deep learning methods can leverage and liberate their content.\n",
      "Library of Congress’s Chronicling America project [19] is the primary public domain historical U.S.\n",
      "newspaper dataset. It consists of around 20 million historical newspaper scans and their correspond-\n",
      "ing digitized texts. Its content is concentrated before 1925, as this content has entered the public\n",
      "37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Bench-\n",
      "marks.\n",
      "\fdomain. Chronicling America does not recognize oftentimes complex newspaper layouts, and so\n",
      "digitized texts are provided at the page level, often scrambling headlines, articles, advertisements,\n",
      "captions, and other content regions together. Because a non-trivial share of the underlying scans\n",
      "are illegible, incoherent texts are prevalent, with illegibility varying across space and time. This\n",
      "complicates applying natural language processing (NLP) and statistical methods, and the data are\n",
      "not of sufficient quality to use for training a large language model to achieve a better understanding\n",
      "of historical English and historical world knowledge.\n",
      "To address these limitations, we develop a pipeline for cheaply extracting high quality digitized ar-\n",
      "ticle texts and layout regions from newspaper scans. First, layout detection predicts the coordinates\n",
      "and classes of content regions - e.g. articles, headlines, bylines, advertisements, pictures, etc. - us-\n",
      "ing object detection methods [34]. Then, an image classifier removes illegible text bounding boxes.\n",
      "We next digitize the text regions using a novel optical character recognition (OCR) architecture that\n",
      "yields highly scalable, accurate results within our constrained budget. The focus on cost effective-\n",
      "ness makes the pipeline accessible to others with limited budgets who would like to digitize massive\n",
      "historical document collections. Finally, we associate headline, byline, and article bounding boxes.\n",
      "We do not process foreign language newspapers, as off-the-shelf OCR tends to perform poorly on\n",
      "the diverse languages and scripts.\n",
      "The resulting American Stories (Structured text on reporting in every state) dataset contains\n",
      "1.14B content regions. The dataset has extensive geographic coverage across all states and has\n",
      "content dating as far back as the 17th century, although the bulk of content comes from the early\n",
      "20th century. Figure 1 shows the distribution of scans across years and states. The vast majority of\n",
      "American Stories is older than the 72 year rule that the U.S. government uses to release personal\n",
      "information (e.g., from the census) into the public domain.\n",
      "(a) Scans Across Time\n",
      "(b) Scans Across Space\n",
      "Figure 1: Scans in the Chronicling America database across time and space.\n",
      "We show that the pipeline produces accurate predictions. The resulting texts could be used for\n",
      "historical language model training, or added to an external database of a retrieval augmented lan-\n",
      "guage model to facilitate the study of topics ranging from international events to family history. The\n",
      "layouts and corresponding texts could provide a massive silver quality dataset for applications like\n",
      "multimodal layout analysis and classification. The American Stories dataset also yields signifi-\n",
      "cantly better performance on social science analyses than the Chronicling America OCR and allows\n",
      "analyses that would be impossible without structured article texts. For example, we cluster article\n",
      "embeddings to detect which stories (e.g., Pancho Villa Expedition, 1916) received the most coverage\n",
      "each year.\n",
      "The rest of this study is organized as follows. Section 2 discussed related literature and Section 3\n",
      "describes the American Stories dataset. Section 4 outlines the digitization pipeline, and Section\n",
      "5 evaluates the quality of the outputs. Section 6 discusses applications and Section 7 considers\n",
      "limitations and recommended usage.\n",
      "2\n",
      "Related Literature\n",
      "Public domain newspaper datasets exist for many countries, but typically pipelines are proprietary,\n",
      "as the norm is to outsource digitization to a private company. Commercial newspaper databases\n",
      "2\n",
      "\flikewise do not disclose their pipelines, resulting in a dearth of open-source methods. The most\n",
      "closely related work to American Stories is the open-source Newspaper Navigator dataset [15].\n",
      "The main, and crucial, difference between American Stories and [15] is that [15] does not detect\n",
      "bounding boxes of articles. [15] focuses on 7 classes of visual content: headlines, photographs,\n",
      "illustrations, maps, comics, editorial cartoons, and advertisements. Distinguishing articles enables\n",
      "legibility classification, application of custom OCR, and association of articles across bounding\n",
      "boxes. These tasks are at the core of our contribution, and enable the usefulness of our contribution\n",
      "for downstream applications. In addition, the OCR in [15] is limited to Chronicling America’s OCR,\n",
      "which we show leads to a quality deterioration.\n",
      "While we focus exclusively on texts where the entire newspaper is indisputably in the public domain\n",
      "(typically because it was published more than 95 years ago), it is worth noting that our pipeline\n",
      "could help address some of the copyright issues that have limited the public availability of historical\n",
      "newspapers. Outside of the nation’s most widely circulated newspapers, it was rare for local papers\n",
      "to publish with a copyright notice or renew their copyright, required formalities until the latter half of\n",
      "the 20th century. Hence, the majority of local papers well into the 20th century are off-copyright. Yet\n",
      "these papers might sometimes print copyrighted content by third parties - e.g., frequently comics,\n",
      "rarely ads, and occasional runs of syndicated fiction [23]. Individual news articles did not have\n",
      "their copyrights renewed, as copyrighting yesterday’s news lacked commercial value. Detecting\n",
      "individual content regions - e.g., so that ads and comics could be cropped out and fictional texts\n",
      "removed with a classifier - is a prerequisite for removing content potentially under copyright. Some\n",
      "copyright experts [23] have suggested this as a way forward for making historical newspapers more\n",
      "accessible.\n",
      "3\n",
      "Dataset\n",
      "Table 1 describes American Stories, totaling 1.14 billion content region bounding boxes. Head-\n",
      "lines, images, bylines, and captions are OCR’ed if legible. The dataset contains 3,313 tokens per\n",
      "page on average, making the full dataset 65.6 billion tokens.\n",
      "(1)\n",
      "(2)\n",
      "(3)\n",
      "(4)\n",
      "(5)\n",
      "(6)\n",
      "(7)\n",
      "(8)\n",
      "(9)\n",
      "Total\n",
      "Text Bounding Boxes\n",
      "Other Bounding Boxes\n",
      "Boxes\n",
      "Articles\n",
      "Headlines\n",
      "Captions\n",
      "Bylines\n",
      "Images\n",
      "Ads\n",
      "Tables\n",
      "Mastheads\n",
      "Legible\n",
      "-\n",
      "335M\n",
      "368M\n",
      "9.7M\n",
      "14.7M\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Illegible\n",
      "-\n",
      "26M\n",
      "27M\n",
      "0.9M\n",
      "2.5M\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Borderline\n",
      "-\n",
      "77M\n",
      "22M\n",
      "1.3M\n",
      "1.2M\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Total\n",
      "1.14B\n",
      "438M\n",
      "417M\n",
      "11.9M\n",
      "18.4M\n",
      "9.1M\n",
      "221M\n",
      "16.3M\n",
      "4.9M\n",
      "Table 1: American Stories dataset statistics.\n",
      "American Stories provides the classes and coordinates for all content regions. Using the provided\n",
      "metadata, it is straightforward for users to link the coordinates with the original scans, which can be\n",
      "downloaded through the Library of Congress’s website. We do not OCR ads because they oftentimes\n",
      "have unusual fonts and complex layouts, including scene text and complex tables with pricing or\n",
      "schedule information, complicating OCR. The table class includes tabular article data, e.g. sporting\n",
      "rosters. We do not transcribe these because accurately detecting and harmonizing the diversity of\n",
      "table layouts is challenging with current technology. Newspaper headers are not OCR’ed because\n",
      "most of their information is contained in the metadata. Mastheads - which contain subscription\n",
      "information - and page numbers often used very small fonts and hence are disproportionately likely\n",
      "to be illegible; page numbers can be inferred from the metadata.\n",
      "Each text region is classified as legible, illegible, or borderline, with examples of each category\n",
      "shown in Figure 2. Borderline forms the grey zone between clearly legible and clearly illegible texts\n",
      "and is OCR’ed. Users can remove it if they would like to limit to the highest quality texts.\n",
      "Substantial shares of illegible content can degrade language model training and bias downstream\n",
      "applications. For example, it is common for social scientists to construct data based on the presence\n",
      "of keyword terms [9], assigning a positive outcome if the term is present and a zero outcome oth-\n",
      "erwise. Illegibility can bias downstream analyses if it is correlated with an underlying unobserved\n",
      "factor. Figure 3 shows that illegibility is correlated with space and time, and hence likely to be cor-\n",
      "3\n",
      "\fFigure 2: Examples of legibility classification, as predicted by our trained model.\n",
      "related with unobserved factors. Using our data, researchers can remove papers with high illegibility\n",
      "rates if desired and more realistically assess selection into the database.\n",
      "(a) Illegibility Across Time\n",
      "(b) Illegibility Across Space\n",
      "Figure 3: Illegible articles in the Chronicling America database across time and space.\n",
      "American Stories has a Creative Commons CC-BY license, to encourage widespread use. The\n",
      "data are available on the Hugging Face Hub1. The raw files are in a json format, and the Hugging\n",
      "Face repo comes with a setup script that easily allows people to download both raw and parsed data\n",
      "to facilitate language modeling and computational social science applications. The supplementary\n",
      "materials and the Readme on the dataset repository provide a detailed usage guide.\n",
      "4\n",
      "Methods\n",
      "Overview: The American Stories pipeline consists of four steps: layout/line detection, legibility\n",
      "classification, OCR, and article association. The pipeline is available on Github2.\n",
      "The pipeline’s modularity offers several advantages. Theoretically, localization (of layouts, lines,\n",
      "words, and characters) and recognition (of characters, akin to classification) may rely on different\n",
      "features of the image, suggesting modularity [31]. Practically, there are vast differences in the\n",
      "number of labels required for training each component of the pipeline. Modularity also leads to\n",
      "architectural simplicity. Swapping in different encoders is straightforward, which makes the pipeline\n",
      "more customizable and future-proof. Off-the-shelf models performing a single pipeline task - like\n",
      "Segment Anything [14] or an OCR engine - would be straightforward to swap in.\n",
      "1https://huggingface.co/datasets/dell-research-harvard/AmericanStories\n",
      "2https://github.com/dell-research-harvard/AmericanStories\n",
      "4\n",
      "\fThe American Stories pipeline uses architectures designed for mobile phones - Yolo v8 [34] and\n",
      "MobileNet v3 [10] - because the accuracy hit relative to much larger models was very modest and\n",
      "deployment costs were over an order of magnitude lower. If budget is not a concern, it would be\n",
      "straightforward to swap in a vision transformer, (e.g., [4, 1, 21]) and a two stage object detection\n",
      "framework (e.g., [2]), variations that [3] examine quantitatively on Chronicling America.\n",
      "The pipeline was run on Azure F-series CPU nodes. Training used an Nvidia A6000 GPU card.\n",
      "Details are described in the Supplementary Materials.\n",
      "Layout and Line Detection: Layout region coordinates and classes are detected using Yolo v8 [34],\n",
      "with Figure 4 showing examples. We train the layout detection model on 2,202 labeled newspaper\n",
      "images, consisting of 48,874 layout objects, with an average of 22 layout objects per page. All\n",
      "annotations for the pipeline were created by undergraduate research assistants, with scans selected\n",
      "randomly and using active learning [27]. To develop a general purpose model, we annotated scans\n",
      "of public domain and off-copyright newspapers from throughout the 19th and 20th centuries. Scans\n",
      "from Chronicling America comprise 13% of the training sample.\n",
      "Figure 4: Variety of newspaper layouts with our layout detection pipeline outputs overlayed.\n",
      "For content regions that are OCR’ed, we detect individual lines within each region using Yolo v8,\n",
      "as lines are the input to OCR. The model is trained on 4,000 synthetic and 373 annotated line crops.\n",
      "Yolo v8, like other object detection frameworks, takes square images as inputs. When the aspect\n",
      "ratios of content regions differ significantly from squares, downstream OCR performance tends to\n",
      "be adversely affected. Hence, for content regions with an aspect ratio greater than 2:1 (twice as\n",
      "tall as wide), we split the layout region (with overlap), run line detection over each separate box,\n",
      "and then run non-maximum suppression jointly over the resulting predictions. For the same reason,\n",
      "before sending lines to OCR, we split lines with an aspect ratio below 1:30 (thirty times wider than\n",
      "tall).\n",
      "Legibility Classification: We classify headline, article, byline, and caption regions as legible, il-\n",
      "legible, or borderline (see Figure 2) using an image classifier with a Mobilenet v3 backbone that is\n",
      "trained on 1,094 double-labeled content region crops.\n",
      "OCR: We aimed to deploy a highly accurate digitization pipeline within a constrained cloud com-\n",
      "pute budget of $60,000 USD. As documented in detail in the supplementary materials, existing OCR\n",
      "solutions did not meet these requirements. Commercial solutions were far too costly, and TrOCR\n",
      "Base [18] - an open-source transformer sequence-to-sequence OCR that produced accurate results\n",
      "- was nearly fifty times more costly to deploy on cloud CPUs than our budget. More scaleable\n",
      "open-source OCR engines were noisy even when fine-tuned on newspaper annotations.\n",
      "We met our accuracy and cost objectives with the EfficientOCR framework [3]. EfficientOCR uses\n",
      "deep learning-based object detection methods to localize individual characters and/or words in an\n",
      "image. Character/word recognition is modeled as a character/word-level image retrieval problem,\n",
      "using a vision encoder contrastively trained on character/word crops, largely created through aug-\n",
      "menting digital fonts. At inference time, character/word embeddings are decoded to text in parallel\n",
      "by retrieving their nearest neighbor from an offline index of exemplar character or word embeddings,\n",
      "created by rendering character/word images with a digital font. Distances are computed using cosine\n",
      "similarity with a Facebook Artificial Intelligence Similarly Search (FAISS) backend [11].\n",
      "5\n",
      "\fSwitching between character and word recognition is important. There are many terms that would\n",
      "not appear in even a very large dictionary, as narrow newspaper columns imply that hyphenated\n",
      "words at the end of lines are common.3 The texts also have a long-tailed distribution of proper\n",
      "nouns and antiquated acronyms and words. Hence, at inference time, whenever a word crop is below\n",
      "a tuned cosine similarity threshold of 0.82 from its nearest neighbor in the offline word embedding\n",
      "index, we instead apply character-level EfficientOCR to individual character crops within the word.\n",
      "The supplementary materials provide a detailed description of training and deployment.\n",
      "Content Association: We associate headlines together (if spanning multiple boxes), associate them\n",
      "with bylines (if present), and with the first article bounding box, using rule-based methods that\n",
      "exploit the position of article and byline bounding boxes relative to headlines (see the Supplementary\n",
      "Materials). Rule-based methods perform less well for articles spanning multiple columns or pages,\n",
      "and language understanding is required. However, we find on a labeled sample that only around\n",
      "3.8% of articles span multiple article bounding boxes, and only 0.2% of articles span multiple pages,\n",
      "meaning there is little scope for gains from neural methods. (Articles spanning multiple columns\n",
      "and pages become more common after the Chronicling America period, as the price of paper falls\n",
      "and font size increases.) Since these cases are rare and our compute budget is limited, we do not\n",
      "associate multiple article bounding boxes together for this release, but may do so in the future, using\n",
      "the RoBERTa cross-encoder method developed in [29].\n",
      "5\n",
      "Pipeline Evaluation\n",
      "Measurement: We use four carefully constructed datasets to evaluate the pipeline:\n",
      "• Full page scans: Two student annotators labeled layout regions and hand-entered the texts\n",
      "for 10 full page scans, resolving all discrepancies by hand. The set consists of 597 content\n",
      "regions and 196,655 characters. It allows us to evaluate the end-to-end pipeline, which\n",
      "requires transcribed full-page scans since layout analysis is applied at the page level. We\n",
      "further use this sample for evaluating content association. It contains 214 headline-article\n",
      "bounding box pairs.\n",
      "• Transcribed day per decade sample: To evaluate line detection and OCR on highly di-\n",
      "verse content, we hand-transcribe a randomly selected sample of 50 lines for each decade\n",
      "between 1850-1920. During this period, printing and archival technology changes signif-\n",
      "icantly. Examples of these textlines, with their accompanied EffOCR transcriptions, are\n",
      "shown in the supplemental materials as Table 1.\n",
      "• Transcriptions of randomly selected lines from Carlson et al. [3]: This sample is used\n",
      "to report comparisons to other object detection frameworks, backbones, and OCR engines.\n",
      "These comparisons are taken from [3], which develops EfficientOCR. This sample includes\n",
      "64 textlines drawn randomly from random scans in the Chronicling America collection.\n",
      "• Legibility sample: We evaluate legibility on a randomly selected (from legibility training\n",
      "data), double labeled sample of 100 bounding boxes, 50 headlines and 50 articles. Tran-\n",
      "scriptions are not included, as we cannot create character labels for illegible content.\n",
      "We measure pipeline accuracy with the character error rate (CER), defined as the Levenshtein dis-\n",
      "tance [16] between the end-to-end digitized content and the ground truth, divided by the length of\n",
      "the ground truth. OCR is similarly evaluated by the character error rate on ground truth layout and\n",
      "line annotations (and hence does not include transcriptions errors induced by errors in the layout\n",
      "predictions). We also examine non-word rate, as it does not require costly-to-create labeled data\n",
      "so can be evaluated on a much larger sample, though it is more difficult to interpret. To measure\n",
      "3Our word dictionary consists of words rendered three times each: with all lowercase characters, all upper-\n",
      "case characters (common in headlines), and capitalized. We select words by first taking the top 25,000 words\n",
      "from a modern dictionary that ranks word frequency [5]. We remove 3,999 words that never appear in a sample\n",
      "of all Chronicling America scans from one-day-per decade (1850s-1920s), OCR’ed with character Efficien-\n",
      "tOCR. Inspection revealed that these were overwhelmingly words related to modern concepts like computing\n",
      "and modern medicine. We then added the 500 words that most frequently appear in this sample but were not\n",
      "frequent modern words - mostly consisting of terms from antiquated domains like traditional medicine - and\n",
      "also added numbers, contractions, state and month abbreviations, and punctuation, for a total of 22,230 total\n",
      "terms.\n",
      "6\n",
      "\fthe quality of layout and line detection, we use mean average precision (mAP@50:95), as well as\n",
      "decomposing what share of the overall character error rate is due to layout and line detection errors.\n",
      "For full article association, we focus on confusability between legible and illegible scans. Finally,\n",
      "we evaluate content association using F1.\n",
      "Overall Pipeline Evaluation: The end-to-end CER is 0.051 (Table 2), showing the pipeline’s high\n",
      "overall accuracy. Some of the errors - e.g. confusing commas and periods are particularly prevalent\n",
      "- are straightforward to fix in post-processing. When we apply a lightweight spellchecker [5], the\n",
      "CER falls to 0.044. Spellchecking produces a slight increase in CER in headlines, likely due to a\n",
      "higher concentration of proper nouns.\n",
      "(1)\n",
      "(2)\n",
      "(3)\n",
      "(4)\n",
      "Overall\n",
      "Headlines\n",
      "Articles\n",
      "Ads\n",
      "Mean Average Precision\n",
      "63.48\n",
      "88.64\n",
      "91.31\n",
      "78.4\n",
      "Overall CER (Spellchecked)\n",
      ".044\n",
      ".092\n",
      ".038\n",
      "-\n",
      "Overall CER\n",
      ".051\n",
      ".089\n",
      ".049\n",
      "-\n",
      "CER from OCR\n",
      ".043\n",
      ".071\n",
      ".039\n",
      "-\n",
      "CER from layout detection\n",
      ".012\n",
      ".018\n",
      ".010\n",
      "-\n",
      "Article Association F1\n",
      "97.0\n",
      "-\n",
      "-\n",
      "-\n",
      "Table 2: Pipeline evaluation on ten labeled scans. CER is the character error rate, decomposed\n",
      "into errors from OCR and from layout detection. Article association F1 evaluates the association of\n",
      "headlines with each other and the first article bounding box. Spellchecking is applied after EffOCR,\n",
      "using [5].\n",
      "Figure 5 plots the non-word rate at the scan level on a day-per-decade sample, where non-word\n",
      "rate measures the share of terms not in a lengthy dictionary with 82,765 terms [5]. Even with a\n",
      "perfect OCR, the non-word rate could be appreciable, due to hyphenated words at the end of rows,\n",
      "acronyms, proper nouns, and antiquated terms. The American Stories distribution is concen-\n",
      "trated well to the left of Chronicling America’s distribution, underscoring the quality of our texts.\n",
      "Differences in the non-word rate between Chronicling America and American Stories are likely to\n",
      "reflect both differences in OCR quality and differences in filtering content based on legibility and\n",
      "content region type, as Chronicling America digitizes all the texts it can localize on the page.\n",
      "Figure 5: Non-Word Rate Distributions of American Stories and Chronicling America.\n",
      "Layout and Line Detection Evaluation: mAP, reported in Table 2, is high, particularly for the\n",
      "classes of central interest such as headlines (88.64) and articles (91.31). Confusing ads for articles -\n",
      "as they often look similar in this period - is relatively common. The ads that look like articles tend\n",
      "to OCR well and have natural language texts, so these errors are also tolerable. The overwhelming\n",
      "majority of content regions in the ten labeled scans are articles, headlines, and advertisements, as\n",
      "photographs - a rarity in this period - do not appear. The mAP for line detection is 86.20.\n",
      "We also decompose the overall CER into errors due to OCR and errors due to line and layout detec-\n",
      "tion. When the layout model fails to detect text regions, misclassifies them as another category such\n",
      "as ads that isn’t OCR’ed, or when line detection misses or crops lines, this increases the CER. The\n",
      "CER due to layout and line detection errors is 0.012.\n",
      "7\n",
      "\fLegibility Classification Evaluation: We want to avoid classifying legible texts as illegible and vice\n",
      "versa, with the borderline class existing to encompass the grey zone between these two categories.\n",
      "In a random sample of labeled texts - containing 81 legible texts - none of the legible texts are\n",
      "misclassified as illegible. Of 16 illegible texts, only one is misclassified as legible. To further\n",
      "evaluate this, we ran all content regions from a one-day-per-decade sample through OCR. The non-\n",
      "word rate is more than three times higher for illegibly classified content as compared to legibly\n",
      "classified content, and more than twice as high for illegibly classified content as for borderline\n",
      "content.\n",
      "OCR Evaluation: Table 2 reports the CER from running OCR on ground truth layouts and lines.\n",
      "It is 0.043. The supplementary materials provide a much more detailed analysis of OCR quality.\n",
      "Evaluation on a day per decade sample shows that CER ranges from 8.9% (1850s) to 1.8% (1910s),\n",
      "with the bulk of content concentrated in the later period where scans are less challenging. The sup-\n",
      "plementary materials also document that EffOCR [3] best meets our accuracy and cost requirements,\n",
      "by comparing to a variety of open-source and proprietary OCR engines.\n",
      "Content Association Evaluation: We achieve an F1 of 97 for associating headlines with articles on\n",
      "our labeled evaluation dataset. We associate all bylines correctly.\n",
      "6\n",
      "Applications\n",
      "Language Modeling: American Stories provides a massive amount of text that can be used to\n",
      "continue pre-training large transformer language models, helping a language model to develop a\n",
      "better understanding of 19th and early 20th century English and greater world knowledge about the\n",
      "past. Moreover, a retrieval augmented language model (e.g. [12]), combined with longer context\n",
      "windows, could provide a valuable tool for retrieving and summarizing vast information, whether it\n",
      "be perspectives on paradigm-shifting historical events or the minutiae of the daily lives of people’s\n",
      "ancestors. American Stories also provides extensive content for studying semantic change.\n",
      "Multimodal Classification: The layouts and texts in American Stories comprise a rich multi-\n",
      "modal dataset, providing vast silver quality data that could be used for developing novel methods\n",
      "for multimodal layout analysis or multimodal classification - e.g., with image-caption pairs.\n",
      "Topic Classification: Topic classification of texts in historical newspapers is a common social sci-\n",
      "ence application, with the literature overwhelmingly using keyword searches to measure topics\n",
      "[9]. To evaluate how American Stories can facilitate topic classification, relative to the exist-\n",
      "ing Chronicling America page-level OCR, we use neural and sparse methods to classify whether a\n",
      "randomly selected set of content is about politics, a frequently covered topic. We use a RoBERTa\n",
      "large [20] classifier, applied to articles in American Stories and chunks of Chronicling America\n",
      "(the page OCR is significantly longer than the context window). The training data were randomly\n",
      "sampled at the article level and contain 2418 articles. The development set contains 15 randomly\n",
      "selected full scans (498 articles) and the test set contains 62 randomly selected scans (1473 articles).\n",
      "We also consider keywords, using two different approaches for selecting these: keyword mining\n",
      "on the training set and asking ChatGPT, with careful prompting. All methods are described in the\n",
      "supplementary materials.\n",
      "American Stories supports article level classification, whereas Chronicling America only sup-\n",
      "ports page level classification. A page is a positive example in the ground truth if any of the articles\n",
      "are on topic, and article or chunk predictions can be aggregated to page level predictions using the\n",
      "same definition. Retrieval at the scan level tends to retrieve a lot of extraneous content, as typically\n",
      "only part of the page contains articles about politics.\n",
      "On structured article texts, neural methods outperform keyword methods by a wide margin (F1 of\n",
      "83.6 versus 58.1). All methods perform better at the page level, as there is a much lower chance of\n",
      "false negatives, with the best performance by a wide margin coming from applying neural methods\n",
      "to the American Stories corpus.\n",
      "Content Dissemination Networks: Reproduced content is of considerable interest to social scien-\n",
      "tists [7], but detecting it can be challenging due to OCR noise and abridgement. We evaluate this\n",
      "task on a full-day sample of labeled front pages from March 1, 1916, a random day that consists of\n",
      "113 reproduced articles (the median article is reproduced twice) as well as 1,994 singleton articles.\n",
      "8\n",
      "\fTopic classification\n",
      "Reproduced content\n",
      "Neural\n",
      "Sparse\n",
      "Neural\n",
      "Sparse\n",
      "F1\n",
      "Mining\n",
      "GPT\n",
      "ARI\n",
      "Viral Texts\n",
      "(1)\n",
      "(2)\n",
      "(3)\n",
      "(4)\n",
      "(5)\n",
      "Article Level\n",
      "American Stories\n",
      "83.6\n",
      "56.4\n",
      "58.1\n",
      "75.1\n",
      "32.3\n",
      "Page Level\n",
      "American Stories\n",
      "96.0\n",
      "82.8\n",
      "79.6\n",
      "86.2\n",
      "74.6\n",
      "Chronicling America\n",
      "83.3\n",
      "83.7\n",
      "79.6\n",
      "-\n",
      "71.4\n",
      "Table 3: Comparing American Stories to Library of Congress’s Chronicling America.\n",
      "To detect reproduced content at the article level with American Stories, we deploy the pre-trained\n",
      "neural model from [28]. They contrastively tuned a Sentence BERT model [26, 32] on a large,\n",
      "hand-annotated sample of paired reproduced articles from a later period. At inference time, article\n",
      "representations are clustered using single linkage clustering to detect reproduced content. To make\n",
      "the American Stories result comparable with Chronicling America, we amalgamate the predic-\n",
      "tions to the page level. A page-pair is counted as positive if the pages have any article in common,\n",
      "making the task easier.\n",
      "For detecting reproduced content with the Chronicling America full page scans, where we lack the\n",
      "article texts required for the neural method, we deploy the sparse methods from Viral Texts [30].\n",
      "Viral Texts was designed specifically for detecting reproduced texts in Chronicling America’s noisy\n",
      "page-level OCR by looking for overlapping n-gram spans. We also apply Viral texts to American\n",
      "Stories at the article and page level. Table 3 reports the adjusted rand index (ARI) for these\n",
      "specifications. The Viral Texts method gives slightly better results on American Stories, but the\n",
      "real advantage of American Stories is that the article structure allows the use of a neural method,\n",
      "which dominates the sparse method by nearly 12 percentage points at the page level.\n",
      "News Story Clustering: The structured nature of American Stories allows for further article-\n",
      "level clustering of content. As a demonstration of this, we show how articles can be grouped into\n",
      "news stories, with different articles that are part of the same unfolding news story clustering together.\n",
      "This prediction is not possible with the unstructured page content in Chronicling America.\n",
      "Year\n",
      "Biggest story\n",
      "Year\n",
      "Biggest story\n",
      "1885\n",
      "Death of General Grant\n",
      "1903\n",
      "Panama Canal Treaty\n",
      "1886\n",
      "Southwest Railroad Strike\n",
      "1904\n",
      "Russo-Japanese War\n",
      "1887\n",
      "Vatican supports Knights of Labor\n",
      "1905\n",
      "Russo-Japanese Peace Process\n",
      "1888\n",
      "Rail strikes\n",
      "1906\n",
      "Hepburn Railroad Rate Bill\n",
      "1889\n",
      "Samoan Crisis\n",
      "1907\n",
      "Mining accidents\n",
      "1890\n",
      "1893 World’s Fair planning\n",
      "1908\n",
      "Taft presidential victory\n",
      "1891\n",
      "New Orleans Lynchings\n",
      "1909\n",
      "Race to the North Pole\n",
      "1892\n",
      "Homestead Steel Strike\n",
      "1910\n",
      "Rail strikes\n",
      "1893\n",
      "World’s Fair, Chicago\n",
      "1911\n",
      "Canadian Reciprocity Bill\n",
      "1894\n",
      "Wilson–Gorman Tariff Act\n",
      "1912\n",
      "Republican National Convention (Taft v Roosevelt)\n",
      "1895\n",
      "British occupation of Corinto, Nicaragua\n",
      "1913\n",
      "Underwood-Simmons Tariff Act\n",
      "1896\n",
      "Bimetallism Movement\n",
      "1914\n",
      "World War I\n",
      "1897\n",
      "Coal Miners’ Strike\n",
      "1915\n",
      "World War I\n",
      "1898\n",
      "Cuban War of Independence\n",
      "1916\n",
      "Pancho Villa Expedition\n",
      "1899\n",
      "Philippine-American War\n",
      "1917\n",
      "World War I\n",
      "1900\n",
      "Anglo-Boer War\n",
      "1918\n",
      "World War I\n",
      "1901\n",
      "U.S. Steel Recognition Strike\n",
      "1919\n",
      "Treaty of Versailles\n",
      "1902\n",
      "Anthracite Coal Strike\n",
      "1920\n",
      "Rail strikes\n",
      "Table 4: Largest news story in each year, 1885-1920.\n",
      "To create these clusters, we fine tune a contrastive biencoder on modern news texts, scraped from\n",
      "allsides.com, a website which amalgamates different representations of the same news story from\n",
      "different news outlets. Full details of the data, model and training are given in the supplementary\n",
      "materials. We ran this model over all de-duplicated front page articles from 1885-1920. We read\n",
      "20 random articles in the largest cluster for each year and named the story which the articles in the\n",
      "cluster refer to. Table 4 shows the largest news story cluster by year.\n",
      "9\n",
      "\fThis application demonstrates one of the many ways that the structured article texts in American\n",
      "Stories can be used to unlock new ways of studying historical and social questions.\n",
      "In addition to these tasks, image-caption pairs from layout analysis could be used for training and\n",
      "assessing image captioning models, visual question-answering models, cross-modal retrieval mod-\n",
      "els, image retrieval models, and multi-modal understanding (e.g., representation learning) models.\n",
      "American Stories could also be leveraged to substantially lower the costs of creating new bench-\n",
      "mark datasets for other common ML tasks, e.g., image and text classification, image retrieval, and\n",
      "named entity recognition.\n",
      "7\n",
      "Limitations and Recommended Usage\n",
      "American Stories contains historical language, that reflects the semantics and cultural biases of\n",
      "the time. This is a distinguishing feature, that is core to many potential applications. We do not\n",
      "filter texts that use antiquated terms or that may be considered offensive, as this would invalidate\n",
      "the use of the dataset for studying semantic change and historical contexts. At the same time,\n",
      "this makes American Stories less suited for tasks that require texts that fully conform to current\n",
      "cultural standards or semantic norms. For these reasons, we recommend against the use of American\n",
      "Stories for training generative models. While the OCR is high quality, American Stories is\n",
      "also not well-suited to tasks requiring fully clean texts. Rather, American Stories can be used\n",
      "for a wide variety of applications, ranging from elucidating social science questions to training\n",
      "a historically-oriented language model to exploring world and family history. It also provides a\n",
      "modular pipeline that can be customized for other document collections and scaled cheaply, offering\n",
      "a blueprint for liberating large-scale historical text corpora.\n",
      "10\n",
      "\fAcknowledgement\n",
      "Funding was provided by the Harvard Data Science Initiative, Harvard Catalyst, the Ken Griffin\n",
      "Harvard Economics Fund, and Microsoft Azure compute credits. We thank Anoushka Ashwin,\n",
      "Domenick Clark Regina, Chloe Combes, Will Cox, Connor Fogal, Brevin Franklin, Prabhav Kamo-\n",
      "jjhala, Zachary Lee, Roberto Lopez-Irrisarry, Elan Pelegri, Krishna Prasad Srinivasan, and Sarah\n",
      "Strohecker for research assistance.\n",
      "References\n",
      "[1] ALI, A., TOUVRON, H., CARON, M., BOJANOWSKI, P., DOUZE, M., JOULIN, A., LAPTEV,\n",
      "I., NEVEROVA, N., SYNNAEVE, G., VERBEEK, J., ET AL. Xcit: Cross-covariance image\n",
      "transformers. Advances in neural information processing systems 34 (2021).\n",
      "[2] CAI, Z., AND VASCONCELOS, N. Cascade r-cnn: Delving into high quality object detection.\n",
      "Proceedings of the IEEE conference on computer vision and pattern recognition (2018), 6154–\n",
      "6162.\n",
      "[3] CARLSON, J., BRYAN, T., AND DELL, M. Efficient ocr for building a diverse digital history.\n",
      "arXiv preprint arXiv:2304.02737 (2023).\n",
      "[4] DOSOVITSKIY, A., BEYER, L., KOLESNIKOV, A., WEISSENBORN, D., ZHAI, X., UN-\n",
      "TERTHINER, T., DEHGHANI, M., MINDERER, M., HEIGOLD, G., GELLY, S., ET AL. An\n",
      "image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint\n",
      "arXiv:2010.11929 (2020).\n",
      "[5] GARBE, W. SymSpell, June 2012.\n",
      "[6] GEBRU, T., MORGENSTERN, J., VECCHIONE, B., VAUGHAN, J. W., WALLACH, H., AU2,\n",
      "H. D. I., AND CRAWFORD, K. Datasheets for datasets, 2021.\n",
      "[7] GUARNERI, J. Newsprint Metropolis. University of Chicago Press, 2017.\n",
      "[8] HADSELL, R., CHOPRA, S., AND LECUN, Y. Dimensionality reduction by learning an in-\n",
      "variant mapping. In 2006 IEEE Computer Society Conference on Computer Vision and Pattern\n",
      "Recognition (CVPR’06) (2006), vol. 2, IEEE, pp. 1735–1742.\n",
      "[9] HANLON, W. W., AND BEACH, B. Historical newspaper data: A researcher’s guide and\n",
      "toolkit, 2022.\n",
      "[10] HOWARD, A., SANDLER, M., CHU, G., CHEN, L.-C., CHEN, B., TAN, M., WANG, W.,\n",
      "ZHU, Y., PANG, R., VASUDEVAN, V., ET AL. Searching for mobilenetv3. Proceedings of the\n",
      "IEEE/CVF international conference on computer vision (2019), 1314–1324.\n",
      "[11] JOHNSON, J., DOUZE, M., AND JÉGOU, H. Billion-scale similarity search with gpus. IEEE\n",
      "Transactions on Big Data 7, 3 (2019), 535–547.\n",
      "[12] KHATTAB, O., SANTHANAM, K., LI, X. L., HALL, D., LIANG, P., POTTS, C., AND\n",
      "ZAHARIA, M. Demonstrate-search-predict: Composing retrieval and language models for\n",
      "knowledge-intensive nlp. arXiv preprint arXiv:2212.14024 (2022).\n",
      "[13] KHOSLA, P., TETERWAK, P., WANG, C., SARNA, A., TIAN, Y., ISOLA, P., MASCHINOT,\n",
      "A., LIU, C.,\n",
      "AND KRISHNAN, D.\n",
      "Supervised contrastive learning.\n",
      "arXiv preprint\n",
      "arXiv:2004.11362 (2020).\n",
      "[14] KIRILLOV, A., MINTUN, E., RAVI, N., MAO, H., ROLLAND, C., GUSTAFSON, L., XIAO,\n",
      "T., WHITEHEAD, S., BERG, A. C., LO, W.-Y., ET AL. Segment anything. arXiv preprint\n",
      "arXiv:2304.02643 (2023).\n",
      "[15] LEE, B. C. G., MEARS, J., JAKEWAY, E., FERRITER, M., ADAMS, C., YARASAVAGE, N.,\n",
      "THOMAS, D., ZWAARD, K., AND WELD, D. S. The newspaper navigator dataset: extracting\n",
      "headlines and visual content from 16 million historic newspaper pages in chronicling amer-\n",
      "ica. In Proceedings of the 29th ACM International Conference on Information & Knowledge\n",
      "Management (2020), pp. 3055–3062.\n",
      "[16] LEVENSHTEIN, V. I., ET AL. Binary codes capable of correcting deletions, insertions, and\n",
      "reversals. In Soviet physics doklady (1966), vol. 10, Soviet Union, pp. 707–710.\n",
      "11\n",
      "\f[17] LI, L., JAMIESON, K., DESALVO, G., ROSTAMIZADEH, A., AND TALWALKAR, A. Hyper-\n",
      "band: A novel bandit-based approach to hyperparameter optimization, 2018.\n",
      "[18] LI, M., LV, T., CUI, L., LU, Y., FLORENCIO, D., ZHANG, C., LI, Z., AND WEI, F.\n",
      "Trocr: Transformer-based optical character recognition with pre-trained models. arXiv preprint\n",
      "arXiv:2109.10282 (2021).\n",
      "[19] LIBRARY OF CONGRESS. Chronicling America: Historic American Newspapers, 2022.\n",
      "[20] LIU, Y., OTT, M., GOYAL, N., DU, J., JOSHI, M., CHEN, D., LEVY, O., LEWIS, M.,\n",
      "ZETTLEMOYER, L., AND STOYANOV, V.\n",
      "Roberta: A robustly optimized bert pretraining\n",
      "approach. arXiv preprint arXiv:1907.11692 (2019).\n",
      "[21] LIU, Z., LIN, Y., CAO, Y., HU, H., WEI, Y., ZHANG, Z., LIN, S., AND GUO, B.\n",
      "Swin transformer: Hierarchical vision transformer using shifted windows.\n",
      "arXiv preprint\n",
      "arXiv:2103.14030 (2021).\n",
      "[22] MUSGRAVE, K., BELONGIE, S., AND LIM, S.-N. Pytorch metric learning, 2020.\n",
      "[23] OCKERBLOOM, J. M. Newspaper copyrights, notices, and renewals, 2019.\n",
      "[24] OORD, A. V. D., LI, Y., AND VINYALS, O. Representation learning with contrastive predic-\n",
      "tive coding. arXiv preprint arXiv:1807.03748 (2018).\n",
      "[25] PASZKE, A., GROSS, S., MASSA, F., LERER, A., BRADBURY, J., CHANAN, G., KILLEEN,\n",
      "T., LIN, Z., GIMELSHEIN, N., ANTIGA, L., DESMAISON, A., KOPF, A., YANG, E., DE-\n",
      "VITO, Z., RAISON, M., TEJANI, A., CHILAMKURTHY, S., STEINER, B., FANG, L., BAI,\n",
      "J., AND CHINTALA, S. PyTorch: An Imperative Style, High-Performance Deep Learning\n",
      "Library.\n",
      "In Advances in Neural Information Processing Systems 32 (2019), H. Wallach,\n",
      "H. Larochelle, A. Beygelzimer, F. d’Alché Buc, E. Fox, and R. Garnett, Eds., Curran As-\n",
      "sociates, Inc., pp. 8024–8035.\n",
      "[26] REIMERS, N., AND GUREVYCH, I. Sentence-bert: Sentence embeddings using siamese bert-\n",
      "networks. arXiv preprint arXiv:1908.10084 (2019).\n",
      "[27] SHEN, Z., ZHAO, J., DELL, M., YU, Y., AND LI, W. Olala: Object-level active learning for\n",
      "efficient document layout annotation. arXiv preprint arXiv:2010.01762 (2020).\n",
      "[28] SILCOCK, E., D’AMICO-WONG, L., YANG, J., AND DELL, M. Noise-robust de-duplication\n",
      "at scale. International Conference on Learning Representations (2023).\n",
      "[29] SILCOCK, E., AND DELL, M. A massive scale semantic similarity dataset of historical english,\n",
      "2023.\n",
      "[30] SMITH, D. A., CORDELL, R., AND MULLEN, A. Computational methods for uncovering\n",
      "reprinted texts in antebellum newspapers. American Literary History 27, 3 (2015), E1–E15.\n",
      "[31] SONG, G., LIU, Y., AND WANG, X. Revisiting the sibling head in object detector. Pro-\n",
      "ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2020),\n",
      "11563–11572.\n",
      "[32] SONG, K., TAN, X., QIN, T., LU, J., AND LIU, T.-Y. Mpnet: Masked and permuted pre-\n",
      "training for language understanding. Advances in Neural Information Processing Systems 33\n",
      "(2020), 16857–16867.\n",
      "[33] TRAAG, V. A., WALTMAN, L., AND VAN ECK, N. J. From Louvain to Leiden: guaranteeing\n",
      "well-connected communities. Scientific Reports 9, 1 (Mar. 2019), 5233. Number: 1 Publisher:\n",
      "Nature Publishing Group.\n",
      "[34] ULTALYTICS.\n",
      "Yolo v8 github repository.\n",
      "https://github.com/ultralytics/\n",
      "ultralytics, 2023.\n",
      "[35] WIGHTMAN,\n",
      "R.\n",
      "Pytorch\n",
      "image\n",
      "models.\n",
      "https://github.com/rwightman/\n",
      "pytorch-image-models, 2019.\n",
      "12\n",
      "\fSupplementary Materials\n",
      "Model Details\n",
      "American Stories deploys a modular pipeline to digitize historical newspapers. This section\n",
      "provides details for each component of the pipeline.\n",
      "Layout Detection\n",
      "To detect articles, headlines, ads, and other content regions in a newspaper scan, we deploy YOLOv8\n",
      "(Medium) [34], initialized from the officially released YOLOv8m pretrained checkpoint. We train\n",
      "for 100 epochs on 2,202 labeled newspaper scans with 48,874 total layout objects, using default\n",
      "YOLOv8 hyperparameters except: {imgsz:\n",
      "1280, iou:\n",
      "0.2, max_det:\n",
      "500}. The final\n",
      "model achieved a 0.91 mAP50:95 on article bounding boxes and a 0.84 mAP50:95 on headline\n",
      "bounding boxes. We decreased the confidence threshold to 0.1 to increase article and headline\n",
      "recall.\n",
      "Legibility Classification\n",
      "Text image bounding boxes are classified as legible, borderline, or illegible, using MobileNetV3\n",
      "(Small) [10] initialized from the PyTorch Image Models (\"timm\") [35] pretrained checkpoint. We\n",
      "train for 50 epochs on 979 labeled article, headline, and image caption examples. 678 of the labeled\n",
      "examples were legible, 192 borderline, and 109 illegible. The model was trained with weighted\n",
      "Cross Entropy Loss: weights [2.0, 1.0, 1.0] for legible, borderline, and illegible classes, respectively.\n",
      "The following specifications were used: {resolution:\n",
      "256, learning rate:\n",
      "2e-3}. The\n",
      "learning rate was multiplied by 0.1 every twenty epochs.\n",
      "Text Line Detection\n",
      "Line bounding boxes are detected using YOLOv8 (Small) [34] initialized from the official YOLOv8s\n",
      "pretrained checkpoint. We train first for 100 epochs on 4000 synthetically generated articles, with\n",
      "default YOLOv8 hyperparameters. After synthetic training, the model was additionally trained\n",
      "for 50 epochs on 373 hand-annotated article and headline crops, with default YOLOv8 hyperpa-\n",
      "rameters except for the following: {resolution:\n",
      "640, initial learning rate:\n",
      "0.02,\n",
      "final learning rate:\n",
      "0.002}.\n",
      "Word and Character Localization\n",
      "Words and characters are detected using YOLOv8 (Small) [34], initialized from the official\n",
      "YOLOv8s pretrained checkpoint. We train first for 100 epochs on 8000 synthetically generated\n",
      "textlines with default YOLOv8 hyperparameters. After synthetic training, the model was addi-\n",
      "tionally trained for 100 epochs on 684 hand-annotated text line images, with default hyperpa-\n",
      "rameters except for the following: {resolution:\n",
      "640, initial learning rate:\n",
      "0.02,\n",
      "final learning rate:\n",
      "0.001}. Each hand-annotated line image was replicated three times\n",
      "with random augmentations along three axes: random rotation between -1°and 1°, random image\n",
      "brightness shift from -30 to 30%, and randomly applied blur at the 0-4px level. On average, text line\n",
      "examples contained 4.3 words and 23.6 characters.\n",
      "Word Recognition\n",
      "Building upon the architecture in [3], we train word recognition as a nearest neighbor image retrieval\n",
      "problem. As described in the main text, the training dataset for the model consists of digital renders\n",
      "of words created using 43 fonts, silver quality data from the target dataset created by applying the\n",
      "EffOCR-C (Small) model from [3] to a random sample of days, and a small number of randomly\n",
      "selected hand labeled word crops. We limited the number of crops with model-generated labels to\n",
      "20 - so each word can have 0-20 silver-quality crops depending upon its frequency of occurrence in\n",
      "our random sample. This limit is binding for common words, e.g., \"the\".\n",
      "13\n",
      "\fThe recognizer is trained using the Supervised Contrastive (“SupCon\") loss function [13], a gener-\n",
      "alization of the InfoNCE loss [24] that allows for multiple positive and negative pairs for a given\n",
      "anchor. In particular, we work with the “outside\" SupCon loss formulation\n",
      "Lsup\n",
      "out =\n",
      "X\n",
      "i∈I\n",
      "Lsup\n",
      "out ,i =\n",
      "X\n",
      "i∈I\n",
      "−1\n",
      "|P(i)|\n",
      "X\n",
      "p∈P (i)\n",
      "log\n",
      "exp (zi · zp/τ)\n",
      "P\n",
      "a∈A(i) exp (zi · za/τ)\n",
      "as implemented in PyTorch Metric Learning [22], where τ is a temperature parameter, i indexes a\n",
      "sample in a “multiviewed\" batch (in this case multiple fonts/augmentations of the same word), P(i)\n",
      "is the set of indices of all positives in the multiviewed batch that are distinct from i, A(i) is the set\n",
      "of all indices excluding i, and z is an embedding of a sample in the batch [13].\n",
      "To create training batches for the recognizer, we use a custom m per class sampling algorithm\n",
      "without replacement, adapted from the PyTorch Metric Learning repository [22]. The m word\n",
      "variants for each class (word) are drawn from both target documents and augmented digital fonts.\n",
      "We select m = 4 and the batch size is 1024, meaning 4 styles of each of 256 different words appear\n",
      "in each batch. For training without hard negatives, we define an epoch as letting the model see each\n",
      "word (case-sensitive) exactly m = 4 times. Sampling for each class occurs without replacement\n",
      "until all variants are exhausted.\n",
      "In order to converge faster with limited compute, we also implement offline-hard negative mining,\n",
      "batching similar negatives and their corresponding positive anchors together - thus making the con-\n",
      "trasts between the positive and negative pairs within a batch especially informative. To create hard\n",
      "negative sets, we render each word using a reference font (Noto-Serif Regular) and embed it to\n",
      "create a reference index. We find k = 8 nearest neighbors for each word using this index and the\n",
      "model trained without hard negatives, which yields sets of 8 words that have a similar appearance\n",
      "when rendered with the reference font. We use only the reference font to create these sets because\n",
      "using crops corresponding to all 43 fonts for each word is computationally costly and creates more\n",
      "hard negative sets than we can use in training. We also use each word crop from the target dataset\n",
      "(both silver quality annotations generated with model predictions and gold quality human-annotated\n",
      "predictions) to create hard negative sets. Hence, the total number of hard-negative sets equals the\n",
      "number of words in our dictionary (generated with the reference font) plus the number of word crops\n",
      "from the newspaper data in the training set.\n",
      "Each hard negative set contains 8 words, with m = 4 views per word, which means we can fit 32\n",
      "randomly sampled hard negative sets within each batch. An epoch is defined as seeing each hard\n",
      "negative set once. Since the number of synthetic views of an image is much larger than the number\n",
      "of target newspaper crops, whenever newspaper crops are available we force the m views of a word\n",
      "to contain an equal number of synthetic and target crops.\n",
      "We use a MobileNetV3 (Small) encoder pre-trained on ImageNet1k sourced from the timm [35]\n",
      "library, more specifically, the model mobilenetv3_small_050. We use 0.1 as the temperature for\n",
      "SupCon loss and AdamW as the optimizer with Pytorch [25] defaults for all parameters other than\n",
      "weight decay (5e-4) and learning rate. We used Cosine Annealing with Warm Restarts as the learn-\n",
      "ing rate scheduler with a maximum learning rate of 2e −3, a minimum learning rate of 0, time\n",
      "to first restart (T0) as the number of batches in an epoch, and restart factor, Tmult of 2 using the\n",
      "implementation provided in Pytorch.\n",
      "While fonts and newspaper crops for each word act as an augmentation on the skeleton of the word,\n",
      "we also add more image-level transformations to improve generalization. These include Affine\n",
      "transformation (only slight translation and scaling allowed), Random Color Jitter, Random Auto-\n",
      "contrast, Random Gaussian Blurring, Random Grayscale, Random Solarize, Random Sharpness,\n",
      "Random Invert, Random Equalize, Random Posterize and Randomly erasing a small number of pix-\n",
      "els of the image. Additionally, we pad the word to make the image square while preserving the\n",
      "aspect ratio of the word render. We do not use common augmentations like Random Cropping or\n",
      "Center Cropping, to avoid destroying too much information.\n",
      "The model trained without hard negatives was trained for 50 epochs and with hard negatives, it was\n",
      "trained for 40 epochs. For selecting the best checkpoint, we use 1-CER (OCR Character Error Rate)\n",
      "as the validation metric on the validation set from [3]. We chose the model that performed best in\n",
      "terms of CER when detecting only words on the validation set. This means that if a word is outside\n",
      "14\n",
      "\fof our dictionary, it is forcefully matched to the nearest neighbor in the dictionary. The best model\n",
      "achieved a CER of 4.9% with word-only recognition.\n",
      "At inference time, words are recognized by retrieving their nearest neighbor from the offline em-\n",
      "bedding index created with the reference font, using a Facebook Artificial Intelligence Similarity\n",
      "Search backend [11]. The code to train the model and generate training data, as well as the model\n",
      "checkpoints, are made available on our GitHub repo.4\n",
      "Character Recognition\n",
      "When the nearest neighbor to an embedded word crop in the offline word embedding index is below\n",
      "a cosine similarity threshold of 0.82, we default to character-level recognition. We use the EffOCR-\n",
      "C (Small) model that is developed in [3] for character recognition.\n",
      "Content Association\n",
      "This step associates headlines, bylines, and article bounding boxes. We use rule-based methods\n",
      "that exploit the position of article and byline bounding boxes relative to headlines. Specifically, we\n",
      "associated a headline bounding box with an article bounding box if they overlap vertically by more\n",
      "than 1% of the page width, and the bottom of the headline is no greater than 10% of the page height\n",
      "above the top of the article, and no greater than 2% of the page height below the top of the article.\n",
      "If multiple article bounding boxes satisfy these rules for a given headline, then we take the highest.\n",
      "The same rules are used to associate bylines.\n",
      "Pipeline Evaluation\n",
      "As discussed in the main paper, we evaluate the data processing pipeline in an end-to-end fashion,\n",
      "as well as evaluating individual sections, particularly OCR. Here we provide additional details on\n",
      "those evaluations.\n",
      "OCR Evaluation\n",
      "Processing 20 million scans required a cost-effective OCR solution, and downstream tasks require\n",
      "highly accurate OCR. We compared custom, open-source, and commercial OCR solutions by accu-\n",
      "racy, speed, and cost to determine our final architecture. Character Error Rate measurements were\n",
      "made on two separate validation datasets:\n",
      "• CER [3] Error rate on a dataset of 64 randomly selected Chronicling America textlines,\n",
      "sampled from the entire collection. Textlines were randomly sampled from random scans,\n",
      "then cropped and transcribed. This dataset and its construction is described in detail in [3].\n",
      "• CER Day-Per-Decade Error rate on a sample of 225 total textlines, sampled from all scans\n",
      "in the Chronicling America collection published on March 1st of years ending in \"6,\" from\n",
      "1856-1926. Unlike the above sample from [3], this sample is balanced across the time pe-\n",
      "riods the predominate the Chronicling America collection. 25 textlines were sampled ran-\n",
      "domly from random pages published on each of the days. A selection of textlines from this\n",
      "collection, along with their EffOCR transcriptions, are shown in Figure S-1. This dataset is\n",
      "designed to be much more challenging than the first, weighting older, harder to read scans\n",
      "more heavily despite their relative scarcity in the Chronicling America collection.\n",
      "Comparisons are listed in Table S-1. Training procedures for EffOCR-Word are described above.\n",
      "See [3] for training procedures, initialization checkpoints, and additional details on training and\n",
      "evaluating comparison models.\n",
      "Of the options we examined, EffOCR-Word (Small) was the clear best option, providing a Character\n",
      "Error Rate under 5% on the hardest evaluation set while offering the cheapest rate per line on an\n",
      "Microsoft Azure Fs4v2 instance.\n",
      "4https://github.com/dell-research-harvard/AmericanStories.\n",
      "15\n",
      "\fModel/Engine\n",
      "Seq2Seq?\n",
      "Transformer?\n",
      "Pretraining\n",
      "Parameters\n",
      "CER [3]\n",
      "CER Day-Per-Decade\n",
      "Lines Per Second\n",
      "Cost Per 10K Lines\n",
      "EffOCR-C (Base)\n",
      "×\n",
      "×\n",
      "from scratch\n",
      "112.5 M\n",
      "0.023\n",
      "0.062\n",
      "0.27\n",
      "$1.77\n",
      "EffOCR-C (Small)\n",
      "×\n",
      "×\n",
      "from scratch\n",
      "9.3 M\n",
      "0.028\n",
      "0.080\n",
      "7.28\n",
      "$0.06\n",
      "EffOCR-T (Base)\n",
      "×\n",
      "✓\n",
      "from scratch\n",
      "101.8 M\n",
      "0.022\n",
      "0.059\n",
      "0.17\n",
      "$2.80\n",
      "EffOCR-Word (Small)\n",
      "×\n",
      "×\n",
      "from scratch\n",
      "10.6 M\n",
      "0.015\n",
      "0.043\n",
      "11.60\n",
      "$0.04\n",
      "Google Cloud Vision OCR\n",
      "?\n",
      "?\n",
      "off-the-shelf\n",
      "?\n",
      "0.005\n",
      "0.019\n",
      "?\n",
      "$15.00\n",
      "Tesseract OCR (Best)\n",
      "✓\n",
      "×\n",
      "off-the-shelf\n",
      "1.4 M\n",
      "0.106\n",
      "0.170\n",
      "2.43\n",
      "$0.19\n",
      "EasyOCR CRNN\n",
      "✓\n",
      "×\n",
      "off-the-shelf\n",
      "3.8 M\n",
      "0.170\n",
      "0.274\n",
      "10.75\n",
      "$0.04\n",
      "fine-tuned\n",
      "0.036\n",
      "0.157\n",
      "from scratch\n",
      "0.131\n",
      "-\n",
      "PaddleOCR SVTR\n",
      "×\n",
      "×\n",
      "off-the-shelf\n",
      "11 M\n",
      "0.304\n",
      "7.36\n",
      "$0.06\n",
      "fine-tuned\n",
      "0.103\n",
      "from scratch\n",
      "0.104\n",
      "TrOCR (Base)\n",
      "✓\n",
      "✓\n",
      "off-the-shelf\n",
      "334 M\n",
      "0.015\n",
      "0.038\n",
      "0.23\n",
      "$2.02\n",
      "fine-tuned\n",
      "0.013\n",
      "0.027\n",
      "from scratch\n",
      "0.809\n",
      "-\n",
      "TrOCR (Small)\n",
      "✓\n",
      "✓\n",
      "off-the-shelf\n",
      "62 M\n",
      "0.039\n",
      "0.121\n",
      "0.53\n",
      "$0.90\n",
      "fine-tuned\n",
      "0.075\n",
      "0.091\n",
      "from scratch\n",
      "0.773\n",
      "-\n",
      "Table S-1: Chronicling America Results and Comparisons. This table reports the performance\n",
      "of different OCR architectures, off-the-shelf (without fine-tuning on target data), fine-tuned on the\n",
      "Chronicling America training set from initialization on the best public, pre-trained OCR checkpoint,\n",
      "and pre-trained from scratch on a consistent, standardized set of synthetic text lines and then fine-\n",
      "tuned on the Chronicling America training set. “?” indicates that the field is unknown due to the\n",
      "proprietary nature of the architecture. Inference speeds are based on an extrapolation from inference\n",
      "speeds measured for EffOCR-Word (Small) to digitize the entire Chronicling America collection\n",
      "using cloud compute.\n",
      "Figure S-1: Examples of textlines in the Day-Per-Decade evaluation set. Image crops are shown\n",
      "on the left, with their corresponding EffOCR transcriptions (using the final model set used in the\n",
      "American Stories processing pipeline) on the right.\n",
      "Legibility\n",
      "Legibility classification was tested on a set of 100 image crops (50 articles and 50 headlines) sampled\n",
      "randomly from the 1,094-image legibility training set. All legibility images were double-entered.\n",
      "Since the goal was to be cautious in classifying images as illegible, where annotators disagreed the\n",
      "more legible of the two labels was used.\n",
      "Annotators were instructed to use the following definitions for legibility labeling:\n",
      "16\n",
      "\f• Legible: Greater than 95% of words in an image readable without context from adjacent\n",
      "words.\n",
      "• Borderline: Between 50 and 95% of words in an image readable without context from\n",
      "adjacent words.\n",
      "• Illegible: Less than 50% of words in an image readable without context from adjacent\n",
      "words.\n",
      "Inter-annotator agreement was 91% between the two annotators. A sample of annotator discrepan-\n",
      "cies is presented in Figure S-2\n",
      "(a) Legible/Borderline\n",
      "(b) Borderline/Illegible\n",
      "(c) Legible/Borderline\n",
      "(d) Borderline/Illegible\n",
      "Figure S-2: Examples of Inter-Annotator disagreement in legibility labeling. Images are labeled\n",
      "\"Class 1\"/\"Class 2\" to show the two labeled classes. In cases of disagreement, the more legible of\n",
      "the two labels was used for training and evaluation.\n",
      "Applications\n",
      "The paper presents multiple applications that can be facilitated by the American Stories dataset.\n",
      "This section provides details for each application given.\n",
      "Topic Classification\n",
      "To evaluate topic classification, we focused on the topic of politics. As we evaluate at both the\n",
      "scan and article level, for development and test sets we sampled full scans (all articles on the same\n",
      "scan). We took a random sample of up to three front page scans from each election year in our\n",
      "sample. These scans were double-labelled by student research assistants and incongruences were\n",
      "discussed and resolved. We place 20% of these (15 scans, 498 articles) into a development set and\n",
      "the remaining 62 scans (1473 articles) into the test set. Training data was sampled at the article level,\n",
      "rather than the scan level, from the same population of front page articles in election years. Training\n",
      "17\n",
      "\fdata was single-labelled by the same research assistants. A sample were double-labelled to check\n",
      "for consistency and they agreed on the labelling in 93% of cases.\n",
      "To evaluate neural methods, we finetune RoBERTa large [20] on the training set for ten epochs, with\n",
      "a batch size of 16, and a learning rate of 2e-6.\n",
      "For evaluation of sparse methods, we use two different methods to select keywords. First, we use\n",
      "the test and evaluation sets to mine keywords. We use TF-IDF to pull words and bigrams that are\n",
      "most commonly found in train set articles about politics, but not found in off-topic articles. We take\n",
      "the top 40 words and bigrams and then sequentially pick those that maximise F1 on the evaluation\n",
      "set, until there is no remaining keyword that increases F1. Using this technique, the mined keywords\n",
      "were: vote, election, republican, committee, united, party, president, congress.\n",
      "Second, we prompted Chat-GPT to produce keywords. We used the prompt: “You have a large\n",
      "number of 19th century US newspaper articles. You wish to classify these on whether they are\n",
      "about politics or not. The only way that you can do this is by checking whether they match any\n",
      "of a list of keywords or keyphrases. You can search for these keywords or phrases in each article,\n",
      "and if it matches any of them it will be classified as about politics, but if it does not match any, it\n",
      "will not. Please provide a list of keywords and phrases that will correctly classify as many of the\n",
      "articles that are about politics as possible, with a minimal number of off-topic articles classified as\n",
      "on topic” and received the following keywords: President, Congress, Election, Senator, Representa-\n",
      "tive, Governor, Democratic Party, Whig Party, Republican Party, Suffrage, Legislation, Lawmakers,\n",
      "Government, Policy, Bill, Campaign, Debate, Vote, Political Convention, Public Office, Political\n",
      "Reform, Impeachment.\n",
      "Using these lists of keywords, we consider any article to be predicted as on topic if it contains any\n",
      "of these keywords. We do not take case into account.\n",
      "The structured data in American Stories allows us to classify at the article level, a significant\n",
      "advantage. However, for comparison with Chronicling America, we also evaluate the same methods\n",
      "at the scan level. A scan is counted as on topic if any article on that page is on topic. For neural\n",
      "methods on Chronicling America, we chunk the text into passages of 256 tokens, as the page OCR\n",
      "is significantly longer than the context window.\n",
      "Content Dissemination Networks\n",
      "To detect reproduced content, we also compare neural and sparse methods. In this case, the neural\n",
      "methods are only possible with American Stories, whereas sparse methods are possible with both\n",
      "American Stories and Chronicling America.\n",
      "We evaluate these methods on all front pages from March 1, 1916, a randomly selected day. A\n",
      "single day is chosen because reproduced content tends to be published around the same time, so\n",
      "a single day will have a far higher number of reproduced articles than a random selection of front\n",
      "pages across time. On this day, American Stories contains 114 scans, with 2,354 articles. 1,994\n",
      "of these were not reproduced, while 360 were reproduced. These 360 comprise 113 distinct articles,\n",
      "with the median reproduced article being reprinted 2 times.\n",
      "For the neural method, we use the pre-trained neural model from [28]. This is a contrastively-trained\n",
      "bi-encoder finetuned from the MPNet Sentence BERT model [26, 32] on a large, hand-annotated\n",
      "sample of pairs of reproduced historical newspaper articles. [28] find this biencoder is marginally\n",
      "improved by running a cross-encoder over the outputs, but we do not reproduce these results as\n",
      "the cross-encoder is computationally costly for a small gain in performance. They also find that\n",
      "this fine-tuned biencoder model outperforms more generic semantic textual similarity models (eg.\n",
      "[26] by up to 20 percentage points. Thus the model is chosen to maximise accuracy, within a\n",
      "reasonable compute budget. At inference time, article representations are clustered using single\n",
      "linkage clustering to detect reproduced content, and spurious links are pruned using community\n",
      "detection. We use the same distance threshold as in [28].\n",
      "To enable a comparison to Chronicling America, where the content is only available at a page level,\n",
      "we amalgamate these results by page. A page-pair is counted as positive if they have any article in\n",
      "common. Nonetheless, the page-level evaluation of the neural method requires the data to be split\n",
      "into articles. It cannot be run over the unstructured text in Chronicling America.\n",
      "18\n",
      "\fTherefore for detecting reproduced content in Chronicling America, where we do not have article\n",
      "texts, we deploy the sparse methods from Viral Texts [30]. Viral Texts was designed specifically for\n",
      "detecting reproduced texts in Chronicling America’s noisy page-level OCR by looking for overlap-\n",
      "ping n-gram spans. To compare this method between American Stories and Chronicling Amer-\n",
      "ica, we also run it over the articles in American Stories and then amalgamate these results at the\n",
      "page level.\n",
      "Finally, we deploy the locality-sensitive hashing (LSH) specification from [28] to evaluate the per-\n",
      "formance of sparse methods on American Stories, using the same parameters. In particular we\n",
      "do this because the Viral Texts method is not designed to be run at the article level. As expected,\n",
      "we find that LSH performs better than Viral Texts at the article level, but both methods perform\n",
      "significantly worse than the neural methods, in line with the findings of [28].\n",
      "Story Clustering\n",
      "Finally, we demonstrate that the content in American Stories can be clustered into news stories,\n",
      "following the same story between newspapers and across time. To create clusters of stories, we use\n",
      "a contrastively-trained biencoder.\n",
      "We train this biencoder using data from allsides.com, a modern news website which shows how\n",
      "the same story is written by different newspapers. Articles on allsides.com are truncated. Groups\n",
      "of articles on the same story on allsides.com were used to create positive pairs. For negatives,\n",
      "we used the fact that each article is labelled with various tags, and also that we know which news\n",
      "source each article came from. For each article we take the article from the same news source, with\n",
      "different topic tags, that had the largest cosine similarity, using the biencoder before finetuning. In\n",
      "the cases where there were no articles with different tags from the same news source, we use articles\n",
      "from a news source which is lifted with the same political leaning. The specification that an article\n",
      "has different tags is important for making sure that articles are actual negatives.\n",
      "Overall this gave 26,194 unique articles, with 18,382 positive pairs and 18,445 negative pairs. We\n",
      "featurized the data as “headline [sep] article” and we finetuned the biencoder from [28] as in ex-\n",
      "periments we found that this outperformed finetuning an MPNet Sentence BERT model [26, 32]\n",
      "directly. We optimised hyperparameters using hyperband [17]. The best model was trained fro 9\n",
      "epochs, on a single GPU, with a batch size of 32, a warm up percent of 0.392. We optimised online\n",
      "contrastive loss [8], with and a loss margin of 0.497.\n",
      "At inference time, we cluster using single-linkage clustering, with a cosine similarity threshold of\n",
      "0.92. We control cluster size using leiden community detection [33]. We deduplicate the content\n",
      "using the method outlined in the section above. We take all articles that are reprinted at least five\n",
      "times, and run same story clustering over a year at a time.\n",
      "Dataset details\n",
      "Dataset URL\n",
      "The dataset can be found at https://huggingface.co/datasets/dell-research-harvard/\n",
      "AmericanStories.\n",
      "This dataset has structured metadata following schema.org, and is readily discoverable.5\n",
      "Training\n",
      "labels\n",
      "for\n",
      "the\n",
      "individual\n",
      "models\n",
      "detailed\n",
      "in\n",
      "this\n",
      "paper\n",
      "are\n",
      "also\n",
      "available,\n",
      "and\n",
      "can\n",
      "be\n",
      "found\n",
      "at\n",
      "https://huggingface.co/datasets/dell-research-harvard/\n",
      "AmericanStoriesTraining.\n",
      "DOI\n",
      "The DOI for this dataset is: 10.57967/hf/0757.\n",
      "5See\n",
      "https://search.google.com/test/rich-results/result?id=esZkoGgfOsLlnkrvwx9nSQ\n",
      "for full metadata.\n",
      "19\n",
      "\fLicense\n",
      "The dataset has a Creative Commons CC-BY license.\n",
      "Dataset usage\n",
      "The dataset is hosted on Hugging Face. Each year in the dataset is divided into a distinct file. The\n",
      "dataset can be easily downloaded using the datasets library:\n",
      "As the dataset is very large, files for specific years can be downloaded by specifying them or users\n",
      "can download all data for all years. Additionally, we provide two options for the output type. The\n",
      "first contains data at the article level, with features like newspaper name, page number, edition, date,\n",
      "headline, byline, and article text. The second contains data at the scan level. It contains information\n",
      "including the scan metadata; all detected content regions like articles, photographs, and adverts;\n",
      "legibility information, and bounding box coordinates.\n",
      "from datasets import load_dataset\n",
      "#\n",
      "Download data for the year 1809 at the associated article level (Default)\n",
      "dataset = load_dataset(\"dell-research-harvard/AmericanStories\",\n",
      "\"subset_years\",\n",
      "year_list=[\"1809\", \"1810\"]\n",
      ")\n",
      "# Download and process data for all years at the article level\n",
      "dataset = load_dataset(\"dell-research-harvard/AmericanStories\",\n",
      "\"all_years\"\n",
      ")\n",
      "# Download and process data for 1809 at the scan level\n",
      "dataset = load_dataset(\"dell-research-harvard/AmericanStories\",\n",
      "\"subset_years_content_regions\",\n",
      "year_list=[\"1809\"]\n",
      ")\n",
      "# Download ad process data for all years at the scan level\n",
      "dataset = load_dataset(\"dell-research-harvard/AmericanStories\",\n",
      "\"all_years_content_regions\")\n",
      "Users can find more information on accessing the dataset using the dataset card on Hugging Face.\n",
      "Author statement\n",
      "We bear all responsibility in case of violation of rights.\n",
      "Maintenance Plan\n",
      "We have chosen to host the dataset on huggingface as this ensures long-term access and preservation\n",
      "of the dataset.\n",
      "Dataset documentation and intended uses\n",
      "We follow the datasheets for datasets template [6]. Additionally, we have completed the dataset card\n",
      "on Hugging Face which can be accessed using the link to the dataset on Hugging Face hub 6\n",
      "Reproducibility\n",
      "Moreover, we have included our responses to The Machine Learning Reproducibility Checklist as\n",
      "outlined in table S-2.\n",
      "6https://huggingface.co/datasets/dell-research-harvard/AmericanStories\n",
      "20\n",
      "\fMotivation\n",
      "For what purpose was the dataset created? Was there a specific task in mind? Was\n",
      "there a specific gap that needed to be filled? Please provide a description.\n",
      "The dataset was created to provide researchers with a large, high-quality corpus of structured and\n",
      "transcribed newspaper article texts from historical local American newspapers. These texts provide a\n",
      "massive repository of information about topics ranging from political polarization to the construction\n",
      "of national and cultural identities to the minutiae of the daily lives of people’s ancestors. The dataset\n",
      "will be useful to a wide variety of researchers including historians, other social scientists, and NLP\n",
      "practitioners.\n",
      "Who created this dataset (e.g., which team, research group) and on behalf of which\n",
      "entity (e.g., company, institution, organization)?\n",
      "The dataset was created by a team of researchers at Harvard University, New York University,\n",
      "Northwestern Kellogg School, MIT, and Princeton University, led by Melissa Dell.\n",
      "Who funded the creation of the dataset? If there is an associated grant, please provide\n",
      "the name of the grantor and the grant name and number.\n",
      "Funding was provided by the Harvard Data Science Initiative, compute credits that Microsoft Azure\n",
      "provided to the Harvard Data Science Initiative, Harvard Catalyst, and the Harvard Economics De-\n",
      "partment Ken Griffin Fund for Research on Development Economics and Political Economy.\n",
      "Any other comments?\n",
      "None.\n",
      "Composition\n",
      "What do the instances that comprise the dataset represent (e.g., documents, pho-\n",
      "tos, people, countries)?\n",
      "Are there multiple types of instances (e.g., movies, users,\n",
      "and ratings; people and interactions between them; nodes and edges)? Please provide a\n",
      "description.\n",
      "Dataset instances are detected content regions in newspaper page scans from the Library of\n",
      "Congress’s Chronicling America collection. In the cases of article, headline, image caption, and\n",
      "byline regions, a text transcription is included if the page is written in English.\n",
      "How many instances are there in total (of each type, if appropriate)?\n",
      "Version 0.1.0 of American Stories contains 402 million content regions, 294 million of which\n",
      "include a text transcription.\n",
      "Does the dataset contain all possible instances or is it a sample (not necessarily\n",
      "random) of instances from a larger set?\n",
      "If the dataset is a sample, then what is the\n",
      "larger set? Is the sample representative of the larger set (e.g., geographic coverage)? If\n",
      "so, please describe how this representativeness was validated/verified. If it is not repre-\n",
      "sentative of the larger set, please describe why not (e.g., to cover a more diverse range of\n",
      "instances, because instances were withheld or unavailable).\n",
      "The Version 1.0 of the dataset will contain all possible instances. Version 0.1.0 contains approxi-\n",
      "mately 40% of all instances as of 6/7/23.\n",
      "What data does each instance consist of? “Raw” data (e.g., unprocessed text or\n",
      "images) or features? In either case, please provide a description.\n",
      "Each instance includes: a unique content region id, its detected class (ARTICLE, HEADLINE, CAP-\n",
      "TION, BYLINE, IMAGE, AD, TABLE, HEADER, PAGE NUMBER, or MASTHEAD), and the pixel co-\n",
      "ordinates of the newspaper page bounding box for the identified region. If the content region is\n",
      "classified as ARTICLE, HEADLINE, CAPTION, or BYLINE, the transcribed text is also provided.\n",
      "21\n",
      "\fIs there a label or target associated with each instance? If so, please provide a de-\n",
      "scription.\n",
      "Content regions are labeled by their model predicted class. Text article transcriptions have no label.\n",
      "Is any information missing from individual instances? If so, please provide a descrip-\n",
      "tion, explaining why this information is missing (e.g. because it was unavailable). This does\n",
      "not include intentionally removed information but might include, e.g., redacted text.\n",
      "No.\n",
      "Are relationships between individual instances made explicit (e.g., users’ movie rat-\n",
      "ings, social network links)? If so, please describe how these relationships are made\n",
      "explicit.\n",
      "All articles and other content regions include metadata that can definitively determine relationships\n",
      "to other content regions. For example, two articles with the same lccn (newspaper identifier), edition,\n",
      "and page number are from the same newspaper page scan.\n",
      "Are there recommended data splits (e.g., training, development/validation, testing)?\n",
      "If so, please provide a description of these splits, explaining the rationale behind them.\n",
      "There are no recommended splits.\n",
      "Are there any errors, sources of noise, or redundancies in the dataset? If so, please\n",
      "provide a description.\n",
      "Layout detection, OCR, and article association all introduce noise.\n",
      "Is the dataset self-contained, or does it link to or otherwise rely on external resources\n",
      "(e.g., websites, tweets, other datasets)? If it links to or relies on external resources, a)\n",
      "are there guarantees that they will exist, and remain constant, over time; b) are there official\n",
      "archival versions of the complete dataset (i.e., including the external resources as they ex-\n",
      "isted at the time the dataset was created); c) are there any restrictions (e.g., licenses, fees)\n",
      "associated with any of the external resources that might apply to a future user? Please\n",
      "provide descriptions of all external resources and any restrictions associated with them, as\n",
      "well as links or other access points, as appropriate.\n",
      "The provided text data are self-contained. Some applications could require downloading the original\n",
      "scans, which are at https://chroniclingamerica.loc.gov/. All scans are freely available and\n",
      "in the public domain.\n",
      "Does the dataset contain data that might be considered confidential (e.g., data that\n",
      "is protected by legal privilege or by doctor-patient confidentiality, data that includes\n",
      "the content of individuals non-public communications)? If so, please provide a de-\n",
      "scription.\n",
      "The dataset is drawn entirely from image scans in the public domain that are freely available for\n",
      "download from the Library of Congress’s website.\n",
      "Does the dataset contain data that, if viewed directly, might be offensive, insulting,\n",
      "threatening, or might otherwise cause anxiety? If so, please describe why.\n",
      "Texts in the dataset reflect attitudes and values of a large, diverse group of newspaper editors and\n",
      "writers in the period they were written (1790-1960) and include content that may be considered\n",
      "offenseive for a variety of reasons.\n",
      "Does the dataset relate to people? If not, you may skip the remaining questions in this\n",
      "section.\n",
      "Yes. The dataset contains news about people.\n",
      "22\n",
      "\fDoes the dataset identify any subpopulations (e.g., by age, gender)? If so, please de-\n",
      "scribe how these subpopulations are identified and provide a description of their respective\n",
      "distributions within the dataset.\n",
      "It may be possible to infer certain characters about individuals covered in the news historically from\n",
      "the data. The authors of the dataset do not identify any subpopulations.\n",
      "Is it possible to identify individuals (i.e., one or more natural persons), either directly\n",
      "or indirectly (i.e., in combination with other data) from the dataset? If so, please\n",
      "describe how.\n",
      "If an individual appeared in the news during this period, then texts may contain their name and\n",
      "other information. In some cases, it may be possible to link individuals to information on ancestry\n",
      "websites or Wikipedia (in the case of prominent historical figures). We do not attempt to do so in\n",
      "this paper.\n",
      "Does the dataset contain data that might be considered sensitive in any way (e.g.,\n",
      "data that reveals racial or ethnic origins, sexual orientations, religious beliefs, politi-\n",
      "cal opinions or union memberships, or locations; financial or health data; biometric\n",
      "or genetic data; forms of government identification, such as social security num-\n",
      "bers; criminal history)? If so, please provide a description.\n",
      "The data are drawn entirely from newspaper scans in the public domain.\n",
      "Any other comments?\n",
      "None.\n",
      "Collection Process\n",
      "How was the data associated with each instance acquired? Was the data directly\n",
      "observable (e.g., raw text, movie ratings), reported by subjects (e.g., survey responses), or\n",
      "indirectly inferred/derived from other data (e.g., part-of-speech tags, model-based guesses\n",
      "for age or language)? If data was reported by subjects or indirectly inferred/derived from\n",
      "other data, was the data validated/verified? If so, please describe how.\n",
      "The pipeline used to create layouts and article transcriptions from page images is described in detail\n",
      "within the paper. The dataset described here is the output of that pipeline.\n",
      "What mechanisms or procedures were used to collect the data (e.g., hardware ap-\n",
      "paratus or sensor, manual human curation, software program, software API)? How\n",
      "were these mechanisms or procedures validated?\n",
      "The data extraction pipeline is described and evaluated in the main paper text.\n",
      "If the dataset is a sample from a larger set, what was the sampling strategy (e.g.,\n",
      "deterministic, probabilistic with specific sampling probabilities)?\n",
      "Release 1.0 will include everything in the Chronicling America scan collection.\n",
      "Who was involved in the data collection process (e.g., students, crowdworkers,\n",
      "contractors) and how were they compensated (e.g., how much were crowdworkers\n",
      "paid)?\n",
      "A large group of professors, research assistants, and students collaborated on all aspects of the data\n",
      "collection process, including labeling training data, training and validating models, data engineering,\n",
      "and conceptual design. All were compensated for their work, according to the regulations of Harvard\n",
      "University and New York University.\n",
      "Over what timeframe was the data collected? Does this timeframe match the creation\n",
      "timeframe of the data associated with the instances (e.g., recent crawl of old news\n",
      "23\n",
      "\farticles)? If not, please describe the timeframe in which the data associated with the\n",
      "instances was created.\n",
      "Scans from Chronicling America were processed between 6/1/23 and 6/7/23. The data associated\n",
      "with the instances were created between 1780 and 1963, when they were published in local newspa-\n",
      "pers.\n",
      "Were any ethical review processes conducted (e.g., by an institutional review\n",
      "board)? If so, please provide a description of these review processes, including the out-\n",
      "comes, as well as a link or other access point to any supporting documentation.\n",
      "The data are entirely in the public domain and hence do not fall under the jurisdiction of university\n",
      "institutional review boards.\n",
      "Does the dataset relate to people? If not, you may skip the remaining questions in this\n",
      "section.\n",
      "Yes, the articles in the dataset talk about people.\n",
      "Did you collect the data from the individuals in question directly, or obtain it via third\n",
      "parties or other sources (e.g., websites)?\n",
      "We collected this data from a third party, the Library of Congress, which has verified that all data\n",
      "are in the public domain.\n",
      "Were the individuals in question notified about the data collection?\n",
      "If so, please\n",
      "describe (or show with screenshots or other information) how notice was provided, and\n",
      "provide a link or other access point to, or otherwise reproduce, the exact language of the\n",
      "notification itself.\n",
      "The data are in the public domain and cover many millions of individuals, most of whom are\n",
      "deceased.\n",
      "Did the individuals in question consent to the collection and use of their data? If\n",
      "so, please describe (or show with screenshots or other information) how consent was re-\n",
      "quested and provided, and provide a link or other access point to, or otherwise reproduce,\n",
      "the exact language to which the individuals consented.\n",
      "The data are in the public domain and cover many millions of individuals, most of whom are\n",
      "deceased.\n",
      "If consent was obtained, were the consenting individuals provided with a mecha-\n",
      "nism to revoke their consent in the future or for certain uses? If so, please provide a\n",
      "description, as well as a link or other access point to the mechanism (if appropriate).\n",
      "Not applicable.\n",
      "Has an analysis of the potential impact of the dataset and its use on data subjects\n",
      "(e.g., a data protection impact analysis) been conducted?\n",
      "If so, please provide a\n",
      "description of this analysis, including the outcomes, as well as a link or other access point\n",
      "to any supporting documentation.\n",
      "No such analysis has been conducted.\n",
      "Any other comments?\n",
      "None.\n",
      "Preprocessing/cleaning/labeling\n",
      "Was any preprocessing/cleaning/labeling of the data done (e.g., discretization or\n",
      "bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of\n",
      "24\n",
      "\finstances, processing of missing values)? If so, please provide a description. If not,\n",
      "you may skip the remainder of the questions in this section.\n",
      "No preprocessing was conducted.\n",
      "Uses\n",
      "Has the dataset been used for any tasks already? If so, please provide a description.\n",
      "Example uses are detailed in the main text.\n",
      "Is there a repository that links to any or all papers or systems that use the dataset?\n",
      "If so, please provide a link or other access point.\n",
      "No such repository currently exists.\n",
      "What (other) tasks could the dataset be used for?\n",
      "There are a large number of potential uses in the social sciences, digital humanities, and deep\n",
      "learning research, discussed in more detail in the main text.\n",
      "Is there anything about the composition of the dataset or the way it was collected and\n",
      "preprocessed/cleaned/labeled that might impact future uses? For example, is there\n",
      "anything that a future user might need to know to avoid uses that could result in unfair\n",
      "treatment of individuals or groups (e.g., stereotyping, quality of service issues) or other\n",
      "undesirable harms (e.g., financial harms, legal risks) If so, please provide a description. Is\n",
      "there anything a future user could do to mitigate these undesirable harms?\n",
      "This dataset contains unfiltered content composed by newspaper editors, columnists, and other\n",
      "sources. It reflects their biases and any factual errors that they made.\n",
      "Are there tasks for which the dataset should not be used? If so, please provide a\n",
      "description.\n",
      "We would urge caution in using the data to train generative language models - without additional\n",
      "filtering - as it contains content that many would consider toxic.\n",
      "Any other comments?\n",
      "None.\n",
      "Distribution\n",
      "Will the dataset be distributed to third parties outside of the entity (e.g., company,\n",
      "institution, organization) on behalf of which the dataset was created? If so, please\n",
      "provide a description.\n",
      "Yes. The dataset is available for public use.\n",
      "How will the dataset will be distributed (e.g., tarball on website, API, GitHub) Does\n",
      "the dataset have a digital object identifier (DOI)?\n",
      "The dataset is available via HuggingFace.\n",
      "Download and instructions are at https:\n",
      "//huggingface.co/datasets/dell-research-harvard/AmericanStories.\n",
      "The dataset’s\n",
      "DOI is: https://doi.org/10.57967/hf/0757\n",
      "When will the dataset be distributed?\n",
      "The dataset is currently available.\n",
      "Will the dataset be distributed under a copyright or other intellectual property (IP)\n",
      "license, and/or under applicable terms of use (ToU)? If so, please describe this license\n",
      "25\n",
      "\fand/or ToU, and provide a link or other access point to, or otherwise reproduce, any relevant\n",
      "licensing terms or ToU, as well as any fees associated with these restrictions.\n",
      "The dataset is distributed under a Creative Commons CC-BY license. The terms of this license can\n",
      "be viewed at https://creativecommons.org/licenses/by/2.0/\n",
      "Have any third parties imposed IP-based or other restrictions on the data associated\n",
      "with the instances? If so, please describe these restrictions, and provide a link or other\n",
      "access point to, or otherwise reproduce, any relevant licensing terms, as well as any fees\n",
      "associated with these restrictions.\n",
      "There are no third party IP-based or other restrictions on the data.\n",
      "Do any export controls or other regulatory restrictions apply to the dataset or to\n",
      "individual instances? If so, please describe these restrictions, and provide a link or other\n",
      "access point to, or otherwise reproduce, any supporting documentation.\n",
      "No export controls or other regulatory restrictions apply to the dataset or to individual instances.\n",
      "Any other comments?\n",
      "None.\n",
      "Maintenance\n",
      "Who will be supporting/hosting/maintaining the dataset?\n",
      "HuggingFace will continue to host the dataset. The authors will provide support, updates, and\n",
      "maintenance.\n",
      "How can the owner/curator/manager of the dataset be contacted (e.g., email ad-\n",
      "dress)?\n",
      "Melissa Dell can be contacted via email at melissadell@fas.harvard.edu\n",
      "Is there an erratum? If so, please provide a link or other access point.\n",
      "There is no erratum.\n",
      "Will the dataset be updated (e.g., to correct labeling errors, add new instances, delete\n",
      "instances)? If so, please describe how often, by whom, and how updates will be commu-\n",
      "nicated to users (e.g., mailing list, GitHub)?\n",
      "The dataset will continue to be updated as new scans are processed. New versions will be added to\n",
      "HuggingFace. Anyone can subscribe to notifications about the dataset via HuggingFace.\n",
      "If the dataset relates to people, are there applicable limits on the retention of the data\n",
      "associated with the instances (e.g., were individuals in question told that their data\n",
      "would be retained for a fixed period of time and then deleted)? If so, please describe\n",
      "these limits and explain how they will be enforced.\n",
      "All data are in the public domain.\n",
      "Will older versions of the dataset continue to be supported/hosted/maintained? If so,\n",
      "please describe how. If not, please describe how its obsolescence will be communicated\n",
      "to users.\n",
      "Older versions of the dataset will still be visable via the HuggingFace repo.\n",
      "If others want to extend/augment/build on/contribute to the dataset, is there a mech-\n",
      "anism for them to do so? If so, please provide a description. Will these contributions\n",
      "be validated/verified? If so, please describe how. If not, why not? Is there a process\n",
      "26\n",
      "\ffor communicating/distributing these contributions to other users? If so, please provide a\n",
      "description.\n",
      "The dataset is privately created and maintained. There is no current plan to allow open source\n",
      "contributions.\n",
      "Any other comments?\n",
      "None.\n",
      "27\n",
      "\fTable S-2: Reproducibility checklist\n",
      "Item\n",
      "Response\n",
      "Comment\n",
      "For all models and algorithms presented, check if you include:\n",
      "A clear description of the mathematical set-\n",
      "ting,\n",
      "algorithm, and/or model.\n",
      "Yes\n",
      "A clear explanation of any assumptions.\n",
      "Yes\n",
      "An analysis of the complexity\n",
      "(time, space, sample size) of any algorithm.\n",
      "NA\n",
      "Complexity can depend upon\n",
      "application-specific architecture\n",
      "and methods. We are using\n",
      "transformer-based models within\n",
      "our\n",
      "framework and we have reported\n",
      "the time profile and other related\n",
      "details\n",
      "For any theoretical claim, check if you include:\n",
      "A clear statement of the claim.\n",
      "Yes\n",
      "A complete proof of the claim.\n",
      "Yes\n",
      "For all datasets used, check if you include:\n",
      "The relevant statistics, such\n",
      "as number of examples\n",
      "Yes\n",
      "The details of train / validation / test splits\n",
      "Yes\n",
      "An explanation of any data that\n",
      "were excluded, and all pre-processing step.\n",
      "Yes\n",
      "A link to a downloadable version\n",
      "of the dataset or simulation environment\n",
      "Yes\n",
      "Link to Hugging Face Hub repo\n",
      "provided\n",
      "For new data collected, a complete\n",
      "description of the data collection process,\n",
      "such as instructions to annotators\n",
      "and methods for quality control.\n",
      "Yes\n",
      "For all shared code related to this work, check if you include:\n",
      "Specification of dependencies.\n",
      "Yes\n",
      "Training code.\n",
      "Yes\n",
      "Evaluation codes\n",
      "Yes\n",
      "(Pre-)trained model(s).\n",
      "Yes\n",
      "Available on HuggingFace\n",
      "README file includes table of results\n",
      "accompanied by precise\n",
      "command to run to produce those results\n",
      "Yes\n",
      "For all reported experimental results, check if you include:\n",
      "The range of hyper-parameters considered,\n",
      "method to select the best hyper-parameter\n",
      "configuration, and specification of all\n",
      "hyper-parameters used to generate results\n",
      "Yes\n",
      "The exact number of training and evaluation\n",
      "runs.\n",
      "Yes\n",
      "A clear definition of the specific\n",
      "measure or statistics used to report results.\n",
      "Yes\n",
      "Continued on next page\n",
      "28\n",
      "\fTable S-2: Reproducibility checklist (Continued)\n",
      "A description of results with\n",
      "central tendency (e.g. mean) variation (e.g.\n",
      "error bars).\n",
      "NA\n",
      "The average runtime for each result,\n",
      "or estimated energy cost.\n",
      "Yes\n",
      "Both training and inference times\n",
      "have been reported\n",
      "A description of the computing infrastructure\n",
      "used\n",
      "Yes\n",
      "29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the last paper in the dataset - one from 2023. This paper is representative of papers that\n",
    "# were converted from PDFs\n",
    "\n",
    "print(papers.loc[20285, 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparing the plaintext to the PDF, here are the things we notice did not translate over very well:\n",
    "\n",
    " - images/figures - the image and figure titles made it across into plaintext, but as expected, images themseves did not. In the RAG response back to the user, we'll have to decide whether to display the rendered images back to the user (most likely relying on the PDF document itself - which might require PDF manipulation if we just want to display the part with the image) _or_ whether we want to leave images out. Leaving images could be potentially viable as we're planning to provide access to the papers involved in the particular RAG response regardless.\n",
    " - tables - tables and their data are translated into plaintext but not in tabular format. This raises questions of how to handle these both from an embedding perspective (would including tabular data add extra \"noise\" to the embedding) as whether they should be displayed in the RAG response (similar to the question for images)\n",
    " - equations - similar to tables, equations are carried over into plaintext, but lacking formatting. This makes it hard for a human to understand the equation, and, similarly, equations are a niche notation that might not be embedded well. So the question regarding whether to include them in embedding/display goes for equations as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573 \n",
      "\n",
      "BIT - SERIAL NEURAL  NETWORKS \n",
      "\n",
      "Alan F.  Murray,  Anthony V . W.  Smith  and Zoe F.  Butler. \n",
      "\n",
      "Department of Electrical Engineering,  University of Edinburgh, \n",
      "\n",
      "The King's Buildings, Mayfield Road,  Edinburgh, \n",
      "\n",
      "Scotland,  EH93JL. \n",
      "\n",
      "ABSTRACT \n",
      "\n",
      "A  bit  - serial  VLSI  neural  network  is  described  from  an  initial  architecture  for  a \n",
      "synapse array through to silicon layout and board design.  The issues surrounding bit \n",
      "- serial  computation,  and  analog/digital  arithmetic  are  discussed  and  the  parallel \n",
      "development  of  a  hybrid  analog/digital  neural  network  is  outlined.  Learning  and \n",
      "recall  capabilities  are  reported  for  the  bit  - serial  network  along  with  a  projected \n",
      "specification  for  a  64  - neuron,  bit  - serial  board  operating  at 20 MHz.  This tech(cid:173)\n",
      "nique  is  extended  to  a  256  (2562  synapses)  network  with  an  update  time  of 3ms, \n",
      "using  a  \"paging\"  technique  to  time  - multiplex  calculations  through  the  synapse \n",
      "array. \n",
      "\n",
      "1. INTRODUCTION \n",
      "\n",
      "The functions a  synthetic neural network may aspire to mimic are the ability to con(cid:173)\n",
      "sider  many  solutions  simultaneously,  an  ability  to  work  with  corrupted  data  and  a \n",
      "natural  fault  tolerance.  This  arises  from  the  parallelism  and  distributed  knowledge \n",
      "representation  which  gives  rise  to  gentle  degradation  as  faults  appear.  These func(cid:173)\n",
      "tions  are  attractive  to implementation  in VLSI  and  WSI.  For example,  the natural \n",
      "fault  - tolerance  could  be  useful  in  silicon  wafers  with  imperfect  yield,  where  the \n",
      "network  degradation  is  approximately  proportional  to  the  non-functioning  silicon \n",
      "area. \n",
      "To cast  neural networks in engineering language,  a  neuron is a  state machine that is \n",
      "either  \"on\"  or  \"off',  which  in  general  assumes  intermediate  states  as  it  switches \n",
      "smoothly  between  these  extrema.  The  synapses  weighting  the  signals  from  a \n",
      "transmitting neuron  such that it is more or less excitatory or inhibitory to the receiv(cid:173)\n",
      "ing  neuron.  The  set  of synaptic weights  determines  the stable  states and  represents \n",
      "the learned  information in a system. \n",
      "The  neural  state,  VI'  is  related  to  the  total  neural  activity  stimulated  by  inputs  to \n",
      "the  neuron  through  an  activation junction,  F.  Neural  activity  is  the  level  of excita(cid:173)\n",
      "tion  of the  neuron  and the  activation  is  the way  it  reacts  in a  response to a  change \n",
      "in activation. The neural output state at time t, V[,  is related to x[ by \n",
      "\n",
      "V[  = F (xf) \n",
      "\n",
      "(1) \n",
      "\n",
      "The  activation  function  is  a  \"squashing\"  function  ensuring  that  (say)  Vi  is  1  when \n",
      "Xi  is large  and  -1  when Xi  is  small.  The neural update function  is therefore straight(cid:173)\n",
      "forward: \n",
      "\n",
      ". \n",
      "\n",
      ",+1  - ,   + ~  ~ T  V' \n",
      "J \n",
      "XI \n",
      "\n",
      "i-n-l \n",
      "0  ~  ii \n",
      "\n",
      "- XI \n",
      "\n",
      "• •••• \n",
      "\n",
      "J-O \n",
      "\n",
      "(2) \n",
      "\n",
      "where  8  represents  the  rate  of change  of neural  activity,  Tij \n",
      "and n  is  the number of terms giving an n  - neuron array [1]. \n",
      "Although  the  neural function  is  simple  enough,  in  a  totally  interconnected  n  - neu(cid:173)\n",
      "ron  network  there  are n 2  synapses requiring n 2  multiplications  and  summations and \n",
      "\n",
      "is  the  synaptic  weight \n",
      "\n",
      "© American Institute of Physics 1988 \n",
      "\n",
      "\f574 \n",
      "\n",
      "a large number of interconnects.  The challenge in VLSI is therefore to design a  sim(cid:173)\n",
      "ple,  compact  synapse  that  can  be  repeated  to  build  a  VLSI  neural  network  with \n",
      "In  a  network  with  fixed  functionality,  this  is  relatively \n",
      "manageable  interconnect. \n",
      "straightforward.  H the  network  is to be able to learn,  however,  the synaptic weights \n",
      "must  be programmable, and therefore more complicated. \n",
      "\n",
      "2. DESIGNING  A NEURAL  NETWORK IN  VLSI \n",
      "\n",
      "There  are  fundamentally  two  approaches  to  implementing  any  function  in  silicon  -\n",
      "digital and analog.  Each technique has its advantages and  disadvantages,  and these \n",
      "are  listed  below,  along  with  the  merits  and  demerits  of bit  - serial  architectures  in \n",
      "digital (synchronous) systems. \n",
      "Digital  vs.  analog:  The  primary  advantage  of digital  design  for  a  synapse  array  is \n",
      "that  digital  memory  is  well  understood,  and  can  be  incorporated  easily.  Learning \n",
      "networks are  therefore  possible  without  recourse  to unusual  techniques  or technolo(cid:173)\n",
      "gies.  Other strengths of a digital approach are that design techniques are advanced, \n",
      "automated  and  well  understood  and  noise  immunity  and  computational  speed  can \n",
      "be  high.  Unattractive features  are  that  digital  circuits  of this complexity need  to  be \n",
      "synchronous  and  all  states  and  activities  are  quantised,  while  real  neural  networks \n",
      "are  asynchronous  and  unquantised.  Furthermore,  digital  multipliers  occupy  a  large \n",
      "silicon  area, giving a low synapse count on  a single chip. \n",
      "The  advantages  of  analog  circuitry  are  that  asynchronous  behaviour  and  smooth \n",
      "neural  activation  are  automatic.  Circuit  elements can  be  small,  but  noise  immunity \n",
      "is relatively  low  and  arbitrarily  high  precision is not  possible.  Most  importantly,  no \n",
      "reliable  analog,  non  - volatile  memory  technology  is  as  yet  readily  available.  For \n",
      "this  reason,  learning  networks  lend  themselves  more  naturally to  digital  design  and \n",
      "implementation. \n",
      "Several  groups  are  developing  neural  chips  and  boards,  and  the  following  listing \n",
      "does  not  pretend  to  be  exhaustive.  It is  included,  rather,  to indicate  the spread  of \n",
      "activity  in  this  field.  Analog  techniques  have  been  used  to  build  resistor  I  opera(cid:173)\n",
      "tional  amplifier  networks [2,3]  similar to  those  proposed  by  Hopfield  and Tank [4]. \n",
      "A  large  group  at  Caltech  is  developing  networks  implementing  early  vision  and \n",
      "auditory  processing  functions  using the intrinsic nonlinearities of MaS transistors in \n",
      "the subthreshold  regime  [5,6].  The problem of implementing analog  networks with \n",
      "electrically  programmable  synapses  has  been  addressed  using  CCDIMNOS technol(cid:173)\n",
      "ogy  [7].  Finally,  Garth  [8]  is  developing  a  digital  neural  accelerator  board  (\"Net(cid:173)\n",
      "sim\")  that  is  effectively  a  fast  SIMD  processor  with  supporting  memory  and  com(cid:173)\n",
      "munications chips. \n",
      "Bit - serial  vs.  bit  - parallel:  Bit  - serial  arithmetic and  communication  is  efficient \n",
      "for  computational  processes,  allowing  good  communication  within  and  between \n",
      "VLSI  chips  and  tightly  pipelined  arithmetic  structures.  It  is  ideal  for  neural  net(cid:173)\n",
      "works  as  it  minimises  the  interconnect  requirement  by  eliminating  multi  - wire \n",
      "busses.  Although  a  bit  - parallel  design  would  be  free  from  computational  latency \n",
      "(delay  between  input  and  output),  pipelining  makes  optimal  use  of  the  high  bit  -\n",
      "rates possible in serial systems,  and  makes for  efficient circuit usage. \n",
      "2.1  An asynchronous pulse stream VLSI neural network: \n",
      "In  addition  to  the  digital  system  that  forms  the  substance  of  this  paper,  we  are \n",
      "developing  a  hybrid  analOg/digital  network  family.  This work  is  outlined  here,  and \n",
      "has  been  reported  in  greater  detail  elsewhere  [9, 10, 11].  The  generic  (logical  and \n",
      "layout)  architecture  of a  single  network  of n  totally  interconnected neurons is  shown \n",
      "\n",
      "\f575 \n",
      "\n",
      "schematically  in  figure  1.  Neurons  are  represented  by  circles,  which  signal  their \n",
      "states,  Vi  upward  into  a  matrix  of  synaptic  operators.  The  state  signals  are  con(cid:173)\n",
      "nected  to  a  n  - bit  horizontal  bus  running  through  the  synaptic  array,  with  a  con(cid:173)\n",
      "nection  to  each  synaptic  operator  in  every  column.  All  columns  have  n  operators \n",
      "(denoted  by  squares)  and  each  operator adds its synaptic contribution,  Tij V j\n",
      ",  to the \n",
      "running  total  of  activity  for  the  neuron  i  at  the  foot  of  the  column.  The  synaptic \n",
      "function  is  therefore  to  multiply  the  signalling  neuron  state,  Vj\n",
      ",  by  the  synaptic \n",
      "weight,  Tij ,  and  to  add  this  product  to  the  running  total.  This  architecture  is com(cid:173)\n",
      "mon to both  the bit - serial and pulse - stream networks. \n",
      "\n",
      "Synapse \n",
      "\n",
      "States { Vj  } \n",
      "\n",
      "Figure 1. Generic architecture for  a  network of n totally interconnected neurons. \n",
      "\n",
      "Neurons \n",
      "\n",
      "j=O \n",
      "\n",
      "j=II -1 \n",
      "\n",
      "This type of architecture has many attractions for  implementation in 2  - dimensional \n",
      "silicon  as  the  summation  2  Tij Vj  is  distributed  in  space.  The  interconnect \n",
      "requirement  (n  inputs  to  each  neuron)  is  therefore  distributed  through  a  column, \n",
      "reducing the need  for  long - range wiring.  The architecture is modular,  regular and \n",
      "can be easily expanded. \n",
      "In  the  hybrid  analog/digital  system,  the  circuitry  uses  a  \"pulse  stream\"  signalling \n",
      "method  similar  to  that  in  a  natural  neural  system.  Neurons  indicate  their  state  by \n",
      "the  presence  or  absence  of  pulses  on  their  outputs,  and  synaptic  weighting  is \n",
      "achieved  by  time  - chopping  the  presynaptic  pulse  stream  prior  to  adding  it  to  the \n",
      "postsynaptic  activity  summation.  It  is  therefore  asynchronous  and  imposes  no fun(cid:173)\n",
      "damental  limitations  on  the  activation  or  neural  state.  Figure  2  shows  the  pulse \n",
      "stream  mechanism  in  more  detail.  The synaptic  weight  is  stored  in  digital  memory \n",
      "local to the operator.  Each synaptic operator has an  excitatory and inhibitory  pulse \n",
      "stream  input  and  output.  The  resultant  product  of  a  synaptic  operation,  Tij Vj\n",
      ",  is \n",
      "added  to  the  running  total  propagating  down  either  the  excitatory  or  inhibitory \n",
      "channel.  One binary bit  (the  MSBit)  of the  stored  Tij  determines whether  the con(cid:173)\n",
      "tribution  is excitatory or inhibitory. \n",
      "The  incoming  excitatory  and  inhibitory  pulse  stream  inputs  to  a  neuron  are \n",
      "integrated  to  give  a  neural  activation  potential  that varies  smoothly  from  0  to  5  V. \n",
      "This  potential controls a  feedback  loop with  an odd number of logic  inversions and \n",
      "\n",
      "\f576 \n",
      "\n",
      ". • • \n",
      "\n",
      "XT •• \n",
      "\n",
      "V , \n",
      ".u.u, \n",
      "• \n",
      "\n",
      "Figure  2.  Pulse  stream  arithmetic.  Neurons  are  denoted  by  0  and synaptic  operators \n",
      "by  D. \n",
      "\n",
      "thus  forms  a  switched  \"ring - oscillator\".  H the inhibitory input dominates,  the feed(cid:173)\n",
      "back  loop  is  broken.  H  excitatory  spikes  subsequently  dominate  at  the  input,  the \n",
      "neural activity rises  to 5V and the feedback  loop oscillates with  a period determined \n",
      "by a  delay  around  the loop.  The resultant  periodic waveform is then converted to a \n",
      "series  of voltage  spikes,  whose  pulse  rate  represents  the  neural  state,  Vi'  Interest(cid:173)\n",
      "ingly,  a  not  dissimilar  technique is  reported  elsewhere  in this volume,  although  the \n",
      "synapse function  is executed differently [12]. \n",
      "\n",
      "3. A 5  - STATE BIT - SERIAL NEURAL  NETWORK \n",
      "\n",
      "The  overall  architecture  of  the  5  - state  bit  - serial  neural  network  is  identical  to \n",
      "that  of  the  pulse  stream  network.  It  is  an  array  of n 2  interconnected  synchronous \n",
      "synaptic  operators,  and  whereas  the  pulse  stream  method  allowed  Vj  to  assume  all \n",
      "values  between  \"off' and  \"on\",  the  5 - state network VJ  is constrained  to 0,  ±0.5 Qr \n",
      "± 1.  The resultant  activation  function  is  shown  in  Figure 3.  Full  digital  multiplica(cid:173)\n",
      "tion  is  costly  in  silicon  area,  but  multiplication  of  Tij  by  Vj  =  0.5  merely  requires \n",
      "the synaptic  weight  to be right  - shifted  by  1 bit.  Similarly,  multiplication  by  0.25 \n",
      "involves  a  further  right  - shift  of Til'  and  multiplication  by 0.0  is  trivially  easy.  VJ \n",
      "<  0 is not  problematic,  as  a  switchable adder/subtractor  is  not much  more complex \n",
      "than  an  adder.  Five  neural  states  are  therefore  feasible  with  circuitry  that  is  only \n",
      "slightly more complex  than  a  simple serial adder.  The neural state expands from a  1 \n",
      "bit  to  a  3  bit  (5  - state)  representation,  where  the  bits  represent  \"add/subtract?\", \n",
      "\"shift?\" and \"multiply by O?\". \n",
      "Figure 4  shows  part of the synaptic  array.  Each synaptic operator includes an 8 bit \n",
      "shift  register  memory  block  holding  the  synaptic  weight,  Til'  A  3  bit  bus  for  the  5 \n",
      "neural  states  runs  horizontally  above  each  synaptic  row.  Single  phase  dynamic \n",
      "CMOS  has  been  used  with  a  clock  frequency  in  excess  of 20  MHz  [13).  Details of \n",
      "a synaptic operator are  shown  in  figure 5.  The synaptic weight  Til  cycles around the \n",
      "shift  register  and  the  neural  state  Vj  is  present  on  the  state  bus.  During  the  first \n",
      "clock  CYCle,  the  synaptic  weight  is  multiplied  by  the  neural  state  and  during  the \n",
      "second,  the  most  significant  bit (MSBit)  of the resultant  Tij Vj  is sign  - extended for \n",
      "\n",
      "\f577 \n",
      "\n",
      "lHRESHOLD \n",
      "\n",
      "State VJ \n",
      "\n",
      "..... -------=-------.. Activity sJ \n",
      "\n",
      "s· \n",
      "\n",
      "\"5  STATE\" \n",
      "\n",
      "\"Sharper\" \n",
      "\n",
      "\"Smoother\" \n",
      "\n",
      "~.....::~-\"'--x.&..t------ Activity \"J \n",
      "\n",
      "Figure 3.  \"Hard - threshold\",  5  - state and sigmoid activation functions. \n",
      "\n",
      "J-a-1T  v \n",
      "~  ..  J \n",
      "J-li \n",
      "\n",
      "v, \n",
      "\n",
      "v, \n",
      "\n",
      "Figure 4.  Section  of the  synaptic  array  of the  5  - state activation function  neural net(cid:173)\n",
      "work. \n",
      "\n",
      "8  bits  to  allow  for  word  growth  in  the  running  summation.  A  least  significant  bit \n",
      "(LSBit)  signal  running down  the  synaptic  columns indicates the arrival  of the LSBit \n",
      "of  the  Xj  running  total.  If  the  neural  state  is  ±O.5  the  synaptic  weight  is  right \n",
      "shifted  by  1 bit and then added to or subtracted from  the running total.  A  multipli(cid:173)\n",
      "cation  of  ± 1  adds  or  subtracts  the  weight  from  the  total  and  multiplication  by  0 \n",
      "\n",
      "\f578 \n",
      "\n",
      ".0.5 \n",
      ".0.0 \n",
      "\n",
      "Add/Subtract \n",
      "\n",
      "Add! \n",
      "Subtract \n",
      "\n",
      "Carry \n",
      "\n",
      "Figure S.  The  synaptic operator with a 5 - state activation function. \n",
      "\n",
      "does not alter the running summation. \n",
      "The  final  summation  at  the  foot  of the  column  is  thresholded  externally  according \n",
      "to  the  5  - state activation function  in  figure  3.  As  the  neuron activity Xj'  increases \n",
      "through  a  threshold  value  x\" \n",
      "ideal  sigmoidal  activation  represents  a  smooth  switch \n",
      "of  neural  state  from  -1  to  1.  The 5  - state  \"staircase\"  function  gives a  superficially \n",
      "much  better  approximation  to  the  sigmoid  form  than  a  (much  simpler  to  imple(cid:173)\n",
      "ment)  threshold  function.  The  sharpness  of  the  transition  can  be  controlled  to \n",
      "\"tune\"  the  neural dynamics for  learning and computation.  The control parameter is \n",
      "referred  to  as  temperature  by  analogy  with  statistical  functions  with  this  sigmoidal \n",
      "form.  High  \"temperature\" gives a  smoother staircase and sigmoid,  while a tempera(cid:173)\n",
      "ture  of  0  reduces  both  to  the  ''Hopfield''  - like  threshold  function.  The  effects  of \n",
      "temperature  on  both  learning  and  recall  for  the  threshold  and  5  - state  activation \n",
      "options are discussed in section 4. \n",
      "\n",
      "4. LEARNING AND  RECALL  WITH VLSI  CONSTRAINTS \n",
      "\n",
      "Before  implementing  the  reduced  - arithmetic  network  in  VLSI,  simulation  experi(cid:173)\n",
      "ments  were  conducted  to  verify  that  the  5  - state  model  represented  a  worthwhile \n",
      "enhancement  over  simple  threshold  activation.  The  \"benchmark\"  problem  was \n",
      "chosen  for  its  ubiquitousness,  rather  than  for  its  intrinsic  value.  The  implications \n",
      "for  learning  and  recall  of the  5  - state  model,  the  threshold  (2  - state)  model  and \n",
      "- state)  were  compared  at  varying  temperatures \n",
      "smooth  sigmoidal  activation  (  00 \n",
      "In  each  simulation  a  totally \n",
      "with  a  restricted  dynamic  range  for  the  weights  Tij • \n",
      "interconnected  64  node  network  attempted  to  learn  32  random  patterns  using  the \n",
      "delta  rule  learning  algorithm  (see  for  example  [14]).  Each  pattern  was  then  cor(cid:173)\n",
      "rupted  with  25%  noise  and  recall  attempted  to  probe  the  content  addressable \n",
      "memory properties under the three different activation options. \n",
      "During  learning,  individual  weights  can  become  large  (positive  or  negative).  When \n",
      "weights  are  \"driven\"  beyond  the  maximum  value  in  a  hardware  implementation, \n",
      "\n",
      "\f579 \n",
      "\n",
      "which  is  determined  by  the  size  of  the  synaptic  weight  blocks,  some  limiting \n",
      "mechanism  must  be  introduced.  For  example,  with  eight  bit  weight  registers,  the \n",
      "limitation is  -128  S  Tij  S  127.  With integer weights,  this can be seen to be a prob(cid:173)\n",
      "lem  of  dynamic  range,  where  it  is  the  relationship  between  the  smallest  possible \n",
      "weight  (± 1) and the largest  (+ 127/-128) that is the issue. \n",
      "Results:  Fig.  6  shows  examples  of the  results  obtained,  studying  learning  using  5  -\n",
      "state  activation  at  different  temperatures,  and  recall  using  both  5  - state  and  thres(cid:173)\n",
      "hold  activation.  At  temperature  T=O,  the  5  - state  and  threshold  models  are \n",
      "degenerate,  and  the results identical.  Increasing smoothness of activation  (tempera(cid:173)\n",
      "ture)  during  learning  improves  the  quality  of  learning  regardless  of  the  activation \n",
      "function  used  in  recall,  as more patterns are recognised  successfully.  Using 5 - state \n",
      "activation  in recall  is more effective  than simple  threshold  activation.  The effect of \n",
      "dynamic  range  restrictions  can  be  assessed  from  the  horizontal  axis,  where  T/j:6.  is \n",
      "shown.  The results  from  these and  many  other experiments may  be  summarised  as \n",
      "follows:-\n",
      "5 - State activation  vs.  threshold: \n",
      "1)  Learning with 5  - state activation was  protracted  over the threshold  activation, \n",
      "as  binary  patterns  were  being  learnt,  and  the  inclusion  of  intermediate  values \n",
      "added extra degrees of freedom. \n",
      "\n",
      "2)  Weight  sets  learnt  using  the  5  - state  activation  function  were  \"better\"  than \n",
      "those  learnt  via  threshold  activation,  as  the  recall  properties  of both  5  - state \n",
      "and  threshold  networks  using  such  a  weight  set  were  more  robust  against \n",
      "noise. \n",
      "Full  sigmoidal  activation  was  better  than  5  - state,  but  the  enhancement  was \n",
      "less  significant  than  that  incurred  by  moving  from  threshold  - 5 - state.  This \n",
      "suggests  that the law  of diminishing returns  applies to  addition of levels to the \n",
      "neural  state  Vi'  This  issue  has  been  studied  mathematically  [15],  with  results \n",
      "that agree  qualitatively with  ours. \n",
      "\n",
      "3) \n",
      "\n",
      "Weight Saturation: \n",
      "Three  methods  were  tried  to  deal  with  weight  saturation.  Firstly,  inclusion  of  a \n",
      "decay,  or  \"forgetting\"  term  was  included  in  the  learning  cycle  [1].  It  is  our  view \n",
      "that  this  technique can  produce the desired weight limiting property,  but in  the time \n",
      "available  for  experiments,  we  were  unable  to  \"tune\"  the  rate  of  decay  sufficiently \n",
      "well  to  confirm  it.  Renormalisation  of the  weights  (division  to  bring large  weights \n",
      "back  into  the  dynamic  range)  was  very  unsuccessful,  suggesting  that  information \n",
      "distributed  throughout  the  numerically small  weights  was  being  destroyed.  Finally, \n",
      "the  weights were  allowed  to  \"clip\"  (ie any weight  outside the dynamic range  was  set \n",
      "to  the  maximum  allowed  value).  This method  proved  very  successful,  as  the learn(cid:173)\n",
      "ing  algorithm  adjusted the weights  over which  it still  had control  to  compensate for \n",
      "the  saturation effect.  It is  interesting to note  that  other experiments have indicated \n",
      "that  Hopfield  nets  can  \"forget\"  in a  different  way,  under different learning control, \n",
      "giving  preference  to  recently acquired  memories [16].  The results  from  the  satura(cid:173)\n",
      "tion experiments were:-\n",
      "1) \n",
      "\n",
      "For  the  32  pattemJ64  node  problem,  integer  weights  with  a  dynamic  range \n",
      "greater than  ±30 were necessary to give enough  storage capability. \n",
      "For weights  with  maximum  values  TiJ  = 50-70,  \"clipping\"  occurs,  but  net(cid:173)\n",
      "work  performance  is  not  seriously  degraded  over  that  with  an  unrestricted \n",
      "weight set. \n",
      "\n",
      "2) \n",
      "\n",
      "\f580 \n",
      "\n",
      "15 \n",
      "\n",
      "\"0  10 \n",
      "c = \n",
      ".2 \n",
      "en e u \n",
      "5 --~ \n",
      "\n",
      "0 \n",
      "\n",
      "0 \n",
      "\n",
      "I \n",
      "\n",
      "\".' \n",
      "\n",
      "., ... \n",
      "\n",
      ".... ----------\n",
      "\n",
      ",-\n",
      "e  ~ ;A ....... ;.. f:'-:' :::::7.:::.::-:::-: f'-. \n",
      ",  ,. \n",
      "i \n",
      "! \n",
      "! , \n",
      "i \n",
      "I \n",
      "I , \n",
      "\n",
      "20  30 \n",
      "\n",
      "40  50  60  70 \n",
      "\n",
      "Limit \n",
      "\n",
      "15 \n",
      "\n",
      "T=30  _._.-.-\n",
      "T=20 \n",
      "T=10 \n",
      "T=O \n",
      "\n",
      "-.-._.-.. \n",
      "\n",
      ",.. .•. -..... -.•. _ .•. \n",
      ", \n",
      ".. \n",
      "i \n",
      "j''''--\n",
      ",,'i \n",
      "\n",
      "- . . .,. '\" \n",
      "\n",
      "j \n",
      "\n",
      "~-------------\n",
      "••••••• •••••••••••••••• •••••• \n",
      "\n",
      "j \n",
      "I \n",
      "\n",
      "O~~~~--~~ __ ~~ __ \n",
      "o \n",
      "\n",
      "20  30  40  50  60  70 \n",
      "\n",
      "Limit \n",
      "\n",
      "5 . state activation function  recal1 \n",
      "\n",
      "tlHopficld\" activation  function  recall \n",
      "\n",
      "Figure 6.  Recall  of patterns  learned  with  the  5  .  state  activation function  and  subse(cid:173)\n",
      "quently restored using  the 5-state and the  hard - threshold activation functions. \n",
      "T  is  the  \"temperature\",  or smoothness  of the  activation function,  and \"limit\"  the  value \n",
      "ofTI; ·  \n",
      "\n",
      "These  results  showed  that  the  5  - state  model  was  worthy  of implementation  as  a \n",
      "VLSI neural board, and suggested that 8 - bit weights were sufficient. \n",
      "\n",
      "S.  PROJECTED SPECIFICATION OF A HARDWARE NEURAL  BOARD \n",
      "\n",
      "The specification of a  64  neuron board is  given  here,  using a  5 - state bit  - serial 64 \n",
      "x 64  synapse array with  a derated clock speed  of 20 MHz.  The synaptic weights are \n",
      "8  bit words and the word  length  of the running summation XI  is  16  bits to  allow for \n",
      "growth.  A  64  synapse  column  has  a  computational  latency  of  80  clock  cycles  or \n",
      "bits,  giving  an  update  time  of 4 .... s  for  the  network.  The  time  to  load  the  weights \n",
      "into  the  array  is  limited  to  6O .... s  by  the  supporting  RAM,  with  an  access  time  of \n",
      "12Ons.  These  load  and  update  times  mean  that  the  network  is  executing  1  x  10' \n",
      "operations/second,  where  one  operation  is  ±  Tlj  Vj •  This  is  much  faster  than  a \n",
      "natural  neural  network,  and  much  faster  than  is  necessary  in  a  hardware  accelera(cid:173)\n",
      "tor.  We  have  therefore  developed  a  \"paging\"  architecture,  that  effectively  \"trades -\n",
      "off\" some of this excessive speed against increased network size. \n",
      "A  \"moving  - patch\"  neural  board:  An  array  of  the  5  - state  synapses  is  currently \n",
      "being  fabricated  as  a  VLSI  integrated  circuit.  The  shift  registers  and \n",
      "the \n",
      "adderlsubtractor for  each  synapse  occupy a  disappointingly large silicon  area,  allow(cid:173)\n",
      "ing only a  3  x 9 synaptic  array.  To achieve  a  suitable size  neural  network  from  this \n",
      "array,  several chips need to be  included on a  board with  memory and control circu(cid:173)\n",
      "itry.  The  \"moving  patch\"  concept  is  shown  in  figure  7,  where  a  small  array  of \n",
      "synapses is passed over a much larger n  x n  synaptic array. \n",
      "Each  time  the  array  is  \"moved\"  to  represent  another set  of  synapses,  new  weights \n",
      "must be  loaded  into it.  For example,  the  first  set of weights will  be T 11  •. ,  T;J  ... T 21 \n",
      "...  T 2j  to Tjj ,  the second  set  Tj + 1,l  to T u  etc..  The final  weight  to be loaded will  be \n",
      "\n",
      "\f581 \n",
      "\n",
      "n  neurons .. om synaptic array \n",
      "\n",
      "Smaller \"Patch\" \n",
      "\n",
      "moves over array \n",
      "\n",
      "rr~ _____ ) __ -.. \n",
      "> \n",
      "~'-\n",
      "\n",
      "Figure 7.  The  \"moving  patch\" concept,  passing  a  small synaptic \"patch\"  over  a larger \n",
      "run synapse array. \n",
      "\n",
      "TNt·  Static,  off - the  - shelf RAM is  used  to store the weights and the  whole opera(cid:173)\n",
      "tion  is  pipelined for  maximum efficiency.  Figure 8 shows the board level design for \n",
      "the network. \n",
      "\n",
      "Synaptic  Accelerator Chips \n",
      "\n",
      "Control \n",
      "\n",
      "HOST \n",
      "Figure 8. A  \"moving  patch\" neural network board. \n",
      "\n",
      "The small  \"patch\" that moves  around  the array  to  give  n  neurons comprises 4 VLSI \n",
      "synaptic accelerator chips to give  a 6 x 18 synaptic array. The number of neurons to \n",
      "be  simulated  is 256  and  the weights for  these  are stored  in 0.5  Mb of RAM  with a \n",
      "load  time  of 8ms.  For  each  \"patch\"  movement,  the  partial  runnin~ summatinn \n",
      "\n",
      ";. \n",
      "\n",
      "\f582 \n",
      "\n",
      "calculated  for  each  column,  is  stored  in  a  separate  RAM  until  it is  required  to  be \n",
      "added  into  the  next  appropriate  summation.  The  update  time  for  the  board  is  3ms \n",
      "giving  2  x  107  operations/second.  This  is  slower  than  the  64  neuron  specification, \n",
      "but  the  network  is  16  times  larger,  as  the  arithmetic  elements are  being  used  more \n",
      "efficiently.  To  achieve  a  network  of  greater  than  256  neurons,  more  RAM  is \n",
      "required to store the weights.  The network is then slower unless a larger number of \n",
      "accelerator chips is  used  to give  a larger moving \"patch\". \n",
      "\n",
      "6.  CONCLUSIONS \n",
      "\n",
      "A  strategy  and  design  method  has  been  given  for  the  construction  of  bit  - serial \n",
      "VLSI neural network chips and  circuit  boards.  Bit - serial  arithmetic,  coupled  to  a \n",
      "reduced  arithmetic  style,  enhances  the  level  of  integration  possible  beyond  more \n",
      "conventional digital,  bit - parallel schemes.  The restrictions imposed  on both synap(cid:173)\n",
      "tic  weight  size  and  arithmetic  precision  by  VLSI  constraints  have  been  examined \n",
      "and shown to be tolerable,  using the associative memory problem as a test. \n",
      "While  we  believe  our  digital  approach  to  represent  a  good  compromise  between \n",
      "arithmetic  accuracy  and  circuit  complexity,  we  acknowledge  that  the  level  of \n",
      "integration  is  disappointingly  low. \n",
      "It  is  our  belief  that,  while  digital  approaches \n",
      "may  be interesting and  useful  in the medium  term,  essentially as  hardware accelera(cid:173)\n",
      "tors for  neural simulations,  analog techniques represent the best  ultimate option in 2 \n",
      "- dimensional  silicon.  To this  end,  we  are currently pursuing techniques for  analog \n",
      "In any  event,  the  full \n",
      "pseudo  - static  memory,  using  standard  CMOS  technology. \n",
      "development  of a  nonvolatile  analog  memory  technology,  such  as  the  MNOS  tech(cid:173)\n",
      "nique [7],  is key to the long - term  future of VLSI neural nets that can learn. \n",
      "\n",
      "7. ACKNOWLEDGEMENTS \n",
      "\n",
      "The  authors  acknowledge  the  support  of  the  Science  and  Engineering  Research \n",
      "Council (UK) in the execution of this work. \n",
      "\n",
      "References \n",
      "\n",
      "1. \n",
      "\n",
      "S.  Grossberg,  \"Some  Physiological  and  Biochemical  Consequences  of Psycho(cid:173)\n",
      "logical Postulates,\" Proc.  Natl.  Acad.  Sci.  USA,  vol.  60,  pp.  758  - 765,  1968. \n",
      "\n",
      "2.  H.  P.  Graf,  L.  D.  Jackel,  R.  E.  Howard,  B.  Straughn,  J.  S.  Denker,  W. \n",
      "Hubbard,  D.  M.  Tennant,  and  D.  Schwartz,  \"VLSI  Implementation  of  a \n",
      "Neural  Network  Memory  with  Several  Hundreds  of  Neurons,\"  Proc.  AlP \n",
      "Conference on Neural Networks for  Computing.  Snowbird,  pp.  182 - 187,  1986. \n",
      "3.  W.  S.  Mackie,  H.  P.  Graf,  and  J.  S.  Denker,  \"Microelectronic  Implementa(cid:173)\n",
      "\n",
      "tion  of  Connectionist  Neural  Network  Models,\"  IEEE  Conference  on  Neural \n",
      "Information Processing Systems.  Denver,  1987. \n",
      "J . J. Hopfield  and D.  W.  Tank, \"Neural\" Computation of Decisions in  Optim(cid:173)\n",
      "isation Problems,\" BioI.  Cybern.,  vol.  52,  pp.  141  - 152,  1985. \n",
      "\n",
      "4. \n",
      "\n",
      "5.  M.  A.  Sivilotti,  M.  A.  Mahowald,  and  C.  A.  Mead, Real - Time  Visual Com(cid:173)\n",
      "\n",
      "putations Using  Analog CMOS  Processing Arrays, 1987.  To be published \n",
      "\n",
      "6.  C.  A.  Mead,  \"Networks  for  Real  - Time  Sensory  Processing,\"  IEEE  Confer(cid:173)\n",
      "\n",
      "ence  on  Neural Information  Processing Systems,  Denver,  1987. \n",
      "\n",
      "\f583 \n",
      "\n",
      "7. \n",
      "\n",
      "8. \n",
      "\n",
      "J.  P.  Sage,  K.  Thompson.  and  R. S.  Withers,  \"An Artificial Neural  Network \n",
      "Integrated  Circuit  Based on MNOSlCCD  Principles,\"  Proc. AlP Conference on \n",
      "Neural Networlcs for Computing,  Snowbird,  pp.  381  - 385,  1986. \n",
      "S.  C.  J.  Garth, \"A Chipset for  High Speed  Simulation of Neural Network  Sys(cid:173)\n",
      "tems,\"  IEEE Conference on Neural Networlc.s,  San Diego,  1987. \n",
      "\n",
      "9.  A.  F.  Murray and  A.  V.  W.  Smith,  \"A Novel  Computational  and  Signalling \n",
      "Method  for  VLSI Neural Networks,\"  European  Solid State Circuits Conference \n",
      ", 1987. \n",
      "\n",
      "10.  A.  F.  Murray  and  A.  J.  W.  Smith,  \"Asynchronous  Arithmetic  for  VLSI \n",
      "\n",
      "Neural Systems,\"  Electronics Letters, vol.  23, no.  12, p.  642, June, 1987. \n",
      "\n",
      "11.  A.  F.  Murray  and  A.  V.  W.  Smith,  \"Asynchronous  VLSI  Neural  Networks \n",
      "\n",
      "using  Pulse  Stream  Arithmetic,\"  IEEE  Journal  of Solid-State  Circuits  and Sys(cid:173)\n",
      "tems,  1988.  To be published \n",
      "\n",
      "12.  M.  E.  Gaspar,  \"Pulsed  Neural  Networks:  Hardware,  Software  and  the  Hop(cid:173)\n",
      "field  AID  Converter  Example,\"  IEEE  Conference  on  Neural  Information  Pro(cid:173)\n",
      "cessing Systems.  Denver,  1987. \n",
      "\n",
      "13.  M.  S.  McGregor,  P.  B.  Denyer,  and A.  F.  Murray,  \"A Single - Phase  Clock(cid:173)\n",
      "ing Scheme for  CMOS  VLSI,\"  Advanced Research  in  VLSI  \" Proceedings of the \n",
      "1987 Stanford Conference,  1987. \n",
      "\n",
      "14.  D.  E.  Rumelhart,  G.  E.  Hinton,  and  R.  J.  Williams,  \"Learning  Internal \n",
      "Representations  by  Error  Propagation,\"  Parallel  Distributed  Processing  \" \n",
      "Explorations  in  the  Microstructure of Cognition,  vol.  1,  pp.  318 - 362,  1986. \n",
      "\n",
      "15.  M.  Fleisher  and  E.  Levin,  \"The  Hopfiled  Model  with  Multilevel  Neurons \n",
      "Models,\"  IEEE  Conference  on  Neural  Information  Processing  Systems.  Denver, \n",
      "1987. \n",
      "\n",
      "16.  G.  Parisi,  \"A  Memory  that  Forgets,\"  J.  Phys.  A  .'  Math.  Gen.,  vol.  19,  pp. \n",
      "\n",
      "L617  - L620,  1986. \n",
      "\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "# Now let's take at the first paper in our dataset - one from 1987. This paper's plaintext was provided by\n",
    "# the NeurIPS website directly.\n",
    "\n",
    "print(papers.loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the formatting is slightly different from the PDF-converted papers. There is a bit more whitespace, and page numbers are present. Outside of that, the same challenges regarding images and equations are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilistic Inference of Hand Motion from Neural\n",
      "\n",
      "Activity in Motor Cortex\n",
      "\n",
      "Y. Gao M. J. Black\u0001\n",
      "\n",
      "E. Bienenstock\u0003\u0002\n",
      "\n",
      "S. Shoham\u0004\n",
      "\n",
      "J. P. Donoghue\u0002\n",
      "\n",
      " Division of Applied Mathematics, Brown University, Providence, RI 02912\n",
      "\n",
      "\u0001 Dept. of Computer Science, Brown University, Box 1910, Providence, RI 02912\n",
      "\n",
      "\u0004 Princeton University, Dept. of Molecular Biology Princeton, NJ, 08544\n",
      "\n",
      "\u0002 Dept. of Neuroscience, Brown University, Providence, RI 02912\n",
      "\n",
      "gao@cfm.brown.edu, black@cs.brown.edu, elie@dam.brown.edu,\n",
      "\n",
      "sshoham@princeton.com, john donoghue@brown.edu\n",
      "\n",
      "Abstract\n",
      "\n",
      "Statistical learning and probabilistic inference techniques are used to in-\n",
      "fer the hand position of a subject from multi-electrode recordings of neu-\n",
      "ral activity in motor cortex. First, an array of electrodes provides train-\n",
      "ing data of neural ﬁring conditioned on hand kinematics. We learn a non-\n",
      "parametric representation of this ﬁring activity using a Bayesian model\n",
      "and rigorously compare it with previous models using cross-validation.\n",
      "Second, we infer a posterior probability distribution over hand motion\n",
      "conditioned on a sequence of neural test data using Bayesian inference.\n",
      "The learned ﬁring models of multiple cells are used to deﬁne a non-\n",
      "Gaussian likelihood term which is combined with a prior probability for\n",
      "the kinematics. A particle ﬁltering method is used to represent, update,\n",
      "and propagate the posterior distribution over time. The approach is com-\n",
      "pared with traditional linear ﬁltering methods; the results suggest that it\n",
      "may be appropriate for neural prosthetic applications.\n",
      "\n",
      "1 Introduction\n",
      "\n",
      "This paper explores the use of statistical learning methods and probabilistic inference tech-\n",
      "niques for modeling the relationship between the motion of a monkey’s arm and neural\n",
      "activity in motor cortex. Our goals are threefold: (i) to investigate the nature of encoding\n",
      "in motor cortex, (ii) to characterize the probabilistic relationship between arm kinematics\n",
      "(hand position or velocity) and activity of a simultaneously recorded neural population, and\n",
      "(iii) to optimally reconstruct (decode) hand trajectory from population activity to smoothly\n",
      "control a prosthetic robot arm (cf [14]).\n",
      "\n",
      "A multi-electrode array (Figure 1) is used to simultaneously record the activity of 24 neu-\n",
      "rons in the arm area of primary motor cortex (MI) in awake, behaving, macaque monkeys.\n",
      "This activity is recorded while the monkeys manually track a smoothly and randomly mov-\n",
      "\n",
      "\f\u0004\u0006\u0005\n",
      "\n",
      "\u0012\u0014\u0013\n",
      "\u0015\u0017\u0016\n",
      "\n",
      "\u001e\u0017\u001f\n",
      "\u0018\u001a\u0019\u001b\u0019\n",
      "\n",
      "C.\n",
      "\n",
      "Acrylic\n",
      "\n",
      "Connector\n",
      "\n",
      "Silicone\n",
      "\n",
      "Bone\n",
      "\n",
      "!\u0006\"\n",
      "\n",
      "White Matter\n",
      "\n",
      ",.-0/\u001b1\n",
      "\n",
      "564\n",
      "\n",
      "Figure 1: Multi-electrode array. A. 10X10 matrix of electrodes. Separation 4007 m (size\n",
      "4X4 mm). B. Location of array in the MI arm area. C. Illustration of implanted array\n",
      "(courtesy N. Hatsopoulos).\n",
      "\n",
      "ing visual target on a computer monitor [12]. Statistical learning methods are used to derive\n",
      "Bayesian estimates of the conditional probability of ﬁring for each cell given the kine-\n",
      "matic variables (we consider only hand velocity here). Speciﬁcally, we use non-parametric\n",
      "models of the conditional ﬁring, learned using regularization (smoothing) techniques with\n",
      "cross-validation. Our results suggest that the cells encode information about the position\n",
      "and velocity of the hand in space. Moreover, the non-parametric models provide a better\n",
      "explanation of the data than previous parametric models [6, 10] and provide new insight\n",
      "into neural coding in MI.\n",
      "\n",
      "Decoding involves the inference of the hand motion from the ﬁring rate of the cells. In par-\n",
      "ticular, we represent the posterior probability of the entire hand trajectory conditioned on\n",
      "the observed sequence of neural activity (spike trains). The nature of this activity results in\n",
      "ambiguities and a non-Gaussian posterior probability distribution. Consequently, we repre-\n",
      "sent the posterior non-parametrically using a discrete set of samples [8]. This distribution\n",
      "is predicted and updated in non-overlapping 50 ms time intervals using a Bayesian estima-\n",
      "tion method called particle ﬁltering [8]. Experiments with real and synthetic data suggest\n",
      "that this approach provides probabilistically sound estimates of kinematics and allows the\n",
      "probabilistic combination of information from multiple neurons, the use of priors, and the\n",
      "rigorous evaluation of models and results.\n",
      "\n",
      "2 Methods: Neural Recording\n",
      "\n",
      "The design of the experiment and data collection is described in detail in [12]. Summa-\n",
      "rizing, a ten-by-ten array of electrodes is implanted in the primary motor cortex (MI) of\n",
      "a Macaque monkey (Figure 1) [7, 9, 12]. Neural activity in motor cortex has been shown\n",
      "to be related to the movement kinematics of the animal’s arm and, in particular, to the\n",
      "direction of hand motion [3, 6]. Previous behavioral tasks have involved reaching in one\n",
      "of a ﬁxed number of directions [3, 6, 14]. To model the relationship between continuous,\n",
      "smooth, hand motion and neural activity, we use a more complex scenario where the mon-\n",
      "key performs a continuous tracking task in which the hand is moved on a 2D tablet while\n",
      "holding a low-friction manipulandum that controls the motion of a feedback dot viewed on\n",
      "a computer monitor (Figure 2a) [12]. The monkey receives a reward upon completion of\n",
      "a successful trial in which the manipulandum is moved to keep the feedback dot within a\n",
      "pre-speciﬁed distance of the target. The path of the target is chosen to be a smooth random\n",
      "walk that effectively samples the space of hand positions and velocities: measured hand\n",
      "positions and velocities have a roughly Gaussian distribution (Figure 2b and c) [12]. Neu-\n",
      "ral activity is ampliﬁed, waveforms are thresholded, and spike sorting is performed off-line\n",
      "to isolate the activity of individual cells [9]. Recordings from 24 motor cortical cells are\n",
      "measured simultaneously with hand kinematics.\n",
      "\n",
      "\n",
      "\u0001\n",
      "\u0002\n",
      "\u0003\n",
      "\u0007\n",
      "\b\n",
      "\t\n",
      "\n",
      "\u000b\n",
      "\f\n",
      "\n",
      "\u000b\n",
      "\u000e\n",
      "\n",
      "\u000f\n",
      "\u0010\n",
      "\t\n",
      "\u000e\n",
      "\n",
      "\b\n",
      "\u0005\n",
      "\f\n",
      "\u0011\n",
      "\u0010\n",
      "\u001c\n",
      "\u001d\n",
      " \n",
      "!\n",
      "#\n",
      "$\n",
      "%\n",
      "&\n",
      "'\n",
      "(\n",
      ")\n",
      ")\n",
      "*\n",
      "+\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "\fMonitor\n",
      "\n",
      "Target\n",
      "\n",
      "Tablet\n",
      "\n",
      "Trajectory\n",
      "\n",
      "Manipulandum\n",
      "\n",
      "a\n",
      "\n",
      "25\n",
      "\n",
      "20\n",
      "\n",
      "15\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "0\n",
      "\n",
      "b\n",
      "\n",
      "c\n",
      "\n",
      "16\n",
      "\n",
      "14\n",
      "\n",
      "12\n",
      "\n",
      "10\n",
      "\n",
      "8\n",
      "\n",
      "6\n",
      "\n",
      "4\n",
      "\n",
      "2\n",
      "\n",
      "0\n",
      "\n",
      "Figure 2: Smooth tracking task. (a) The target moves with a smooth random walk. Distri-\n",
      "bution of the position (b) and velocity (c) of the hand. Color coding indicates the frequency\n",
      "with which different parts of the space are visited. (b) Position: horizontal and vertical\n",
      "\n",
      "axes represent  and \u0001 position of the hand. (c) Velocity: the horizontal axis represents\n",
      "direction, \u0002\u0004\u0003\u0006\u0007\n",
      "\t\u000b\u0003\n",
      "\n",
      ", and the vertical axis represents speed, \f .\n",
      "\n",
      "3\n",
      "\n",
      "\u0011\u0013\u0012\n",
      "\n",
      "\u000f\u000e\n",
      "\n",
      "\u001bcell 3\n",
      "\n",
      "cell 16\n",
      "\n",
      "cell 19\n",
      "\n",
      "2.5\n",
      "\n",
      "2\n",
      "\n",
      "1.5\n",
      "\n",
      "1\n",
      "\n",
      "0.5\n",
      "\n",
      "0\n",
      "\n",
      "Figure 3: Observed mean conditional ﬁring rates in 50 ms intervals for three cells given\n",
      "hand velocity. The horizontal axis represents the direction of movement,\n",
      "\n",
      "0 cm/s to 12 cm/s. Color ranges from dark blue (no measurement) to red (approximately 3\n",
      "spikes).\n",
      "\n",
      "\u0007 , in radians\n",
      "to\u0003 ). The vertical axis represents speed, \f , and ranges from\n",
      "\n",
      "(“wrapping” around from \u0002\u0004\u0003\n",
      "\n",
      "3 Modeling Neural Activity\n",
      "\n",
      "Figure 3 shows the measured mean ﬁring rate within 50 ms time intervals for three cells\n",
      "conditioned on the subject’s hand velocity. We view the neural ﬁring activity in Figure 3\n",
      "as a stochastic and sparse realization of some underlying model that relates neural ﬁring\n",
      "to hand motion. Similar plots are obtained as a function of hand position. Each plot can\n",
      "be thought of as a type of “tuning function” [12] that characterizes the response of the cell\n",
      "conditioned on hand velocity.\n",
      "In previous work, authors have considered a variety of\n",
      "models of this data including a cosine tuning function [6] and a modiﬁed cosine function\n",
      "[10]. Here we explore a non-parametric model of the underling activity and, adopting a\n",
      "Bayesian formulation, seek a maximum a posterior (MAP) estimate of a cell’s conditional\n",
      "ﬁring.\n",
      "\n",
      "Adopting a Markov Random Field (MRF) assumption [4], let the velocity space,\n",
      "\n",
      "\u001c\u001e\u001d\n",
      ", be discretized on a &(')'\n",
      "*+&(')' grid. Let g be the array of true (unobserved) condi-\n",
      "\f! \"\u0007!#%$\n",
      "tional neural ﬁring and , be the corresponding observed mean ﬁring. We seek the posterior\n",
      "\n",
      "probability\n",
      "\n",
      "(1)\n",
      "\n",
      "-/. g 01,123\u001d5476\n",
      "\n",
      ".98:-/.9;\n",
      "\n",
      "-/.\n",
      "\n",
      "6<0>=?6@2A4CB\n",
      "\n",
      "DFE/G\n",
      "\n",
      "=?6<0H=?6?IJ2K2\n",
      "\n",
      "\u000e\n",
      "\u0010\n",
      "\u0014\n",
      "\u0015\n",
      "\u0016\n",
      "\u0017\n",
      "\u0018\n",
      "\u0019\n",
      "\u001a\n",
      "\u001f\n",
      "\f0.18\n",
      "\n",
      "0.16\n",
      "\n",
      "0.14\n",
      "\n",
      "0.12\n",
      "\n",
      "0.1\n",
      "\n",
      "0.08\n",
      "\n",
      "0.06\n",
      "\n",
      "0.04\n",
      "\n",
      "0.02\n",
      "\n",
      "0\n",
      "\n",
      "−2\n",
      "\n",
      "−4\n",
      "\n",
      "−6\n",
      "\n",
      "−8\n",
      "\n",
      "−10\n",
      "\n",
      "0\n",
      "−3\n",
      "\n",
      "−2\n",
      "\n",
      "−1\n",
      "\n",
      "0\n",
      "\n",
      "a\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "−12\n",
      "−3\n",
      "\n",
      "−2\n",
      "\n",
      "−1\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "b\n",
      "\n",
      "'\u0003\u0002\u0005\u0004\u0007\u0006 .\n",
      "\n",
      ":\n",
      "\n",
      ".9;\n",
      "\n",
      "0H=\n",
      "\n",
      "0>=\n",
      "\n",
      ";\u000f\u000e\n",
      "\n",
      "\u0010\u0012\u0011\u0012\u0013\u0015\u0014\n",
      "\n",
      "respectively, =\n",
      "\n",
      "6 and =\n",
      "\n",
      "6 are the observed and true\n",
      "\n",
      "th neighboring\n",
      "\n",
      "= ). (a) Probability of ﬁring variation com-\n",
      "\n",
      "The ﬁrst term on the right hand side represents the likelihood of observing a particular ﬁring\n",
      ". Here we compare two generative models of the neural\n",
      "\n",
      "(b) Logarithm of the distributions shown to provide detail.\n",
      "\n",
      "is a normalizing constant independent of g, ;\n",
      "\n",
      "where 8\n",
      "mean ﬁring at velocity \u001c\n",
      "velocity of \u001c\n",
      "rate ;\n",
      "spiking process within 50 ms; a Poisson model,-\n",
      "\n",
      "Figure 4: Prior probability of ﬁring variation (\n",
      "puted from training data (blue). Proposed robust prior model (red) plotted for\u0001\n",
      "I represents the ﬁring rate for th\n",
      ", and the neighbors are taken to be the four nearest velocities (\t\n",
      "\u001d\u000b\n",
      " ).\n",
      "\u0002\u0006=A2 \u001f\n",
      "\u0004\u0012\u0001\n",
      "\n",
      "6 given that the true rate is =\u000f6\n",
      "\n",
      ", and a Gaussian model,-\n",
      "\n",
      ",\n",
      "the variation of neural activity in velocity space. The MRF prior states that the ﬁring,\n",
      "\n",
      "corresponds to an assumption that the ﬁring rate varies smoothly. A robust prior assumes\n",
      ", (derivatives of the\n",
      "\n",
      ", at velocity \u001c depends only on the ﬁring at neighboring velocities. We consider two\n",
      "= : Gaussian and “robust”. A Gaussian prior\n",
      "ﬁring rate in the \f and \u0007 directions) and implies piecewise smooth data. The two spatial\n",
      "\n",
      "The second term is a spatial prior probability that encodes our expectations about\n",
      "possible prior models for the distribution of\n",
      "a heavy-tailed distribution of the spatial variation (see Figure 4),\n",
      "\u0004?\u0003\u0017\u0001\u0019\u0018\u001b\u001a\u001d\u001c\n",
      "\n",
      "sian+Gaussian, and Poisson+Robust) are ﬁt to the training data as shown in Figure 5.G\n",
      "\n",
      "The various models (cosine, a modiﬁed cosine (Moran and Schwartz [10]), Gaus-\n",
      "\n",
      "In the case of the Gaussian+Gaussian and Poisson+Robust models, the optimal value of\n",
      "\n",
      "\u0004?\u0003\u0017\u0001\u0019\u0018\u001b\u001a\u001d\u001c\n",
      "\n",
      "2(\u001f\n",
      "\u001f)!\n",
      "\n",
      "\u0004\u0012\u0001\n",
      "\n",
      "=?6\n",
      "\n",
      "priors are\n",
      "\n",
      "\u0004\u0007\u0001%$\n",
      "\u001f'&\n",
      "\n",
      "-#\"\n",
      "\n",
      "the\u0001 parameter is computed for each cell using cross validation. During cross-validation,\n",
      "\n",
      "each time 10 trials out of 180 are left out for testing and the models are ﬁt with the remain-\n",
      "ing training data. We then compute the log likelihood of the test data given the model. This\n",
      "provides a measure of how well the model captures the statistical variation in the training\n",
      "set and is used for quantitative comparison. The whole procedure is repeated 18 times for\n",
      "different test data sets.\n",
      "\n",
      "The solution to the Gaussian+Gaussian model can be computed in closed form but for\n",
      "the Poisson+Robust model no closed form solution for g exists and an optimal Bayesian\n",
      "estimate could be achieved with simulated annealing [4]. Instead, we derive an approximate\n",
      "\n",
      "“Poisson+Robust” implies a Poisson likelihood and robust spatial prior.\n",
      "\n",
      "* By “Gaussian+Gaussian” we mean both the likelihood and prior terms are Gaussian whereas\n",
      "\n",
      "\u001d\n",
      "6\n",
      "\f\n",
      "\n",
      "-\n",
      "\f\n",
      ".\n",
      ";\n",
      "2\n",
      "\u001d\n",
      "&\n",
      "=\n",
      " \n",
      "-\n",
      "\n",
      "2\n",
      "\u001d\n",
      "&\n",
      "\u0016\n",
      "\u001e\n",
      "\u0002\n",
      ".\n",
      ";\n",
      "\u001f\n",
      "!\n",
      "\u0002\n",
      "=\n",
      "=\n",
      ".\n",
      "\n",
      "=\n",
      "2\n",
      "\u001d\n",
      "\u0003\n",
      ".\n",
      "\u0001\n",
      "\n",
      "=\n",
      "\u001f\n",
      "2\n",
      "\u001f\n",
      " \n",
      "-\n",
      "\n",
      ".\n",
      "\n",
      "=\n",
      "2\n",
      "\u001d\n",
      "&\n",
      "\u0016\n",
      "\u001e\n",
      "\u0002\n",
      ".\n",
      "\n",
      "=\n",
      "\u0002\n",
      "\f1.2\n",
      "1\n",
      "0.8\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "1.2(cid:13)\n",
      "1(cid:13)\n",
      "0.8(cid:13)\n",
      "0.6(cid:13)\n",
      "0.4(cid:13)\n",
      "0.2(cid:13)\n",
      "0.8(cid:13)\n",
      "\n",
      "0.6(cid:13)\n",
      "\n",
      "0.4(cid:13)\n",
      "\n",
      "0.7\n",
      "\n",
      "0.5\n",
      "\n",
      "0.3\n",
      "\n",
      "1.5(cid:13)\n",
      "\n",
      "1(cid:13)\n",
      "\n",
      "0.5(cid:13)\n",
      "\n",
      "1.5(cid:13)\n",
      "\n",
      "1(cid:13)\n",
      "\n",
      "0.5(cid:13)\n",
      "\n",
      "0.9(cid:13)\n",
      "\n",
      "0.8(cid:13)\n",
      "\n",
      "0.7(cid:13)\n",
      "\n",
      "1\n",
      "\n",
      "0.8\n",
      "\n",
      "0.6\n",
      "\n",
      "1(cid:13)\n",
      "\n",
      "0.5(cid:13)\n",
      "\n",
      "0.8(cid:13)\n",
      "0.6(cid:13)\n",
      "0.4(cid:13)\n",
      "0.2(cid:13)\n",
      "\n",
      "0.75(cid:13)\n",
      "0.7(cid:13)\n",
      "0.65(cid:13)\n",
      "\n",
      "0.8\n",
      "0.7\n",
      "0.6\n",
      "0.5\n",
      "\n",
      "Cosine\n",
      "\n",
      "Moran&Schwartz\n",
      "(M&S)\n",
      "\n",
      "Gaussian+Gaussian\n",
      "\n",
      "Poisson+Robust\n",
      "\n",
      "cell 3\n",
      "\n",
      "cell 16\n",
      "\n",
      "cell 19\n",
      "\n",
      "Figure 5: Estimated ﬁring rate for cells in Figure 3 using different models.\n",
      "\n",
      "Method:\n",
      "G+G over Cosine\n",
      "G+G over M&S\n",
      "P+R over Cosine\n",
      "P+R over M&S\n",
      "\n",
      "Log Likelihood Ratio\n",
      "\n",
      "p-value\n",
      "\n",
      "24.9181\n",
      "15.8333\n",
      "50.0685\n",
      "32.2218\n",
      "\n",
      "7.6294e-06\n",
      "\n",
      "0.0047\n",
      "\n",
      "7.6294e-06\n",
      "7.6294e-06\n",
      "\n",
      "Table 1: Numerical comparison; log likelihood ratio of pairs of models and the signiﬁcance\n",
      "level given by Wilcoxon signed rank test (Splus, MathSoft Inc., WA).\n",
      "\n",
      "solution for g in (1) by minimizing the negative logarithm of the distribution using standard\n",
      "regularization techniques [1, 13] with missing data, the learned prior model, and a Poisson\n",
      "likelihood term [11]. Simple gradient descent [1] with deterministic annealing provides a\n",
      "reasonable solution. Note that the negative logarithm of the prior term can be approximated\n",
      "by the robust statistical error function\n",
      "extensively in machine vision and image processing for smoothing data with discontinuities\n",
      "[1, 5].\n",
      "\n",
      "=\u0002\u0001\n",
      "\n",
      "=A2\n",
      "\n",
      "=A2 \u001f12 which has been used\n",
      "\n",
      "\u0001\u0017\u001f\n",
      "\n",
      "Figure 5 shows the various estimates of the receptive ﬁelds. Observe that the pattern of\n",
      "\n",
      "ﬁring is not Gaussian. Moreover, some cells appear to be tuned to motion direction, \u0007 , and\n",
      "not to speed, \f , resulting in vertically elongated patterns of ﬁring. Other cells (e.g. cell 19)\n",
      "\n",
      "appear to be tuned to particular directions and speeds; this type of activity is not well ﬁt by\n",
      "the parametric models.\n",
      "\n",
      "Table 1 shows a quantitative comparison using cross-validation. The log likelihood ratio\n",
      "(LLR) is used to compare each pair of models: LLR(model 1, model 2) = log(\n",
      "(observed\n",
      "\n",
      "ﬁring 0 model 1)/Pr(observed ﬁring 0 model 2)). The positive values in Table 1 indicate\n",
      "\n",
      "that the non-parametric models do a better job of explaining new data than the parametric\n",
      "models with the Poisson+Robust ﬁt providing the best description of the data. This P+R\n",
      "model implies that the conditional ﬁring rate is well described by regions of smooth activity\n",
      "with relatively sharp discontinuities between them. The non-parametric models reduce the\n",
      "strong bias of the parametric models with a slight increase in variance and hence achieve a\n",
      "lower total error.\n",
      "\n",
      "\u0003\u0005\u0004\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\u001d\n",
      "\n",
      ".\n",
      "&\n",
      ".\n",
      "\n",
      "\f4 Temporal Inference\n",
      "\n",
      "Given neural measurements our goal is to infer the motion of the hand over time. Related\n",
      "approaches have exploited simple linear ﬁltering methods which do not provide a prob-\n",
      "abilistic interpretation of the data that can facilitate analysis and support the principled\n",
      "combination of multiple sources of information. Related probabilistic approaches have\n",
      "exploited Kalman ﬁltering [2]. We note here however, that the learned models of neural\n",
      "activity are not-Gaussian and the dynamics of the hand motion may be non-linear. Further-\n",
      "more with a small number of cells, our interpretation of the neural data may be ambiguous\n",
      "and the posterior probability of the kinematic variables, given the neural activity, may be\n",
      "best modeled by a non-Gaussian, multi-modal, distribution. To cope with these issues in\n",
      "a sound probabilistic framework we exploit a non-parametric approach that uses factored\n",
      "sampling to discretely approximate the posterior distribution, and particle ﬁltering to prop-\n",
      "agate and update this distribution over time [8].\n",
      "\n",
      "D\u0005\u0004\n",
      "\n",
      "G\u0006\u0004\n",
      "\n",
      "7\u001d\n",
      "\n",
      "\f! \n",
      "\u0003\n",
      "\n",
      "be the mean ﬁring rate of cell\n",
      "\n",
      "Let the state of the system be s\n",
      "\n",
      "\u0007?# at time \u0001 . Let\n",
      "# represent the ﬁring rate of all\n",
      "\n",
      "windows. Also, let c\n",
      "Similarly let\n",
      "C\n",
      "\n",
      "\b at time \u0001 where the mean ﬁring rate is estimated within non-overlapping 50 ms temporal\n",
      "represent the sequence of these ﬁring rates for cel up to time \u0001 and let\n",
      "\n",
      "cells up to time \u0001 .\n",
      "state at time \u0001 depends only on the state at the previous time instant:\n",
      ". s\n",
      "\n",
      "# represent the ﬁring of all\n",
      "\n",
      "We assume that the temporal dynamics of the states, s\n",
      "\n",
      ", form a Markov chain for which the\n",
      "\n",
      "cells at time \u0001 .\n",
      "\n",
      "D\t\u0004\n",
      "\u0002\f\u000b\n",
      "\n",
      "-/. s\n",
      "\n",
      "\u0002\u0007\u0002\n",
      "\n",
      "G\u0006\u0004\n",
      "\n",
      "\u0003\n",
      "\n",
      "where S\n",
      "observation c\n",
      "\n",
      "\u001f s\n",
      "\n",
      "and the previous observations C\n",
      "\n",
      "(# denotes the state history. We also assume that given s\n",
      "\n",
      ", the current\n",
      "\n",
      "Using Bayes rule and the above assumptions, the probability of observing the state at time\n",
      "\n",
      "0 S\n",
      "\n",
      "2\u0006\u001d\n",
      "\n",
      "\u0001 given the history of ﬁring can be written as\n",
      "where8\n",
      "lihood term-/. c\n",
      "\n",
      ". s\n",
      "\n",
      ". c\n",
      "\n",
      "H0 C\n",
      "D\t\u0004\n",
      "\n",
      "J2\n",
      "0 s\n",
      "\n",
      "is a normalizing term that insures that the distribution integrates to one. The like-\n",
      "\n",
      "0 s\n",
      "\n",
      "\u001d\u000f\u000e\n",
      "\n",
      "cells where the likelihood for the ﬁring rate of an individual cell is taken to be a Poisson\n",
      "distribution with the mean ﬁring rate for the speed and velocity given by s\n",
      "determined by\n",
      "the conditional ﬁring models learned in the previous section. Plotting this likelihood term\n",
      "for a range of states reveals that its structure is highly non-Gaussian with multiple peaks.\n",
      "\n",
      "2 assumes conditional independence of the individual\n",
      "\n",
      "DFE/G\n",
      "\n",
      "(2)\n",
      "\n",
      "The temporal prior term,-\n",
      "-/. s\n",
      "H0 C\n",
      "\n",
      ". s\n",
      "\n",
      "0 C\n",
      "\n",
      "2 can be written as\n",
      "-/. s\n",
      "-/. s\n",
      "\n",
      "H0 s\n",
      "\n",
      "0 C\n",
      "\n",
      "2\u0012\u0011\n",
      "\n",
      ". s\n",
      "\n",
      "where-\n",
      "to be constant with Gaussian noise; that is, a diffusion process. Note, -\n",
      "H0 s\n",
      "posterior distribution over the state space at time \u0001\n",
      "The posterior,-\n",
      "\n",
      "2 embodies the temporal dynamics of the hand velocity which are assumed\n",
      ". s\n",
      "\n",
      "random sam-\n",
      "ples which are propagated in time using a standard particle ﬁlter (see [8] for details). Unlike\n",
      "previous applications of particle ﬁltering, the likelihood of ﬁring for an individual cell in\n",
      "\n",
      "J2 , is represented with a discrete, weighted set, of\n",
      "\n",
      "\u0013\u000f')'\u000f'\n",
      "\n",
      "0 C\n",
      "\n",
      "0 C\n",
      "\n",
      "is the\n",
      "\n",
      ". s\n",
      "\n",
      "& .\n",
      "\n",
      "s\n",
      "\n",
      "(3)\n",
      "\n",
      "\u0002F s\n",
      "\n",
      "0 s\n",
      "G are independent.\n",
      "-/. s\n",
      "\n",
      "0 s\n",
      "\n",
      "\"2\n",
      "\n",
      "H0 C\n",
      "\n",
      "\u001f\n",
      "\u0002\n",
      "\u0003\n",
      "\n",
      "\n",
      "\u001d\n",
      "\u001f\n",
      "\u0002\n",
      "\u0003\n",
      "\n",
      "\u0002\n",
      "\u0002\n",
      "\u0004\n",
      "\n",
      "\n",
      "\u000b\n",
      "\u0003\n",
      "\n",
      "\n",
      "\u001d\n",
      "\u001f\n",
      "\u000b\n",
      "\u0003\n",
      "\n",
      "\u0002\n",
      "\u0002\n",
      "\u0004\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u0013\n",
      "G\n",
      "-\n",
      "\n",
      "\n",
      "\u0013\n",
      "G\n",
      "2\n",
      " \n",
      "\n",
      "\u001d\n",
      "\n",
      " \n",
      "\u0002\n",
      "\u0002\n",
      "\n",
      "\n",
      "\n",
      "\u0013\n",
      "-\n",
      "\u001d\n",
      "8\n",
      "\u001f\n",
      "-\n",
      "\n",
      "\n",
      "\u0013\n",
      "G\n",
      "2\n",
      "\u001f\n",
      "\n",
      "\n",
      "2\n",
      "\b\n",
      "-\n",
      ".\n",
      "\u0002\n",
      "\u0003\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u0013\n",
      "G\n",
      "\n",
      "\u0013\n",
      "G\n",
      "2\n",
      "\u001d\n",
      "\u0010\n",
      "\n",
      "\u0013\n",
      "G\n",
      "2\n",
      "\n",
      "\u0013\n",
      "G\n",
      "\n",
      "\u0013\n",
      "G\n",
      "\n",
      "\u0013\n",
      "G\n",
      " \n",
      "\n",
      "\u0013\n",
      "G\n",
      "\n",
      "\u0013\n",
      "G\n",
      "\n",
      "\u0013\n",
      "G\n",
      "2\n",
      "\u0002\n",
      "\n",
      "\ftrial No. 8, Vx in cm/s, blue:true, red:reconstruction\n",
      "\n",
      "trial No. 8, Vx in cm/s, blue:true, red:reconstruction\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "0\n",
      "\n",
      "-5\n",
      "\n",
      "-10\n",
      "\n",
      "125\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "0\n",
      "\n",
      "(cid:21)-5\n",
      "\n",
      "(cid:21)-10\n",
      "\n",
      "125\n",
      "\n",
      "126\n",
      "\n",
      "127\n",
      "\n",
      "128\n",
      "\n",
      "129\n",
      "\n",
      "130\n",
      "\n",
      "131\n",
      "\n",
      "132\n",
      "\n",
      "133\n",
      "\n",
      "134\n",
      "\n",
      "135\n",
      "\n",
      "time in second\n",
      "\n",
      "Vy in cm/s\n",
      "\n",
      "126\n",
      "\n",
      "127\n",
      "\n",
      "128\n",
      "\n",
      "129\n",
      "\n",
      "130\n",
      "\n",
      "131\n",
      "\n",
      "132\n",
      "\n",
      "133\n",
      "\n",
      "134\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "0\n",
      "\n",
      "-5\n",
      "\n",
      "-10\n",
      "\n",
      "125\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "0\n",
      "\n",
      "(cid:21)-5\n",
      "\n",
      "(cid:21)-10\n",
      "\n",
      "125\n",
      "\n",
      "126\n",
      "\n",
      "127\n",
      "\n",
      "128\n",
      "\n",
      "129\n",
      "\n",
      "130\n",
      "\n",
      "131\n",
      "\n",
      "132\n",
      "\n",
      "133\n",
      "\n",
      "134\n",
      "\n",
      "135\n",
      "\n",
      "time in second\n",
      "\n",
      "Vy in cm/s\n",
      "\n",
      "126\n",
      "\n",
      "127\n",
      "\n",
      "128\n",
      "\n",
      "129\n",
      "\n",
      "130\n",
      "\n",
      "131\n",
      "\n",
      "132\n",
      "\n",
      "133\n",
      "\n",
      "134\n",
      "\n",
      "135\n",
      "\n",
      "a\n",
      "\n",
      "b\n",
      "\n",
      ", (top)\n",
      "Figure 6: Tracking results using 1008 synthetic cells showing horizontal velocity,\n",
      "and vertical velocity,\n",
      "(a) Bayesian\n",
      "estimate using particle ﬁltering. Red curve shows expected value of the posterior. The\n",
      ". (b) Linear ﬁltering method shown in\n",
      "\n",
      ", (bottom). Blue indicates true velocity of hand.\n",
      "\n",
      "\u0004\u0003\n",
      "for\n",
      "\n",
      "\u0002\u0001\n",
      "\n",
      "error is \f\n",
      "red; \f\n",
      "\n",
      "and\f\n",
      "\n",
      "\u0006\u0001\n",
      "and \f\n",
      "\n",
      "'\u0003\u0002\n",
      "\n",
      "\u0013\n",
      "\t\n",
      "\n",
      "for\n",
      "\n",
      "\u0006\u0001\n",
      "\n",
      "\u0013\u0007\n",
      "\n",
      "'\u0003\u0007\u0004\u0007\n",
      "\n",
      "for\n",
      "\n",
      "for\n",
      ".\n",
      "\n",
      "\u0006\u0003\n",
      "\n",
      "\u0006\u0003\n",
      "\n",
      "\u0005\f\u000b\n",
      "\n",
      "'\u0003\u0002\n",
      "\n",
      "'\u0003\u0002\n",
      "\n",
      "\u0006\u000f'\n",
      "\n",
      "50 ms provides very little information. For the posterior to be meaningful we must com-\n",
      "bine evidence from multiple cells. Our experiments indicate that the responses from our\n",
      "24 cells are insufﬁcient for this task. To demonstrate the feasibility of the particle ﬁltering\n",
      "method, we synthesized approximately 1000 cells by taking the learned models of the 24\n",
      "\n",
      "cells and translating them along the \u0007 axis to generate a more complete covering of the\n",
      "\n",
      "velocity space. Note that the assumption of such a set of cells in MI is quite reasonable\n",
      "give the sampling of cells we have observed in multiple monkeys.\n",
      "\n",
      "From the set of synthetic cells we then generate a synthetic spike train by taking a known\n",
      "sequence of hand velocities and stochastically generating spikes using the learned condi-\n",
      "tional ﬁring models with a Poisson generative model. Particle ﬁltering is used to estimate\n",
      "the posterior distribution over hand velocities given the synthetic neural data. The expected\n",
      "value of the horizontal and vertical velocity is displayed in Figure 6a. For comparison, a\n",
      "standard linear ﬁltering method [6, 14] was trained on the synthetic data from 50 ms in-\n",
      "tervals. The resulting prediction is shown in Figure 6b. Linear ﬁltering works well over\n",
      "longer time windows which introduce lag. The Bayesian analysis provides a probabilistic\n",
      "framework for sound causal estimates over short time intervals.\n",
      "\n",
      "We are currently experimenting with modiﬁed particle ﬁltering schemes in which linear\n",
      "ﬁltering methods provide a proposal distribution and importance sampling is used to con-\n",
      "struct a valid posterior distribution. We are also comparing these results with those of\n",
      "various Kalman ﬁlters.\n",
      "\n",
      "5 Conclusions\n",
      "\n",
      "We have described a Bayesian model for neural activity in MI that relates this activity to\n",
      "actions in the world. Quantitative comparison with previous models of MI activity indicate\n",
      "that the non-parametric models computed using regularization more accurately describe\n",
      "the neural activity. In particular, the robust spatial prior term suggests that neural ﬁring in\n",
      "MI is not a smooth function of velocity but rather exhibits discontinuities between regions\n",
      "\n",
      "\u001f\n",
      "\u001d\n",
      "\u0006\n",
      "\u0005\n",
      "\u001f\n",
      "\u001d\n",
      "\u0005\n",
      "'\n",
      "\u0013\n",
      "\u0013\n",
      "\u001f\n",
      "\u001d\n",
      "\u001f\n",
      "\u001d\n",
      "\fof high and low activity.\n",
      "\n",
      "We have also described the Bayesian decoding of hand motion from ﬁring activity using a\n",
      "particle ﬁlter. Initial results suggest that measurements from several hundred cells may be\n",
      "required for accurate estimates of hand velocity. The application of particle ﬁltering to this\n",
      "problem has many advantages as it allows complex, non-Gaussian, likelihood models that\n",
      "may incorporate non-linear temporal properties of neural ﬁring (e.g. refractory period).\n",
      "Unlike previous linear ﬁltering methods this Bayesian approach provides probabilistically\n",
      "sound, causal, estimates in short time windows of 50ms. Current work is exploring correla-\n",
      "tions between cells [7] and the relationship between the neural activity and other kinematic\n",
      "variables [12].\n",
      "\n",
      "Acknowledgments. This work was supported by the Keck Foundation and by the National\n",
      "Institutes of Health under grants #R01 NS25074 and #N01-NS-9-2322 and by the National\n",
      "Science Foundation ITR Program award #0113679. We are very grateful to M. Serruya,\n",
      "M. Fellows, L. Paninski, and N. Hatsopoulos who provided the neural data and valuable\n",
      "insight.\n",
      "\n",
      "References\n",
      "[1] M. Black and A. Rangarajan. On the uniﬁcation of line processes, outlier rejection, and robust\n",
      "\n",
      "statistics with applications in early vision. IJCV, 19(1):57–92, 1996.\n",
      "\n",
      "[2] E. Brown, L. Frank, D. Tang, M. Quirk, and M. Wilson. A statistical paradigm for neural spike\n",
      "train decoding applied to position prediction from ensemble ﬁring patterns of rat hippocampal\n",
      "place cells. J. Neuroscience, 18(18):7411–7425, 1998.\n",
      "\n",
      "[3] Q-G. Fu, D. Flament, J. Coltz, and T. Ebner. Temporal encoding of movement kinematics in the\n",
      "discharge of primate primary motor and premotor neurons. J. of Neurophysiology, 73(2):836–\n",
      "854, 1995.\n",
      "\n",
      "[4] S. Geman and D. Geman. Stochastic relaxation, Gibbs distributions and Bayesian restoration\n",
      "\n",
      "of images. PAMI, 6(6):721–741, November 1984.\n",
      "\n",
      "[5] S. Geman and D. McClure. Statistical methods for tomographic image reconstruction. Bulletin\n",
      "\n",
      "of the Int. Stat. Inst., LII-4:5–21, 1987.\n",
      "\n",
      "[6] A. Georgopoulos, A. Schwartz, and R. Kettner. Neuronal population coding of movement\n",
      "\n",
      "direction. Science, 233:1416–1419, 1986.\n",
      "\n",
      "[7] N. Hatsopoulos, C. Ojakangas, L. Paninski, and J. Donoghue.\n",
      "\n",
      "Information about movement\n",
      "direction obtained from synchronous activity of motor cortical neurons. Proc. Nat. Academy of\n",
      "Sciences, 95:15706–15711, 1998.\n",
      "\n",
      "[8] M. Isard and A. Blake. Condensation – conditional density propagation for visual tracking.\n",
      "\n",
      "IJCV, 29(1): 5–28, 1998.\n",
      "\n",
      "[9] E. Maynard, N. Hatsopoulos, C. Ojakangas, B. Acuna, J. Sanes, R. Normann, and J. Donoghue.\n",
      "Neuronal interaction improve cortical population coding of movement direction. J. of Neuro-\n",
      "science, 19(18):8083–8093, 1999.\n",
      "\n",
      "[10] D. Moran and A. Schwartz. Motor cortical representation of speed and direction during reach-\n",
      "\n",
      "ing. J. Neurophysiol, 82:2676-2692, 1999.\n",
      "\n",
      "[11] R. Nowak and E. Kolaczyk. A statistical multiscale framework for Poisson inverse problems.\n",
      "\n",
      "IEEE Inf. Theory, 46(5):1811–1825, 2000.\n",
      "\n",
      "[12] L. Paninski, M. Fellows, N. Hatsopoulos, and J. Donoghue. Temporal tuning properties for\n",
      "\n",
      "hand position and velocity in motor cortical neurons. submitted, J. Neurophysiology, 2001.\n",
      "\n",
      "[13] D. Terzopoulos. Regularization of inverse visual problems involving discontinuities. PAMI,\n",
      "\n",
      "8(4):413–424, 1986.\n",
      "\n",
      "[14] J. Wessberg, C. Stambaugh, J. Kralik, P. Beck, M. Laubach, J. Chapin, J. Kim, S. Biggs, M.\n",
      "Srinivasan, and M. Nicolelis. Real-time prediction of hand trajectory by ensembles of cortical\n",
      "neurons in primates. Nature, 408:361–365, 2000.\n",
      "\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "# Now let's take a look at another paper from before 2020, where the plaintext was provided by the NeurIPS website\n",
    "# directly. This paper was manually selected because it contains images, equations, and tables.\n",
    "\n",
    "paper = papers[papers['name'] == 'Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex']\n",
    "print(paper.iloc[0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that page numbers are absent from this paper - so page numbers must have been phased out from earlier years of the conference. Additionally, the table comes across similarly to the PDF-converted papers - it contains all the data but is not formatted tabularly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there may be critical information in the images, tables, and equations of these papers, it might be worthwhile exploring the use of PyMuPDF's Markdown formatter - which converts PDFs into Markdown. This might aid in preserving some of the information. It also might make it easier to parse the papers into chunks - if we decide that would improve the RAG system.\n",
    "\n",
    "Also, considering that the plaintext of papers pre-2020 (provided directly from the NeurIPS website) and papers provided after 2020 (converted from PDFs using PyMuPDF) have different formatting - it might be worthwhile to consider using the same PDF conversion process for all the papers to try to make formatting slightly more standardized. Although, the underlying paper PDFs might not have consistent formatting from year to year.\n",
    "\n",
    "Of note, is that all of these would be preprocessing steps - which only happen once. Which provides us a bit more leeway as far as scalability is concerned. (I.e., adding more preprocessing steps make take longer for the preprocessing pipeline to run, but since it's only run once or on a batch basis, that might be worth it if it makes the RAG responses better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academic-paper-explorer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
