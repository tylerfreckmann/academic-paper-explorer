{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.read_csv('papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20286, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Bit-Serial Neural Networks</td>\n",
       "      <td>573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>Connectivity Versus Entropy</td>\n",
       "      <td>1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>The Hopfield Model with Multi-Level Neurons</td>\n",
       "      <td>278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>How Neural Nets Work</td>\n",
       "      <td>442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>Spatial Organization of Neural Networks: A Pro...</td>\n",
       "      <td>740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                               name  \\\n",
       "0  1987                         Bit-Serial Neural Networks   \n",
       "1  1987                        Connectivity Versus Entropy   \n",
       "2  1987        The Hopfield Model with Multi-Level Neurons   \n",
       "3  1987                               How Neural Nets Work   \n",
       "4  1987  Spatial Organization of Neural Networks: A Pro...   \n",
       "\n",
       "                                                text  \n",
       "0  573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...  \n",
       "1  1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...  \n",
       "2  278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...  \n",
       "3  442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...  \n",
       "4  740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20281</th>\n",
       "      <td>2023</td>\n",
       "      <td>Optimal testing using combined test statistics...</td>\n",
       "      <td>Optimal testing using combined test statistics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20282</th>\n",
       "      <td>2023</td>\n",
       "      <td>Regret-Optimal Model-Free Reinforcement Learni...</td>\n",
       "      <td>Regret-Optimal Model-Free Reinforcement Learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20283</th>\n",
       "      <td>2023</td>\n",
       "      <td>Convolutional State Space Models for Long-Rang...</td>\n",
       "      <td>Convolutional State Space Models for\\nLong-Ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20284</th>\n",
       "      <td>2023</td>\n",
       "      <td>CRoSS: Diffusion Model Makes Controllable, Rob...</td>\n",
       "      <td>CRoSS: Diffusion Model Makes\\nControllable, Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20285</th>\n",
       "      <td>2023</td>\n",
       "      <td>American Stories: A Large-Scale Structured Tex...</td>\n",
       "      <td>American Stories: A Large-Scale Structured Tex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year                                               name  \\\n",
       "20281  2023  Optimal testing using combined test statistics...   \n",
       "20282  2023  Regret-Optimal Model-Free Reinforcement Learni...   \n",
       "20283  2023  Convolutional State Space Models for Long-Rang...   \n",
       "20284  2023  CRoSS: Diffusion Model Makes Controllable, Rob...   \n",
       "20285  2023  American Stories: A Large-Scale Structured Tex...   \n",
       "\n",
       "                                                    text  \n",
       "20281  Optimal testing using combined test statistics...  \n",
       "20282  Regret-Optimal Model-Free Reinforcement Learni...  \n",
       "20283  Convolutional State Space Models for\\nLong-Ran...  \n",
       "20284  CRoSS: Diffusion Model Makes\\nControllable, Ro...  \n",
       "20285  American Stories: A Large-Scale Structured Tex...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Papers from 1987-2019 were downloaded as plaintext directly from the NeurIPS conference website. Papers from 2020 onward were downloaded as PDFs and then converted to plaintext using PyMuPDF. This may have resulted in some formatting differences. Let's take a look at the plaintext of a few papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Stories: A Large-Scale Structured Text\n",
      "Dataset of Historical U.S. Newspapers\n",
      "Melissa Dell1,2∗, Jacob Carlson1, Tom Bryan1, Emily Silcock1, Abhishek Arora1, Zejiang Shen3,\n",
      "Luca D’Amico-Wong1, Quan Le4, Pablo Querubin2,5, Leander Heldring6\n",
      "1Harvard University; Cambridge, MA, USA.\n",
      "2National Bureau of Economic Research; Cambridge, MA, USA.\n",
      "3Massachusetts Institute of Technology; Cambridge, MA, USA.\n",
      "4Princeton University; Princeton, NJ, USA.\n",
      "5New York University; New York, NY, USA.\n",
      "6Kellogg School of Management, Northwestern University, Evanston, IL, USA.\n",
      "∗Corresponding author: melissadell@fas.harvard.edu.\n",
      "Abstract\n",
      "Existing full text datasets of U.S. public domain newspapers do not recognize the\n",
      "often complex layouts of newspaper scans, and as a result the digitized content\n",
      "scrambles texts from articles, headlines, captions, advertisements, and other lay-\n",
      "out regions. OCR quality can also be low. This study develops a novel, deep learn-\n",
      "ing pipeline for extracting full article texts from newspaper images and applies it\n",
      "to the nearly 20 million scans in Library of Congress’s public domain Chronicling\n",
      "America collection. The pipeline includes layout detection, legibility classifica-\n",
      "tion, custom OCR, and association of article texts spanning multiple bounding\n",
      "boxes. To achieve high scalability, it is built with efficient architectures designed\n",
      "for mobile phones. The resulting American Stories dataset provides high quality\n",
      "data that could be used for pre-training a large language model to achieve better\n",
      "understanding of historical English and historical world knowledge. The dataset\n",
      "could also be added to the external database of a retrieval-augmented language\n",
      "model to make historical information - ranging from interpretations of political\n",
      "events to minutiae about the lives of people’s ancestors - more widely accessible.\n",
      "Furthermore, structured article texts facilitate using transformer-based methods\n",
      "for popular social science applications like topic classification, detection of repro-\n",
      "duced content, and news story clustering. Finally, American Stories provides a\n",
      "massive silver quality dataset for innovating multimodal layout analysis models\n",
      "and other multimodal applications.\n",
      "1\n",
      "Introduction\n",
      "Historical local newspapers provide a massive repository of texts about American communities and\n",
      "their inhabitants that can elucidate topics ranging from semantic change to political polarization\n",
      "to the construction of national and cultural identities to the minutiae of the daily lives of people’s\n",
      "ancestors. Given the enormous breadth and depth of content, historical newspapers have been widely\n",
      "studied, yet existing open source U.S. newspaper datasets have significant limitations that complicate\n",
      "the extent to which modern deep learning methods can leverage and liberate their content.\n",
      "Library of Congress’s Chronicling America project [19] is the primary public domain historical U.S.\n",
      "newspaper dataset. It consists of around 20 million historical newspaper scans and their correspond-\n",
      "ing digitized texts. Its content is concentrated before 1925, as this content has entered the public\n",
      "37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Bench-\n",
      "marks.\n",
      "\fdomain. Chronicling America does not recognize oftentimes complex newspaper layouts, and so\n",
      "digitized texts are provided at the page level, often scrambling headlines, articles, advertisements,\n",
      "captions, and other content regions together. Because a non-trivial share of the underlying scans\n",
      "are illegible, incoherent texts are prevalent, with illegibility varying across space and time. This\n",
      "complicates applying natural language processing (NLP) and statistical methods, and the data are\n",
      "not of sufficient quality to use for training a large language model to achieve a better understanding\n",
      "of historical English and historical world knowledge.\n",
      "To address these limitations, we develop a pipeline for cheaply extracting high quality digitized ar-\n",
      "ticle texts and layout regions from newspaper scans. First, layout detection predicts the coordinates\n",
      "and classes of content regions - e.g. articles, headlines, bylines, advertisements, pictures, etc. - us-\n",
      "ing object detection methods [34]. Then, an image classifier removes illegible text bounding boxes.\n",
      "We next digitize the text regions using a novel optical character recognition (OCR) architecture that\n",
      "yields highly scalable, accurate results within our constrained budget. The focus on cost effective-\n",
      "ness makes the pipeline accessible to others with limited budgets who would like to digitize massive\n",
      "historical document collections. Finally, we associate headline, byline, and article bounding boxes.\n",
      "We do not process foreign language newspapers, as off-the-shelf OCR tends to perform poorly on\n",
      "the diverse languages and scripts.\n",
      "The resulting American Stories (Structured text on reporting in every state) dataset contains\n",
      "1.14B content regions. The dataset has extensive geographic coverage across all states and has\n",
      "content dating as far back as the 17th century, although the bulk of content comes from the early\n",
      "20th century. Figure 1 shows the distribution of scans across years and states. The vast majority of\n",
      "American Stories is older than the 72 year rule that the U.S. government uses to release personal\n",
      "information (e.g., from the census) into the public domain.\n",
      "(a) Scans Across Time\n",
      "(b) Scans Across Space\n",
      "Figure 1: Scans in the Chronicling America database across time and space.\n",
      "We show that the pipeline produces accurate predictions. The resulting texts could be used for\n",
      "historical language model training, or added to an external database of a retrieval augmented lan-\n",
      "guage model to facilitate the study of topics ranging from international events to family history. The\n",
      "layouts and corresponding texts could provide a massive silver quality dataset for applications like\n",
      "multimodal layout analysis and classification. The American Stories dataset also yields signifi-\n",
      "cantly better performance on social science analyses than the Chronicling America OCR and allows\n",
      "analyses that would be impossible without structured article texts. For example, we cluster article\n",
      "embeddings to detect which stories (e.g., Pancho Villa Expedition, 1916) received the most coverage\n",
      "each year.\n",
      "The rest of this study is organized as follows. Section 2 discussed related literature and Section 3\n",
      "describes the American Stories dataset. Section 4 outlines the digitization pipeline, and Section\n",
      "5 evaluates the quality of the outputs. Section 6 discusses applications and Section 7 considers\n",
      "limitations and recommended usage.\n",
      "2\n",
      "Related Literature\n",
      "Public domain newspaper datasets exist for many countries, but typically pipelines are proprietary,\n",
      "as the norm is to outsource digitization to a private company. Commercial newspaper databases\n",
      "2\n",
      "\flikewise do not disclose their pipelines, resulting in a dearth of open-source methods. The most\n",
      "closely related work to American Stories is the open-source Newspaper Navigator dataset [15].\n",
      "The main, and crucial, difference between American Stories and [15] is that [15] does not detect\n",
      "bounding boxes of articles. [15] focuses on 7 classes of visual content: headlines, photographs,\n",
      "illustrations, maps, comics, editorial cartoons, and advertisements. Distinguishing articles enables\n",
      "legibility classification, application of custom OCR, and association of articles across bounding\n",
      "boxes. These tasks are at the core of our contribution, and enable the usefulness of our contribution\n",
      "for downstream applications. In addition, the OCR in [15] is limited to Chronicling America’s OCR,\n",
      "which we show leads to a quality deterioration.\n",
      "While we focus exclusively on texts where the entire newspaper is indisputably in the public domain\n",
      "(typically because it was published more than 95 years ago), it is worth noting that our pipeline\n",
      "could help address some of the copyright issues that have limited the public availability of historical\n",
      "newspapers. Outside of the nation’s most widely circulated newspapers, it was rare for local papers\n",
      "to publish with a copyright notice or renew their copyright, required formalities until the latter half of\n",
      "the 20th century. Hence, the majority of local papers well into the 20th century are off-copyright. Yet\n",
      "these papers might sometimes print copyrighted content by third parties - e.g., frequently comics,\n",
      "rarely ads, and occasional runs of syndicated fiction [23]. Individual news articles did not have\n",
      "their copyrights renewed, as copyrighting yesterday’s news lacked commercial value. Detecting\n",
      "individual content regions - e.g., so that ads and comics could be cropped out and fictional texts\n",
      "removed with a classifier - is a prerequisite for removing content potentially under copyright. Some\n",
      "copyright experts [23] have suggested this as a way forward for making historical newspapers more\n",
      "accessible.\n",
      "3\n",
      "Dataset\n",
      "Table 1 describes American Stories, totaling 1.14 billion content region bounding boxes. Head-\n",
      "lines, images, bylines, and captions are OCR’ed if legible. The dataset contains 3,313 tokens per\n",
      "page on average, making the full dataset 65.6 billion tokens.\n",
      "(1)\n",
      "(2)\n",
      "(3)\n",
      "(4)\n",
      "(5)\n",
      "(6)\n",
      "(7)\n",
      "(8)\n",
      "(9)\n",
      "Total\n",
      "Text Bounding Boxes\n",
      "Other Bounding Boxes\n",
      "Boxes\n",
      "Articles\n",
      "Headlines\n",
      "Captions\n",
      "Bylines\n",
      "Images\n",
      "Ads\n",
      "Tables\n",
      "Mastheads\n",
      "Legible\n",
      "-\n",
      "335M\n",
      "368M\n",
      "9.7M\n",
      "14.7M\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Illegible\n",
      "-\n",
      "26M\n",
      "27M\n",
      "0.9M\n",
      "2.5M\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Borderline\n",
      "-\n",
      "77M\n",
      "22M\n",
      "1.3M\n",
      "1.2M\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Total\n",
      "1.14B\n",
      "438M\n",
      "417M\n",
      "11.9M\n",
      "18.4M\n",
      "9.1M\n",
      "221M\n",
      "16.3M\n",
      "4.9M\n",
      "Table 1: American Stories dataset statistics.\n",
      "American Stories provides the classes and coordinates for all content regions. Using the provided\n",
      "metadata, it is straightforward for users to link the coordinates with the original scans, which can be\n",
      "downloaded through the Library of Congress’s website. We do not OCR ads because they oftentimes\n",
      "have unusual fonts and complex layouts, including scene text and complex tables with pricing or\n",
      "schedule information, complicating OCR. The table class includes tabular article da\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the last paper in the dataset - one from 2023. This paper is representative of papers that\n",
    "# were converted from PDFs\n",
    "\n",
    "# To keep things readable, let's just take a look at the beginning of the paper.\n",
    "\n",
    "text = papers.loc[20285, 'text']\n",
    "print(text[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "In comparing the plaintext to the PDF, here are the things we notice did not translate over very well:\n",
    "\n",
    " - images/figures - the image and figure titles made it across into plaintext, but as expected, images themseves did not. In the RAG response back to the user, we'll have to decide whether to display the rendered images back to the user (most likely relying on the PDF document itself - which might require PDF manipulation if we just want to display the part with the image) _or_ whether we want to leave images out. Leaving images could be potentially viable as we're planning to provide access to the papers involved in the particular RAG response regardless.\n",
    " - tables - tables and their data are translated into plaintext but not in tabular format. This raises questions of how to handle these both from an embedding perspective (would including tabular data add extra \"noise\" to the embedding) as whether they should be displayed in the RAG response (similar to the question for images)\n",
    " - equations - similar to tables, equations are carried over into plaintext, but lacking formatting. This makes it hard for a human to understand the equation, and, similarly, equations are a niche notation that might not be embedded well. So the question regarding whether to include them in embedding/display goes for equations as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573 \n",
      "\n",
      "BIT - SERIAL NEURAL  NETWORKS \n",
      "\n",
      "Alan F.  Murray,  Anthony V . W.  Smith  and Zoe F.  Butler. \n",
      "\n",
      "Department of Electrical Engineering,  University of Edinburgh, \n",
      "\n",
      "The King's Buildings, Mayfield Road,  Edinburgh, \n",
      "\n",
      "Scotland,  EH93JL. \n",
      "\n",
      "ABSTRACT \n",
      "\n",
      "A  bit  - serial  VLSI  neural  network  is  described  from  an  initial  architecture  for  a \n",
      "synapse array through to silicon layout and board design.  The issues surrounding bit \n",
      "- serial  computation,  and  analog/digital  arithmetic  are  discussed  and  the  parallel \n",
      "development  of  a  hybrid  analog/digital  neural  network  is  outlined.  Learning  and \n",
      "recall  capabilities  are  reported  for  the  bit  - serial  network  along  with  a  projected \n",
      "specification  for  a  64  - neuron,  bit  - serial  board  operating  at 20 MHz.  This tech(cid:173)\n",
      "nique  is  extended  to  a  256  (2562  synapses)  network  with  an  update  time  of 3ms, \n",
      "using  a  \"paging\"  technique  to  time  - multiplex  calculations  through  the  synapse \n",
      "array. \n",
      "\n",
      "1. INTRODUCTION \n",
      "\n",
      "The functions a  synthetic neural network may aspire to mimic are the ability to con(cid:173)\n",
      "sider  many  solutions  simultaneously,  an  ability  to  work  with  corrupted  data  and  a \n",
      "natural  fault  tolerance.  This  arises  from  the  parallelism  and  distributed  knowledge \n",
      "representation  which  gives  rise  to  gentle  degradation  as  faults  appear.  These func(cid:173)\n",
      "tions  are  attractive  to implementation  in VLSI  and  WSI.  For example,  the natural \n",
      "fault  - tolerance  could  be  useful  in  silicon  wafers  with  imperfect  yield,  where  the \n",
      "network  degradation  is  approximately  proportional  to  the  non-functioning  silicon \n",
      "area. \n",
      "To cast  neural networks in engineering language,  a  neuron is a  state machine that is \n",
      "either  \"on\"  or  \"off',  which  in  general  assumes  intermediate  states  as  it  switches \n",
      "smoothly  between  these  extrema.  The  synapses  weighting  the  signals  from  a \n",
      "transmitting neuron  such that it is more or less excitatory or inhibitory to the receiv(cid:173)\n",
      "ing  neuron.  The  set  of synaptic weights  determines  the stable  states and  represents \n",
      "the learned  information in a system. \n",
      "The  neural  state,  VI'  is  related  to  the  total  neural  activity  stimulated  by  inputs  to \n",
      "the  neuron  through  an  activation junction,  F.  Neural  activity  is  the  level  of excita(cid:173)\n",
      "tion  of the  neuron  and the  activation  is  the way  it  reacts  in a  response to a  change \n",
      "in activation. The neural output state at time t, V[,  is related to x[ by \n",
      "\n",
      "V[  = F (xf) \n",
      "\n",
      "(1) \n",
      "\n",
      "The  activation  function  is  a  \"squashing\"  function  ensuring  that  (say)  Vi  is  1  when \n",
      "Xi  is large  and  -1  when Xi  is  small.  The neural update function  is therefore straight(cid:173)\n",
      "forward: \n",
      "\n",
      ". \n",
      "\n",
      ",+1  - ,   + ~  ~ T  V' \n",
      "J \n",
      "XI \n",
      "\n",
      "i-n-l \n",
      "0  ~  ii \n",
      "\n",
      "- XI \n",
      "\n",
      "• •••• \n",
      "\n",
      "J-O \n",
      "\n",
      "(2) \n",
      "\n",
      "where  8  represents  the  rate  of change  of neural  activity,  Tij \n",
      "and n  is  the number of terms giving an n  - neuron array [1]. \n",
      "Although  the  neural function  is  simple  enough,  in  a  totally  interconnected  n  - neu(cid:173)\n",
      "ron  network  there  are n 2  synapses requiring n 2  multiplications  and  summations and \n",
      "\n",
      "is  the  synaptic  weight \n",
      "\n",
      "© American Institute of Physics 1988 \n",
      "\n",
      "\f574 \n",
      "\n",
      "a large number of interconnects.  The challenge in VLSI is therefore to design a  sim(cid:173)\n",
      "ple,  compact  synapse  that  can  be  repeated  to  build  a  VLSI  neural  network  with \n",
      "In  a  network  with  fixed  functionality,  this  is  relatively \n",
      "manageable  interconnect. \n",
      "straightforward.  H the  network  is to be able to learn,  however,  the synaptic weights \n",
      "must  be programmable, and therefore more complicated. \n",
      "\n",
      "2. DESIGNING  A NEURAL  NETWORK IN  VLSI \n",
      "\n",
      "There  are  fundamentally  two  approaches  to  implementing  any  function  in  silicon  -\n",
      "digital and analog.  Each technique has its advantages and  disadvantages,  and these \n",
      "are  listed  below,  along  with  the  merits  and  demerits  of bit  - serial  architectures  in \n",
      "digital (synchronous) systems. \n",
      "Digital  vs.  analog:  The  primary  advantage  of digital  design  for  a  synapse  array  is \n",
      "that  digital  memory  is  well  understood,  and  can  be  incorporated  easily.  Learning \n",
      "networks are  therefore  possible  without  recourse  to unusual  techniques  or technolo(cid:173)\n",
      "gies.  Other strengths of a digital approach are that design techniques are advanced, \n",
      "automated  and  well  understood  and  noise  immunity  and  computational  speed  can \n",
      "be  high.  Unattractive features  are  that  digital  circuits  of this complexity need  to  be \n",
      "synchronous  and  all  states  and  activities  are  quantised,  while  real  neural  networks \n",
      "are  asynchronous  and  unquantised.  Furthermore,  digital  multipliers  occupy  a  large \n",
      "silicon  area, giving a low synapse count on  a single chip. \n",
      "The  advantages  of  analog  circuitry  are  that  asynchronous  behaviour  and  smooth \n",
      "neural  activation  are  automatic.  Circuit  elements can  be  small,  but  noise  immunity \n",
      "is relatively  low  and  arbitrarily  high  precision is not  possible.  Most  importantly,  no \n",
      "reliable  analog,  non  - volatile  memory  technology  is  as  yet  readily  available.  For \n",
      "this  reason,  learning  networks  lend  themselves  more  naturally to  digital  design  and \n",
      "implementation. \n",
      "Several  groups  are  developing  neural  chips  and  boards,  and  the  following  listing \n",
      "does  not  pretend  to  be  exhaustive.  It is  included,  rather,  to indicate  the spread  of \n",
      "activity  in  this  field.  Analog  techniques  have  been  used  to  build  resistor  I  opera(cid:173)\n",
      "tional  amplifier  networks [2,3]  similar to  those  proposed  by  Hopfield  and Tank [4]. \n",
      "A  large  group  at  Caltech  is  developing  networks  implementing  early  vision  and \n",
      "auditory  processing  functions  using the intrinsic nonlinearities of MaS transistors in \n",
      "the subthreshold  regime  [5,6].  The problem of implementing analog  networks with \n",
      "electrically  programmable  synapses  has  been  addressed  using  CCDIMNOS technol(cid:173)\n",
      "ogy  [7].  Finally,  Garth  [8]  is  developing  a  digital  neural  accelerator  board  (\"Net(cid:173)\n",
      "sim\")  that  is  effectively  a  fast  SIMD  processor  with  supporting  memory  and  com(cid:173)\n",
      "munications chips. \n",
      "Bit - serial  vs.  bit  - parallel:  Bit  - serial  arithmetic and  communication  is  efficient \n",
      "for  computational  processes,  allowing  good  communication  within  and  between \n",
      "VLSI  chips  and  tightly  pipelined  arithmetic  structures.  It  is  ideal  for  neural  net(cid:173)\n",
      "works  as  it  minimises  the  interconnect  requirement  by  eliminating  multi  - wire \n",
      "busses.  Although  a  bit  - parallel  design  would  be  free  from  computational  latency \n",
      "(delay  between  input  and  output),  pipelining  makes  optimal  use  of  the  high  bit  -\n",
      "rates possible in serial systems,  and  makes for  efficient circuit usage. \n",
      "2.1  An asynchronous pulse stream VLSI neural network: \n",
      "In  addition  to  the  digital  system  that  forms  the  substance  of  this  paper,  we  are \n",
      "developing  a  hybrid  analOg/digital  network  family.  This work  is  outlined  here,  and \n",
      "has  been  reported  in  greater  detail  elsewhere  [9, 10, 11].  The  generic  (logical  and \n",
      "layout)  architecture  of a  single  network  of n  totally  interconnected neurons is  shown \n",
      "\n",
      "\f575 \n",
      "\n",
      "schematically  in  figure  1.  Neurons  are  represented  by  circles,  which  signal  their \n",
      "states,  Vi  upward  into  a  matrix  of  synaptic  operators.  The  state  signals  are  con(cid:173)\n",
      "nected  to  a  n  - bit  horizontal  bus  running  through  the  synaptic  array,  with  a  con(cid:173)\n",
      "nection  to  each  synaptic  operator  in  every  column.  All  columns  have  n  operators \n",
      "(denoted  by  squares)  and  each  operator adds its synaptic contribution,  Tij V j\n",
      ",  to the \n",
      "running  total  of  activity  for  the  neuron  i  at  the  foot  of  the  column.  The  synaptic \n",
      "function  is  therefore  to  multiply  the  signalling  neuron  state,  Vj\n",
      ",  by  the  synaptic \n",
      "weight,  Tij ,  and  to  add  this  product  to  the  running  total.  This  architecture  is com(cid:173)\n",
      "mon to both  the bit - serial and pulse - stream networks. \n",
      "\n",
      "Synapse \n",
      "\n",
      "States { Vj  } \n",
      "\n",
      "Figure 1. Generic architecture for  a  network of n totally interconnected neurons. \n",
      "\n",
      "Neurons \n",
      "\n",
      "j=O \n",
      "\n",
      "j=II -1 \n",
      "\n",
      "This type of architecture has many attractions for  implementation in 2  - dimensional \n",
      "silicon  as  the  summation  2  Tij Vj  is  distributed  in  space.  The  interconnect \n",
      "requirement  (n  inputs  to  each  neuron)  is  therefore  distributed  through  a  column, \n",
      "reducing the need  for  long - range wiring.  The architecture is modular,  regular and \n",
      "can be easily expanded. \n",
      "In  the  hybrid  analog/digital  system,  the  circuitry  uses  a  \"pulse  stream\"  signalling \n",
      "method  similar  to  that  in  a  natural  neural  system.  Neurons  indicate  their  state  by \n",
      "the  presence  or  absence  of  pulses  on  their  outputs,  and  synaptic  weighting  is \n",
      "achieved  by  time  - chopping  the  presynaptic  pulse  stream  prior  to  adding  it  to  the \n",
      "postsynaptic  activity  summation.  It  is  therefore  asynchronous  and  imposes  no fun(cid:173)\n",
      "damental  limitations  on  the  activation  or  neural  state.  Figure  2  shows  the  pulse \n",
      "stream  mechanism  in  more  detail.  The synaptic  weight  is  stored  in  digital  memory \n",
      "local to the operator.  Each synaptic operator has an  excitatory and inhibitory  pulse \n",
      "stream  input  and  output.  The  resultant  product  of  a  synaptic  operation,  Tij Vj\n",
      ",  is \n",
      "added  to  the  running  total  propagating  down  either  the  excitatory  or  inhibitory \n",
      "channel.  One binary bit  (the  MSBit)  of the  stored  Tij  determines whether  the con(cid:173)\n",
      "tribution  is excitatory or inhibitory. \n",
      "The  incoming  excitatory  and  inhibitory  pulse  stream  inputs  to  a  neuron  are \n",
      "integrated  to \n"
     ]
    }
   ],
   "source": [
    "# Now let's take at the first paper in our dataset - one from 1987. This paper's plaintext was provided by\n",
    "# the NeurIPS website directly.\n",
    "\n",
    "print(papers.loc[0, 'text'][:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Here we can see that the formatting is slightly different from the PDF-converted papers. There is a bit more whitespace, and page numbers are present. Outside of that, the same challenges regarding images and equations are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilistic Inference of Hand Motion from Neural\n",
      "\n",
      "Activity in Motor Cortex\n",
      "\n",
      "Y. Gao M. J. Black\u0001\n",
      "\n",
      "E. Bienenstock\u0003\u0002\n",
      "\n",
      "S. Shoham\u0004\n",
      "\n",
      "J. P. Donoghue\u0002\n",
      "\n",
      " Division of Applied Mathematics, Brown University, Providence, RI 02912\n",
      "\n",
      "\u0001 Dept. of Computer Science, Brown University, Box 1910, Providence, RI 02912\n",
      "\n",
      "\u0004 Princeton University, Dept. of Molecular Biology Princeton, NJ, 08544\n",
      "\n",
      "\u0002 Dept. of Neuroscience, Brown University, Providence, RI 02912\n",
      "\n",
      "gao@cfm.brown.edu, black@cs.brown.edu, elie@dam.brown.edu,\n",
      "\n",
      "sshoham@princeton.com, john donoghue@brown.edu\n",
      "\n",
      "Abstract\n",
      "\n",
      "Statistical learning and probabilistic inference techniques are used to in-\n",
      "fer the hand position of a subject from multi-electrode recordings of neu-\n",
      "ral activity in motor cortex. First, an array of electrodes provides train-\n",
      "ing data of neural ﬁring conditioned on hand kinematics. We learn a non-\n",
      "parametric representation of this ﬁring activity using a Bayesian model\n",
      "and rigorously compare it with previous models using cross-validation.\n",
      "Second, we infer a posterior probability distribution over hand motion\n",
      "conditioned on a sequence of neural test data using Bayesian inference.\n",
      "The learned ﬁring models of multiple cells are used to deﬁne a non-\n",
      "Gaussian likelihood term which is combined with a prior probability for\n",
      "the kinematics. A particle ﬁltering method is used to represent, update,\n",
      "and propagate the posterior distribution over time. The approach is com-\n",
      "pared with traditional linear ﬁltering methods; the results suggest that it\n",
      "may be appropriate for neural prosthetic applications.\n",
      "\n",
      "1 Introduction\n",
      "\n",
      "This paper explores the use of statistical learning methods and probabilistic inference tech-\n",
      "niques for modeling the relationship between the motion of a monkey’s arm and neural\n",
      "activity in motor cortex. Our goals are threefold: (i) to investigate the nature of encoding\n",
      "in motor cortex, (ii) to characterize the probabilistic relationship between arm kinematics\n",
      "(hand position or velocity) and activity of a simultaneously recorded neural population, and\n",
      "(iii) to optimally reconstruct (decode) hand trajectory from population activity to smoothly\n",
      "control a prosthetic robot arm (cf [14]).\n",
      "\n",
      "A multi-electrode array (Figure 1) is used to simultaneously record the activity of 24 neu-\n",
      "rons in the arm area of primary motor cortex (MI) in awake, behaving, macaque monkeys.\n",
      "This activity is recorded while the monkeys manually track a smoothly and randomly mov-\n",
      "\n",
      "\f\u0004\u0006\u0005\n",
      "\n",
      "\u0012\u0014\u0013\n",
      "\u0015\u0017\u0016\n",
      "\n",
      "\u001e\u0017\u001f\n",
      "\u0018\u001a\u0019\u001b\u0019\n",
      "\n",
      "C.\n",
      "\n",
      "Acrylic\n",
      "\n",
      "Connector\n",
      "\n",
      "Silicone\n",
      "\n",
      "Bone\n",
      "\n",
      "!\u0006\"\n",
      "\n",
      "White Matter\n",
      "\n",
      ",.-0/\u001b1\n",
      "\n",
      "564\n",
      "\n",
      "Figure 1: Multi-electrode array. A. 10X10 matrix of electrodes. Separation 4007 m (size\n",
      "4X4 mm). B. Location of array in the MI arm area. C. Illustration of implanted array\n",
      "(courtesy N. Hatsopoulos).\n",
      "\n",
      "ing visual target on a computer monitor [12]. Statistical learning methods are used to derive\n",
      "Bayesian estimates of the conditional probability of ﬁring for each cell given the kine-\n",
      "matic variables (we consider only hand velocity here). Speciﬁcally, we use non-parametric\n",
      "models of the conditional ﬁring, learned using regularization (smoothing) techniques with\n",
      "cross-validation. Our results suggest that the cells encode information about the position\n",
      "and velocity of the hand in space. Moreover, the non-parametric models provide a better\n",
      "explanation of the data than previous parametric models [6, 10] and provide new insight\n",
      "into neural coding in MI.\n",
      "\n",
      "Decoding involves the inference of the hand motion from the ﬁring rate of the cells. In par-\n",
      "ticular, we represent the posterior probability of the entire hand trajectory conditioned on\n",
      "the observed sequence of neural activity (spike trains). The nature of this activity results in\n",
      "ambiguities and a non-Gaussian posterior probability distribution. Consequently, we repre-\n",
      "sent the posterior non-parametrically using a discrete set of samples [8]. This distribution\n",
      "is predicted and updated in non-overlapping 50 ms time intervals using a Bayesian estima-\n",
      "tion method called particle ﬁltering [8]. Experiments with real and synthetic data suggest\n",
      "that this approach provides probabilistically sound estimates of kinematics and allows the\n",
      "probabilistic combination of information from multiple neurons, the use of priors, and the\n",
      "rigorous evaluation of models and results.\n",
      "\n",
      "2 Methods: Neural Recording\n",
      "\n",
      "The design of the experiment and data collection is described in detail in [12]. Summa-\n",
      "rizing, a ten-by-ten array of electrodes is implanted in the primary motor cortex (MI) of\n",
      "a Macaque monkey (Figure 1) [7, 9, 12]. Neural activity in motor cortex has been shown\n",
      "to be related to the movement kinematics of the animal’s arm and, in particular, to the\n",
      "direction of hand motion [3, 6]. Previous behavioral tasks have involved reaching in one\n",
      "of a ﬁxed number of directions [3, 6, 14]. To model the relationship between continuous,\n",
      "smooth, hand motion and neural activity, we use a more complex scenario where the mon-\n",
      "key performs a continuous tracking task in which the hand is moved on a 2D tablet while\n",
      "holding a low-friction manipulandum that controls the motion of a feedback dot viewed on\n",
      "a computer monitor (Figure 2a) [12]. The monkey receives a reward upon completion of\n",
      "a successful trial in which the manipulandum is moved to keep the feedback dot within a\n",
      "pre-speciﬁed distance of the target. The path of the target is chosen to be a smooth random\n",
      "walk that effectively samples the space of hand positions and velocities: measured hand\n",
      "positions and velocities have a roughly Gaussian distribution (Figure 2b and c) [12]. Neu-\n",
      "ral activity is ampliﬁed, waveforms are thresholded, and spike sorting is performed off-line\n",
      "to isolate the activity of individual cells [9]. Recordings from 24 motor cortical cells are\n",
      "measured simultaneously with hand kinematics.\n",
      "\n",
      "\n",
      "\u0001\n",
      "\u0002\n",
      "\u0003\n",
      "\u0007\n",
      "\b\n",
      "\t\n",
      "\n",
      "\u000b\n",
      "\f\n",
      "\n",
      "\u000b\n",
      "\u000e\n",
      "\n",
      "\u000f\n",
      "\u0010\n",
      "\t\n",
      "\u000e\n",
      "\n",
      "\b\n",
      "\u0005\n",
      "\f\n",
      "\u0011\n",
      "\u0010\n",
      "\u001c\n",
      "\u001d\n",
      " \n",
      "!\n",
      "#\n",
      "$\n",
      "%\n",
      "&\n",
      "'\n",
      "(\n",
      ")\n",
      ")\n",
      "*\n",
      "+\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "\fMonitor\n",
      "\n",
      "Target\n",
      "\n",
      "Tablet\n",
      "\n",
      "Trajectory\n",
      "\n",
      "Manipulandum\n",
      "\n",
      "a\n",
      "\n",
      "25\n",
      "\n",
      "20\n",
      "\n",
      "15\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "0\n",
      "\n",
      "b\n",
      "\n",
      "c\n",
      "\n",
      "16\n",
      "\n",
      "14\n",
      "\n",
      "12\n",
      "\n",
      "10\n",
      "\n",
      "8\n",
      "\n",
      "6\n",
      "\n",
      "4\n",
      "\n",
      "2\n",
      "\n",
      "0\n",
      "\n",
      "Figure 2: Smooth tracking task. (a) The target moves with a smooth random walk. Distri-\n",
      "bution of the position (b) and velocity (c) of the hand. Color coding indicates the frequency\n",
      "with which different parts of the space are visited. (b) Position: horizontal and vertical\n",
      "\n",
      "axes represent  and \u0001 position of the hand. (c) Velocity: the horizontal axis represents\n",
      "direction, \u0002\u0004\u0003\u0006\u0007\n",
      "\t\u000b\u0003\n",
      "\n",
      ", and the vertical axis represents speed, \f .\n",
      "\n",
      "3\n",
      "\n",
      "\u0011\u0013\u0012\n",
      "\n",
      "\u000f\u000e\n",
      "\n",
      "\u001bcell 3\n",
      "\n",
      "cell 16\n",
      "\n",
      "cell 19\n",
      "\n",
      "2.5\n",
      "\n",
      "2\n",
      "\n",
      "1.5\n",
      "\n",
      "1\n",
      "\n",
      "0.5\n",
      "\n",
      "0\n",
      "\n",
      "Figure 3: Observed mean conditional ﬁring rates in 50 ms intervals for three cells given\n",
      "hand velocity. The horizontal axis represents the direction of movement,\n",
      "\n",
      "0 cm/s to 12 cm/s. Color ranges from dark blue (no measurement) to red (approximately 3\n",
      "spikes).\n",
      "\n",
      "\u0007 , in radians\n",
      "to\u0003 ). The vertical axis represents speed, \f , and ranges from\n",
      "\n",
      "(“wrapping” around from \u0002\u0004\u0003\n",
      "\n",
      "3 Modeling Neural Activity\n",
      "\n",
      "Figure 3 shows the measured mean ﬁring rate within 50 ms time intervals for three cells\n",
      "conditioned on the subject’s hand velocity. We view the neural ﬁring activity in Figure 3\n",
      "as a stochastic and sparse realization of some underlying model that relates neural ﬁring\n",
      "to hand motion. Similar plots are obtained as a function of hand position. Each plot can\n",
      "be thought of as a type of “tuning function” [12] that characterizes the response of the cell\n",
      "conditioned on hand velocity.\n",
      "In previous work, authors have considered a variety of\n",
      "models of this data including a cosine tuning function [6] and a modiﬁed cosine function\n",
      "[10]. Here we explore a non-parametric model of the underling activity and, adopting a\n",
      "Bayesian formulation, seek a maximum a posterior (MAP) estimate of a cell’s conditional\n",
      "ﬁring.\n",
      "\n",
      "Adopting a Markov Random Field (MRF) assumption [4], let the velocity space,\n",
      "\n",
      "\u001c\u001e\u001d\n",
      ", be discretized on a &(')'\n",
      "*+&(')' grid. Let g be the array of true (unobserved) condi-\n",
      "\f! \"\u0007!#%$\n",
      "tional neural ﬁring and , be the corresponding observed mean ﬁring. We seek the posterior\n",
      "\n",
      "probability\n",
      "\n",
      "(1)\n",
      "\n",
      "-/. g 01,123\u001d5476\n",
      "\n",
      ".98:-/.9;\n",
      "\n",
      "-/.\n",
      "\n",
      "6<0>=?6@2A4CB\n",
      "\n",
      "DFE/G\n",
      "\n",
      "=?6<0H=?6?IJ2K2\n",
      "\n",
      "\u000e\n",
      "\u0010\n",
      "\u0014\n",
      "\u0015\n",
      "\u0016\n",
      "\u0017\n",
      "\u0018\n",
      "\u0019\n",
      "\u001a\n",
      "\u001f\n",
      "\f0.18\n",
      "\n",
      "0.16\n",
      "\n",
      "0.14\n",
      "\n",
      "0.12\n",
      "\n",
      "0.1\n",
      "\n",
      "0.08\n",
      "\n",
      "0.06\n",
      "\n",
      "0.04\n",
      "\n",
      "0.02\n",
      "\n",
      "0\n",
      "\n",
      "−2\n",
      "\n",
      "−4\n",
      "\n",
      "−6\n",
      "\n",
      "−8\n",
      "\n",
      "−10\n",
      "\n",
      "0\n",
      "−3\n",
      "\n",
      "−2\n",
      "\n",
      "−1\n",
      "\n",
      "0\n",
      "\n",
      "a\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "−12\n",
      "−3\n",
      "\n",
      "−2\n",
      "\n",
      "−1\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "b\n",
      "\n",
      "'\u0003\u0002\u0005\u0004\u0007\u0006 .\n",
      "\n",
      ":\n",
      "\n",
      ".9;\n",
      "\n",
      "0H=\n",
      "\n",
      "0>=\n",
      "\n",
      ";\u000f\u000e\n",
      "\n",
      "\u0010\u0012\u0011\u0012\u0013\u0015\u0014\n",
      "\n",
      "respectively, =\n",
      "\n",
      "6 and =\n",
      "\n",
      "6 are the observed and true\n",
      "\n",
      "th neighboring\n",
      "\n",
      "= ). (a) Probability of ﬁring variation com-\n",
      "\n",
      "The ﬁrst term on the right hand side represents the likelihood of observing a particular ﬁring\n",
      ". Here we compare two generative models of the neural\n",
      "\n",
      "(b) Logarithm of the distributions shown to provide detail.\n",
      "\n",
      "is a normalizing constant independent of g, ;\n",
      "\n",
      "where 8\n",
      "mean ﬁring at velocity \u001c\n",
      "velocity of \u001c\n",
      "rate ;\n",
      "spiking process within 50 ms; a Poisson model,-\n",
      "\n",
      "Figure 4: Prior probability of ﬁring variation (\n",
      "puted from training data (blue). Proposed robust prior model (red) plotted for\u0001\n",
      "I represents the ﬁring rate for th\n",
      ", and the neighbors are taken to be the four nearest velocities (\t\n",
      "\u001d\u000b\n",
      " ).\n",
      "\u0002\u0006=A2 \u001f\n",
      "\u0004\u0012\u0001\n",
      "\n",
      "6 given that the true rate is =\u000f6\n",
      "\n",
      ", and a Gaussian model,-\n",
      "\n",
      ",\n",
      "the variation of neural activity in velocity space. The MRF prior states that the ﬁring,\n",
      "\n",
      "corresponds to an assumption that the ﬁring rate varies smoothly. A robust prior assumes\n",
      ", (derivatives of the\n",
      "\n",
      ", at velocity \u001c depends only on the ﬁring at neighboring velocities. We consider two\n",
      "= : Gaussian and “robust”. A Gaussian prior\n",
      "ﬁring rate in the \f and \u0007 directions) and implies piecewise smooth data. The two spatial\n",
      "\n",
      "The second term is a spatial prior probability that encodes our expectations about\n",
      "possible prior models for the distribution of\n",
      "a heavy-tailed distribution of the spatial variation (see Figure 4),\n",
      "\u0004?\u0003\u0017\u0001\u0019\u0018\u001b\u001a\u001d\u001c\n",
      "\n",
      "sian+Gaussian, and Poisson+Robust) are ﬁt to the training data as shown in Figure 5.G\n",
      "\n",
      "The various models (cosine, a modiﬁed cosine (Moran and Schwartz [10]), Gaus-\n",
      "\n",
      "In the case of the Gaussian+Gaussian and Poisson+Robust models, the optimal value of\n",
      "\n",
      "\u0004?\u0003\u0017\u0001\u0019\u0018\u001b\u001a\u001d\u001c\n",
      "\n",
      "2(\u001f\n",
      "\u001f)!\n",
      "\n",
      "\u0004\u0012\u0001\n",
      "\n",
      "=?6\n",
      "\n",
      "priors are\n",
      "\n",
      "\u0004\u0007\u0001%$\n",
      "\u001f'&\n",
      "\n",
      "-#\"\n",
      "\n",
      "the\u0001 parameter is computed fo\n"
     ]
    }
   ],
   "source": [
    "# Now let's take a look at another paper from before 2020, where the plaintext was provided by the NeurIPS website\n",
    "# directly. This paper was manually selected because it contains images, equations, and tables.\n",
    "\n",
    "paper = papers[papers['name'] == 'Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex']\n",
    "print(paper.iloc[0, 2][:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "We notice that page numbers are absent from this paper - so page numbers must have been phased out from earlier years of the conference. Additionally, the table comes across similarly to the PDF-converted papers - it contains all the data but is not formatted tabularly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerations\n",
    "\n",
    "Given that there may be critical information in the images, tables, and equations of these papers, it might be worthwhile exploring the use of PyMuPDF's Markdown formatter - which converts PDFs into Markdown. This might aid in preserving some of the information. It also might make it easier to parse the papers into chunks - if we decide that would improve the RAG system.\n",
    "\n",
    "Also, considering that the plaintext of papers pre-2020 (provided directly from the NeurIPS website) and papers provided after 2020 (converted from PDFs using PyMuPDF) have different formatting - it might be worthwhile to consider using the same PDF conversion process for all the papers to try to make formatting slightly more standardized. Although, the underlying paper PDFs might not have consistent formatting from year to year.\n",
    "\n",
    "Of note, is that all of these would be preprocessing steps - which only happen once. Which provides us a bit more leeway as far as scalability is concerned. (I.e., adding more preprocessing steps make take longer for the preprocessing pipeline to run, but since it's only run once or on a batch basis, that might be worth it if it makes the RAG responses better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academic-paper-explorer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
