Unnamed: 0,year,name,text
20281,2023,Optimal testing using combined test statistics across independent studies,"Optimal testing using combined test statistics across
independent studies
Lasse Vuursteen⇤
Delft Institute of Applied Mathematics
Delft University of Technology
l.vuursteen@tudelft.nl
Botond Szabó
Department of Decision Sciences
and Institute for Data Science and Analytics
Bocconi University
botond.szabo@unibocconi.it
Aad van der Vaart
Delft Institute of Applied Mathematics
Delft University of Technology
a.w.vandervaart@tudelft.nl
Harry van Zanten
Mathematics Department
Vrije Universiteit Amsterdam
j.h.van.zanten@vu.nl
Abstract
Combining test statistics from independent trials or experiments is a popular method
of meta-analysis. However, there is very limited theoretical understanding of the
power of the combined test, especially in high-dimensional models considering
composite hypotheses tests. We derive a mathematical framework to study standard
meta-analysis testing approaches in the context of the many normal means model,
which serves as the platform to investigate more complex models.
We introduce a natural and mild restriction on the meta-level combination functions
of the local trials. This allows us to mathematically quantify the cost of compressing
m trials into real-valued test statistics and combining these. We then derive
minimax lower and matching upper bounds for the separation rates of standard
combination methods for e.g. p-values and e-values, quantifying the loss relative
to using the full, pooled data. We observe an elbow effect, revealing that in certain
cases combining the locally optimal tests in each trial results in a sub-optimal
meta-analysis method and develop approaches to achieve the global optima. We
also explore the possible gains of allowing limited coordination between the trial
designs. Our results connect meta-analysis with bandwidth constraint distributed
inference and build on recent information theoretic developments in the latter ﬁeld.
1
Introduction
Given multiple data sets relating to the same hypothesis, one would like to combine the evidence.
Sometimes, the full data sets are not available (e.g. due to privacy or proprietary reasons) or difﬁcult
to combine directly (e.g. due to the different experimental or observational setups). In such cases, the
analysis must be carried out on the basis of the published results for each of the studies. Such “meta-
analysis” can increase the statistical power by combining individually inconclusive or moderately
signiﬁcant tests, while keeping the false positive rate under control. Therefore, meta-analysis has
received a lot of attention in various ﬁelds, for instance in genetics and system biology, when studying
rare variants [4, 16] or in deep learning, for few shot image recognition and neural architecture search,
see the review article [24].
⇤
37th Conference on Neural Information Processing Systems (NeurIPS 2023).
The outcomes of the studies concerning hypothesis tests are, typically, summarized as real-valued
test statistics and/or associated p-values. One expects the combination of m such p-values to
result in an increase in power, but one also expects to pay a price relative to computing a test
on the basis of the full, pooled data of the m trials. The question of how to optimally combine
independent real-valued test statistics concerning the same hypothesis into a single test has an
extensive literature. A multitude of methods for combining independent tests of signiﬁcance exist.
For combining p-values, this starts with Fisher, Tippett and Pearson in the nineteen-thirties, see
[42, 18, 32, 36, 21, 28, 45, 14, 31, 50, 48, 12, 47] and references therein. In Section 3, we collect and
describe the most popular and frequently used p-value combination techniques.
As noted in [9], there does not exist a general uniformly most powerful p-value combination method
for all alternative hypotheses. The distribution of a p-value or its underlying test statistic under the al-
ternative hypothesis should be taken into consideration when selecting a method of combination. The
performance of different p-value combination techniques was investigated extensively by empirical
experiments in various synthetic and real world scenarios, see for instance [29, 51]. However, a uni-
ﬁed, general theoretical description is lacking, especially in non-trivial, multi-dimensional composite
testing problems, where the likelihood ratio test is not necessarily uniformly most powerful.
E-values are an increasingly popular and important notion of evidence, see [35, 22, 34]. E-values
allow the combination of several tests in a straightforward manner while preserving the prescribed
level of the tests (see Section 3.2). Formally, e-values are nonnegative random variables whose
expected values under the null hypothesis are bounded by one. In contrast to p-values deﬁned
by probabilities, e-values are deﬁned by expectation. This imposes signiﬁcant differences in their
interpretation, application and combination compared to the more standard p-values. However, as
for p-values, very little is known about the power of these combination procedures. Theoretical
results focus on speciﬁc optimality criteria, for instance the worst-case growth-rate (GROW), see
[22]. However, these do not directly imply guarantees on the testing power, which is the main focus
in practice.
Our focus is on multidimensional models, where a certain loss in power is to be expected, since
combining multidimensional data into a real-valued statistic (e.g. p-value or e-value) requires
data compression. Typically, summary statistics are combined by some “reasonable” function
Cm : Rm ! R, where “reasonable” means that Cm should not exploit the richness of the real
numbers to encode the data in full. We aim to quantify the loss of summarizing, the gain of
performing a meta-analysis and the best testing strategies in the individual experiments meta-analysis.
We consider the signal detection problem in the many normal means model, see Section 2 for
the detailed description. One possible interpretation of this testing problem is to learn whether
a treatment has an effect on any of the dimensions investigated. This model is directly applied
in several ﬁelds where high-dimensional statistics and machine learning settings are concerned,
such as detecting differentially expressed genes [33, 27, 30, 41, 15], bankruptcy prediction for
publicly traded companies using Altman’s Z-score in ﬁnance [5, 6], separation of the background
and source in astronomical images [13, 23], and wavelet analysis [1, 26]. Furthermore, the model
allows for tractable computations and it typically serves as the platform to investigate more difﬁcult
statistical and learning problems, including high- and inﬁnite-dimensional models, see for instance
[25, 43, 15, 20]. In each experiment j 2 {1, ..., m} the observations are summarized by an appropriate
real-valued summary statistic S(j). These local test statistics (e.g. p- or e-values) are combined
into Cm(S(1), . . . , S(m)). We consider a general class of combination functions Cm, requiring only
Hölder type continuity. This introduces only a mild restriction, and includes many standard meta-
analysis techniques, for instance the standard p-value combination methods (see Section 3.1); e-value
techniques (see Section 3.2); and other ad hoc and natural test statistic combination approaches, see
the beginning of Section 3 for additional examples.
Our setting provides a principled and uniﬁed framework to study the power of standard meta-analysis
testing methods. Within the framework of the many normal means model, we derive a minimax
lower bound for the testing (separation) error and provide test statistics with associated combination
methods that attain this theoretical limit (up to a logarithmic factor). Our results reveal that there is a
certain unavoidable loss associated with compressing the data of each experiment to a real valued test
statistic. We see that while it is always possible to obtain better testing rates using m trials instead of
the best possible test based on a single trial, there is always a loss incurred when compared to the
2
full, pooled data and optimal test in moderate- to large dimensional problems. Our theoretical results
quantify these gains and losses in terms of the dimension d, sample size n and number of trials m.
Furthermore, we observe an elbow effect, which occurs when the number of trials is large compared
to the dimension of the signal. In this regime, combinations of the (locally) optimal test in each
individual trial performs sub-optimally as a whole when aggregated and meta-analysis approaches
based on directional test statistics are shown to perform better. Finally, we show that the performance
of the meta-level tests can substantially improve (in certain regimes, depending on d, m, n) if a
certain amount of coordination between the trials is allowed (e.g. by having access to the same
random seed). For the theoretical analysis of meta-analysis techniques we derive connections with
the distributed statistical learning literature under communication constraints. Our paper builds on the
recent information theoretical developments in distributed testing [2, 39, 40], allowing us to address
several fundamental questions for the ﬁrst time with mathematical rigor.
The paper is organised as follows. In Section 2 we introduce the mathematical framework we
consider in our investigation and present the corresponding minimax testing lower bound results.
Next in Subsection 2.1 we show that the derived results are sharp by providing several meta-analysis
approaches attaining the limits. Then we investigate the beneﬁts of allowing a mild coordination
between the trials in Subsection 2.2. We collect and discuss the standard p- and e-value combination
methods in Section 3 and demonstrate our theoretical results numerically on synthetic data sets in
Section 4. We discuss our results and derive conclusions in Section 5. The proofs of our results are
deferred to the Appendix. In Section A.1 we present the proof of our main results while the proofs of
the technical lemmas are given in A.2.
Notation: For two positive sequences an, bn we write an . bn if the inequality an Cbn holds
for some universal positive constant C. Similarly, we write an ⇣bn if an . bn and bn . an hold
simultaneously and let an ⌧bn denote that an/bn = o(1). Furthermore, we use the notations a _ b
and a ^ b for the maximum and minimum, respectively, between a and b. Throughout the paper c and
C denote global constants whose value may change from one line to another.
2
Main results
In our analysis, we consider the localized version of the many normal means model, tailored to
investigating meta-analysis techniques. We assume that in each local trial or experiment j 2
{1, ..., m} we observe a d-dimensional random variable X(j) 2 Rd, subject to
X(j) = f +
1
pnZ(j),
Z(j) iid
⇠N(0, Id),
j = 1, ..., m,
(1)
for some unknown f 2 Rd. We denote by Pf the joint distribution of the observations and let Ef be
the corresponding expectation. We note that this framework is equivalent to having n independent
N(f, Id) observations within each local sample.
Our goal is to test the presence or absence of the “signal component” f 2 Rd. More formally, we
consider the simple null hypothesis H0 : f = 0 versus composite alternative hypothesis H⇢: kfk2 ≥
⇢, for some ⇢> 0. This corresponds to testing for joint signiﬁcance of variables, such as the presence
of an effect of a treatment on any of the dimensions investigated. The difﬁculty in distinguishing the
hypotheses depends on the effect size, the sample size and the dimension d. Here, ⇢can be seen as
the smallest effect size deemed important.
For a {0, 1}-valued test T, deﬁne the testing risk R(T, H⇢) as the sum of the Type I error probability
and worst case Type II error probability, i.e.
R(T, H⇢) := P0(T = 1) + sup
f2H⇢
Pf (T = 0) .
(2)
In the case of a single trial (i.e. m = 1), this testing problem is known to have minimax separation
rate or “detection boundary” ⇢2 ⇣
p
d/n.
This means that if ⇢2 ≫
p
d/n, there exist consistent2 tests T ⌘Td,n in the sense that R(T, H⇢) ! 0,
whilst no consistent tests exist when ⇢2 ⌧
p
d/n. That is, for effect sizes of smaller order than
2For any asymptotics in ⇢, d and n such that ⇢2 ≫
p
d/n.
3
p
d/n, the null hypothesis cannot be consistently distinguished from the alternative hypothesis. Such
a testing rate is attainable through a chi-square test based on kpnX(1)k2
2 (see e.g. [7]).
In case of m trials, if the full data were pooled (with aggregated sample size nm), the minimax
separation rate would be
p
d/(mn). However, pooling the data might not be possible or allowed
in practice and often only real-valued test statistics are available that describe the signiﬁcance in
the local problems (e.g. a p- or an e-value). These m test statistics S(j), j = 1, ..., m, then can
be combined with some combination function Cm : Rm ! R, providing the test statistic in the
meta-analysis. We now ask whether the above pooled testing rate is attainable with this meta-analysis
procedure.
Without any restrictions on the test statistics S = (S(1), . . . , S(m)) or the combination function Cm,
any of the conventional optimal “full-data” tests can be reconstructed, since the real numbers and
mappings between the real numbers form an overly rich class. We wish to restrict our analysis to S
and Cm that are reasonable in practice and capture (most of) the relevant meta-analysis methods as
listed in Section 3.
Based on each of the local observations X(j), a real-valued test statistic S(j) is computed, where
each S(j) is a function of X(j) and possibly a source of randomness U (j) independent of X :=
(X(1), . . . , X(m)).
Assumption 1. For measurable functions fj : Rd ⇥R ! R and independent random variables
U (1), . . . , U (m) which are independent of the data X, the j-th test statistic S(j) = fj(X(j), U (j))
satisﬁes E0|S(j)| M, for some M > 0, j = 1, . . . , m.
We consider Hölder continuous combination functions Cm : Rm ! R. Arguably, this is the most
important assumption in ruling out bijections between Rd and R. This ensures that a small change in
the underlying local test statistics cannot result in a large change in the combination of test statistics
Cm(S(1), . . . , S(m)).
Assumption 2. There exist L, p, q > 0 such that for all s, s0 2 Rm
|Cm(s) −Cm(s0)| L
⇣m
X
j=1
|sj −s0
j|p⌘q
.
(3)
The special case of p = 2 and q = 1/2 leads to Lipschitz continuous functions. Assumption 1 and
Assumption 2 should be considered in conjunction. By rescaling and centering test statistics S(j),
one can typically obtain test statistics satisfying Assumption 1. Rescaling and centering typically
does affect how the test statistics need to be combined, which might “break” Assumption 2.
Finally, following the standard testing approach, we compare the aggregated test statistics
Cm(S(1), . . . , S(m)) to a threshold value. If the combined test statistics result in a large enough
value, the null hypothesis of no effect is rejected. We note here that two sided tests can be written as
one-sided tests through straightforward transformations (e.g. centering and taking absolute value).
More formally, we consider tests T↵of level ↵satisfying the following assumption.
Assumption 3. There exists a strictly decreasing function ↵7! ↵so that
T↵=
n
Cm(S(1), . . . , S(m)) ≥↵
o
(4)
satisﬁes P0T↵↵.
The map ↵7! ↵could be taken as the quantile function of Cm(S(1), . . . , S(m)) under its null
distribution if it is appropriately standardized. If E0Cm(S(1), . . . , S(m)) is bounded in m, we can
choose ↵equal to 1/↵times the upper bound, in view of Markov’s inequality.
Our ﬁrst main result, Theorem 1 below, establishes a lower bound for tests of the form (4) and
Cm and S satisfying the above assumptions. More concretely, under our assumptions, any test
T↵(of level ↵0.1) has large Type II-error under alternatives with ⇢2 of smaller order than
(pm ^
d
log(m))
p
d/(mn). When the number of trials is small compared to the dimension (i.e.
m log2(m) d2), this means that the separation rate is at least
p
d/(pmn). Thus even though
there is a beneﬁt in terms of separation rate compared to testing based on just a single trial, the
4
gain is at best the square root of what one would gain based on testing on the pooled data. When
m log2(m) ≥d2, the rate in the lower bound changes to d
p
d/(mn log(m)), resulting in an elbow
effect.
Theorem 1. Let S(1), . . . , S(m), Cm and T↵satisfy Assumptions 1–3 with T↵of level ↵2 (0, 0.1].
Then there exists a constant c > 0 depending only on L, p, q and M, such that if
⇢2 c
(pm ^
d
log(m))
p
d
mn
,
(5)
it holds for all n, m, d 2 N that
sup
f2H⇢
Pf (T↵= 0) ≥3/4.
(6)
Remark 1. The ranges of values 0 < ↵0.1 and β = 3/4 for the Type I and II errors, respectively,
are arbitrary. Similar results hold for different choices as well. For instance, one can take arbitrary
↵2 (0, 1/5] and β 2 (0, 2/3], see the proof of the theorem for details. The result implies in particular
that consistent testing is not possible for signals of a smaller order than the right hand side of (5),
where asymptotics can be considered in n, m and d simultaneously.
In the next section we show that the lower bounds in the theorems above are sharp (up to a logarithmic
factor).
2.1
Rate optimal combination methods
To attain the lower bound rate derived in Theorem 1, different tests can be considered. The optimal
rate displays an elbow effect around m ⇣d2. When the dimension is large compared to the number
of trials m (i.e. m . d2), strategies that combine p-values for the optimal local tests (based on
kpnX(j)k2
2 ⇠H0 χ2
d), turn out to achieve the optimal rate, as exhibited below. Such a test statistic is
invariant to the directionality of X(j) and invariant under the model in the sense that the resulting
power for the alternative Pf or Pg is the same as long as kfk2 = kgk2.
On the other hand, when the dimension is small compared to the number of trials (i.e. m & d2),
optimal strategies exhibited below use information on the direction of X(j). In fact, we show in
Theorem 4 in the Appendix that if no such information is available (i.e. the events deﬁned by the signs
of the (X(j))j=1,...,m vector are not contained in the sigma algebra generated by the test statistics S),
one cannot obtain a rate better than
p
d/(pmn). This implies that by combining the locally optimal
test statistics S(j) = kpnX(j)k2
2 (or their arbitrary functions, e.g. the corresponding local p-values)
would result in information loss and hence sub-optimal rates in the meta-analysis.
Furthermore, it turns out, in accordance with the empirical literature discussed in the introduction, that
there does not exist a uniquely best meta-analysis method. In fact, multiple standard meta-analysis
techniques provide (up to a logarithmic factor) optimal rates, see below for some standard approaches
attaining the lower bounds derived in Theorem 1.
First we consider the scenario when the dimension d of the model is large compared to the number
of trials m, i.e. m . d2. Locally the optimal test is based on the test statistic kpnX(j)k2
2
H0
⇠χ2
d. A
natural way to combine these statistics would be to sum these locally optimal test statistics to obtain
T↵=
8
<
:
m
X
j=1
)))
pnX(j))))
2
2 ≥F −1
χ2
dm(1 −↵)
9
=
; ,
(7)
which has level ↵. Alternatively, one could also apply p-value combination methods, such as Fisher’s
or Edgington’s method based on the p-value p(j) = 1 −Fχ2
d(kpnX(j)k2
2), see Section 3. Lemma 6
in the appendix establishes that these tests are rate optimal.
Second, consider the case that the number of trials is large compared to the dimension, i.e. m & d2.
Rate optimal tests can be constructed based on a variation of Edgington’s or Stouffer’s method, see
Section 3 for their descriptions. Taking a partition of {1, . . . , m} = [d
i=1Ji where |Ji| ⇣m/d and
5
setting S(j) = pnX(j)
i
if j 2 Ji, the meta-level test
T↵=
8
>
<
>
:
p
d
m
d
X
i=1
0
@ X
j2Ji
S(j)
1
A
2
≥d−1/2F −1
χ2
d (1 −↵)
9
>
=
>
;
(8)
achieves the lower bounds. The above test is similar to employing Stouffer’s method for each of the
coordinates and averaging, i.e. computing approximately m/d iid p-values p(j) = Φ(pnX(j)
i
) for
j 2 Ji and applying the inverse Gaussian CDF Φ−1(p(j)). Alternatively, the following variation of
Edgington’s method,
T↵=
8
>
<
>
:
p
d
m
d
X
i=1
0
@ X
j2Ji
✓
p(j) −1
2
◆1
A
2
≥↵
9
>
=
>
;
,
(9)
is also rate optimal, as proven in Lemma 7 in the appendix. Essentially, these strategies divide the
trials accross the d different directions, and combines the evidence for each of the directions. Theorem
4 afﬁrms that the information on the “direction” of the data is crucial to achieve the optimal rate in the
m & d2 case, by showing that strategies that do not contain such information (rotationally invariant
strategies such as norm-based test statistics) achieve the rate
p
d/(pmn) at best. We summarize the
above testing upper bounds in the theorem below.
Theorem 2. For all ↵, β 2 (0, 1) there exist S, Cm : Rm ! R and tests T↵of level ↵satisfying
Assumptions 1–3 such that if
⇢2 ≥C↵,β
(pm ^ d)
p
d
mn
,
(10)
we have
sup
f2H⇢
Pf (T↵= 0) β
for a large enough constant C↵,β > 0 depending only on ↵, β 2 (0, 1), for all n, m, d 2 N.
2.2
Beneﬁts of coordination between the trials
When the dimension is small relative to the number of trials, as exhibited in the previous section,
optimal strategies include information on the directionality of the observation vector. In this section
we show that in this regime, there could be an additional beneﬁt from allowing mild coordination
between the trials through employing shared randomness, e.g. a shared random seed between the
trials. Such a phenomenon has been observed before in the distributed testing literature [3, 2, 39, 40],
which forms the basis of our analysis below.
We consider the following variation on Assumption 1, where the key difference is that the source of
randomness is allowed to be shared between the m trials.
Assumption 4. For functions fj : Rd ⇥R ! R and a random variable U which is independent of
the data X, the j-th test statistic S(j) = fj(X(j), U) satisﬁes E0|S(j)| M for some M > 0 and
all j = 1, . . . , m.
Test statistics satisfying this assumption shall be referred to as shared randomness (or public coin)
protocols.
The theorem below establishes the optimal rate when coordination through shared randomness is
allowed. When the number of trials is small compared to the dimension (i.e. m . d/ log m),
there is no difference between protocols that coordinate using shared randomness or those without
coordination. In fact, the optimal rate (⇢2 ⇣
p
d/(pmn)) in this case is reached by the test (7) or
the ones below it, which do not employ shared randomness. However, when the number of trials is
large compared to the dimension (i.e. m & d), the testing rate substantially improves in the shared
randomness protocols.
Theorem 3. Let S(1), . . . , S(m), Cm and T↵satisfy Assumptions 2–4. Then there exists a constant
c > 0 depending only on L, p, q and M, such that if
⇢2 c
⇣pm ^
q
d
log(m)
⌘p
d
mn
,
(11)
6
it holds that sup
f2H⇢
Pf (T↵= 0) > 2/3 for all n, m, d 2 N and any level ↵2 (0, 0.1].
At the same time, for all ↵, β 2 (0, 1) there exists a constant C↵,β > 0 depending only on β, L, p, q,
the function ↵7! ↵and M, such that if
⇢2 ≥C↵,β
⇣pm ^
p
d
⌘p
d
mn
(12)
it holds that sup
f2H⇢
Pf (T↵= 0) β for some test T↵of level ↵satisfying Assumptions 2–4.
Remark 2. Similarly to Theorem 1 the choice of ranges 0 < ↵0.1 and β = 2/3 in the lower
bound result is arbitrary, other choices are also possible as presented in the proof.
A shared randomness method that attains the rate in (12) is given next. Consider drawing an
orthonormal d ⇥d matrix U taking values from the uniform measure on such matrices. As a
test statistic, each trial computes (pnUX(j))1, which is a N(0, 1) random variable under the null
hypothesis. A level ↵2 (0, 1) meta-level test is then given by combining the local test statistics as
T↵:=
8
<
:
55 1
pm
m
X
j=1
(pnUX(j))1
55 ≥Φ−1(1 −↵/2)
9
=
; ,
(13)
where Φ is the standard Gaussian CDF. The core idea here is that for each trial, the same 1-dimensional
projection of the d -dimensional data is computed, where the projection is taken uniformly at random
and the test is conducted along the projected direction. The above method corresponds to Stouffer’s
method for the p-values p(j) = Φ(pn(UX(j))1) for j = 1, . . . , m. Lemma 8 in the appendix shows
that the above test attains a small Type II error probability whenever ⇢2 & d/(mn).
3
Examples for meta-analysis methods
Combinations of independent test statistics that fall into the framework of Assumptions 1– 4 are
subject to the rate optimality theory established by the main theorems in Section 2. In this section, we
look into common methods for combining p-values, e-values and other test-statistics, as mentioned in
the introduction.
When the distribution under the null hypothesis of the test statistics are known, certain combinations
are natural. For example, the sum of normal or chi-square test statistics is again normal or chi-square
distributed, respectively. Similarly, voting based mechanisms typically rely on summing Bernoulli
random variables. It is easy to see that these and similar combinations methods fall into the framework
of Assumptions 1–4.
For more speciﬁc test statistics, such as p-values or e-values, many general combination methods
have been introduced in the literature. We cover some of the most prominent combination approaches
for p-values and e-values in Section 3.1 and Section 3.2, respectively. The list of methods is certainly
non-exhaustive and many more combination methods exist, but they serve as context for the range of
techniques covered by our general theory. Our main results allow establishing lower bound rates for
the ones listed below, whilst in Sections 2.1 and 2.2 attainability of these rates by some of the listed
methods was exhibited.
3.1
Combinations of p-values
If p(1), . . . , p(m) are p-values obtained from m independent test statistics concerning the same
hypothesis, then under the null p(j) ⇠iid U(0, 1). One can aim to combine the m p-values to form
a test T↵⌘T↵(p(1), . . . , p(m)) with Type I error probability ↵, which hopefully has higher power
than a test based on one of the individual p-values. Below we list standard methods in the literature.
• Fisher’s method [18]. Because the variables −2 log p(j)’s are iid χ2
2-distributed under the
null hypothesis, their sum follows a χ2
2m-distribution. Therefore the combination method
Pm
j=1 −2 log p(j) results in a χ2
2m distributed random variable, and the corresponding
quantile function provides level-↵one-sided tests at the meta-level.
7
• Similar ﬂavour to Fisher’s method are the combinations Pm
j=1 −log(1 −p(j)) (Pearson’s
method [32]), Pm
j=1 −log p(j)(1 −p(j)) (the logit method / Mudholkar and George method
[31]) and m−1/2 Pm
j=1(p(j) −1/2) (Edgington’s method [14]).
• Order-based methods such as Tippett’s method [42] based on min{p(1), . . . , p(m)}
H0
⇠
Beta(1, m).
• Methods based on inverse CDF’s, such as by Stouffer et.
al [36] based on
m−1/2Pm
j=1Φ−1(p(j)) ⇠N(0, 1) under the null hypothesis.
• Generalized averages as considered in [48], T↵=
7
ar,mMr,m(p(1), . . . , p(m)) ↵
 
,
where Mr,m(p(1), . . . , p(m)) equals
9
m−1Pm
j=1(p(j))r:1/r for r 2 R \ {0}, the geometric
mean, minimimum (i.e. Tippett’s method) and maximum for r = 0, r ! −1, and r ! 1,
respectively. For r 2 {−1} [ [1/(m −1), 1], ar,m can be taken to obtain precisely level
↵tests (i.e. P0T↵= ↵). We note that this means that canonical multiple testing methods
(see e.g. [19]) such as Bonferroni’s correction (which corresponds with taking as Mr,m the
minimum and ar,m = m) also fall within our framework.
Lemma 1 below shows that all the methods mentioned above fall into the framework of Assumptions
1–4. This means that the error rate lower bounds of Theorem 1 and Theorem 3 respectively, apply
to the p-value combination methods listed above. That is, one cannot attain a better separation rate
when considering the worst case Type II error probability for the alternative hypothesis in (2), with
any of the p-value combination methods listed above. Whether Assumption 1 or 4 applies depends
on whether shared randomness is used in generating the p-values. To conﬁrm that Assumptions 3 and
2 apply to tests based on the combined p-values, some algebra is needed. The proof of the lemma is
deferred to the appendix.
Lemma 1. Consider p-values p(1), . . . , p(m), where each p(j) depends on the local data X(j) and
possibly local randomness that is independent of the data. For each of the combination methods for
p-values mentioned above and corresponding test T↵of level ↵2 (0, 1), the conclusions of Theorem
1 holds.
We remark that the p-values are obtained using shared randomness (i.e. in the sense of Assumption
1), the lower bound rate of Theorem 3 applies. Furthermore, as exhibited in Sections 2.1 and 2.2,
for p-values corresponding to well chosen test statistics, these combination methods can achieve the
theoretical limits established in Theorems 1 and 3, respectively.
3.2
Combining e-values
An e-value is a nonnegative random variable E such that supP02H0 P0E 1. The threshold test
corresponding to E of level ↵is
{E ≥↵−1}. This test yields a so called strict p-value; for P0 2 H0
we have P0(E ≥↵−1) ↵by Markov’s inequality.
E-values lend themselves for combining outcomes of independent studies for two main reasons. First,
they are easy to combine, see Section 4 in [49] for an indepth discussion of speciﬁc combination
functions for independent e-values. Second, they are robust to misspeciﬁcation and offer optional
stopping/continuation guarantees [22]. Common examples of e-values are Bayes factors and like-
lihood ratios, which are nonnegative and have expectation equal to 1 in the case of a simple null
hypothesis such as considered in this article.
Several combination methods (e-merging functions) were proposed in the literature. For instance,
the product of independent e-values is also again an e-value. This was shown to weakly dominate
any other combination of independent e-values in the sense that ⇧m
j=1E(j) ≥Cm(E), for any
E = (E(j)) 2 [1, 1)m and E 7! Cm(E) such that Cm(E(1), . . . , E(m)) is an e-value for any
independent e-values E(1), . . . , E(m), see [49]. Similarly, the average of e-values is again an e-
value. The product and the average are admissible in the sense that there is no e-merging function
that strictly dominates them on [0, 1]m. The lemma below shows that these two, arguably most
prominent e-value combination methods fulﬁll Assumptions 1– 4 and hence the lower bounds derived
in Theorems 1 and 3 apply.
8
Lemma 2. Consider e-values E(1), . . . , E(m), where each E(j) depends on the local data X(j) and
possibly local randomness that is independent of the data. Let Cm : Rm ! R correspond to either
the average or the product and let T↵be the corresponding threshold test of level ↵2 (0, 1),
T↵=
n
Cm(E(1), . . . , E(m)) ≥↵−1o
.
If Cm is the product, assume in addition that E0| log E(j)| is uniformly bounded. Then, the conclusion
of Theorem 1 holds. In case the e-values are generated using shared randomness, then Theorem 3
applies.
4
Simulations
In this section, we investigate the numerical performance of the testing strategies outlined in Section
2.1 on synthetic data sets. We compare the tests based on their receiver operating characteristic
(ROC) curve. For a range of signiﬁcance levels we compute for each tests the “true positive rate”
(TPR) and “false positive rates” or (FPR), i.e. the fraction of the simulation runs in which the test
correctly identiﬁes the underlying signal, falsely rejects the null hypothesis, respectively. Plotting the
TPR against the FPR (both given as a function of the signiﬁcance level) provides us the ROC curve,
visualizing the diagnostic ability of the test.
Figure 1: ROC curves for different values of d, whilst keeping m = 20, n = 30, ⇢2 =
p
d/(4n).
From left to right, top to bottom: d = 2, d = 5, d = 10, d = 20.
In our simulations we set m = 20, n = 30, let d range from 2 to 20 and take ⇢2 =
p
d/(4n). This
value of ⇢2 corresponds to a signal that is almost indistinguishable from noise using just a single
trial, whilst consistently detectable if the data were to be pooled with m ⇡20 (which increases the
signal size to noise ratio effectively by a factor
p
20 > 4. For each level ↵2 {0.01, 0.02, . . . , 0.99}
we compute the power for different combination strategies 100 times, each time drawing a different
f 2 Rd with kfk2 = ⇢according to fi = d−1/2⇢Ri and Ri iid Rademacher random variables for
i = 1, . . . , d. As combination strategies, we compare the strategies (7), (13) and (8) from Section 2,
9
which are called “chi-square combined”, “coordinated directional” and “uncoordinated directional”
in the legend of Figure 4. In addition, we display the ROC curves for the chi-square test based on
pooled data (“chi-square pooled”) and that of a single trial (“single trial”).
We make the following observations, in line with our theoretical ﬁndings. The meta-analysis methods
based on combining the locally optimal chi-squared test statistics (yellow curves) substantially out-
performed the chi-squared test statistics based on a single trial (blue curve), but was substantially
worse than the chi-square test based on the pooled data (pink curve). Second note that the large
dimensional case (d = 10 and d = 20) the best strategy is indeed to combine the local chi-square
statistics (yellow curve), while in the low dimensional setting (d = 2) it is more advantageous to
combine the directional test statistics X(j)
i
(blue curve). Finally, note that allowing coordination
between the trials by a shared randomness protocol can result in improved performance (green
curve) compared to the independent experiments (blue curve). In fact this approach provides the best
meta-analysis method in the small dimensional setting (e.g. d = 2 and d = 5 for small ↵, which is
the most interesting case).
In the appendix, Section A.6, we explore eight additional simulation settings, where we consider
larger values of d and m. Whilst these simulations do not reveal additional phenomena to the ones
observed in Figure 4, they do give insight into the relative performance of the testing methods for
different values of d and m.
5
Discussion
We brieﬂy summarize our main contributions and discuss possible extensions and research directions.
First, by establishing a connection between meta-analysis and distributed learning under communica-
tion constraints, we have provided a uniﬁed, theoretical framework for evaluating the behaviour of
standard meta-analysis techniques. In our analysis, we considered the many normal means model, but
these results can be extended to other more complex models as well, building on the connection with
distributed computation. For example, minimax estimation rates under communication constraints
were derived for other parametric models [53], density estimation [8], signal-in-Gaussian-white-noise
[54, 38, 10], nonparametric regression [37] and in abstract settings [52] including binary and Poisson
regression, drift estimation, and more. The normal means model allows for a tractable analysis, but
results in this model are known to extend to more complicated models, such as discrete density testing
(see e.g. [11]). With the due technical work, our results are expected to translate to these settings as
well, but we leave this for future endeavor.
In the normal means model we show that by combining the locally optimal chi-square statistics at a
meta-level one can gain a factor of pm compared to using a single trial. Nevertheless, regardless
of the choice of the combination method, a factor of pm is lost compared to the scenario when
all data from all trials are at our disposal. This loss is clearly visible even in small sample sizes,
dimensions and trial numbers, as demonstrated in our numerical analysis, as can be seen in the
corresponding ROC curves. For more complex models, such a numerical study can be a ﬁrst step to
quantify the efﬁciency of the meta-analysis method. We have also shown that in the small dimension
- large number of trials setting combining the locally optimal chi-square statistics (or any rotationally
invariant statistics for that matter) results in information loss and sub-optimal accuracy. In this case,
better rates can be attained by test statistics based on the direction of the observations combined at the
meta-level. In practice, one often cannot choose which test statistics can be obtained from independent
trials. In such cases, the pm-factor loss in the case of e.g. rotationally invariant test statistics is of
interest when considering power calculations. Meta-analysis approaches based on directional test
statistics are designed for scenarios where individual datasets are not centrally collected, but there is
some level of coordination among experimenters.
The assumption throughout the paper of homogeneity between the trials (i.e. each trial consisting
of the same number of observations) simpliﬁes the presentation, but the results can be extended to
cases where the number of observations in each trial differ by constant factors. Situations where the
number of observations differs greatly (e.g. k ⌧m trials have as much observations as the other
m −k trials combined) are certainly of interest, but beyond the scope of this paper.
10
Acknowledgements: Co-funded by the European Union (ERC, BigBayesUQ, project number:
101041064). Views and opinions expressed are however those of the author(s) only and do not
necessarily reﬂect those of the European Union or the European Research Council. Neither the
European Union nor the granting authority can be held responsible for them. This research was
partially funded by a Spinoza grant of the Dutch Research Council (NWO).
References
[1] ABRAMOVICH, F., BENJAMINI, Y., DONOHO, D. L., AND JOHNSTONE, I. M. Adapting
to unknown sparsity by controlling the false discovery rate. The Annals of Statistics (2006),
584–653.
[2] ACHARYA, J., CANONNE, C. L., AND TYAGI, H. Distributed signal detection under communi-
cation constraints. In Conference on Learning Theory (2020), PMLR, pp. 41–63.
[3] ACHARYA, J., CANONNE, C. L., AND TYAGI, H. Inference Under Information Constraints I:
Lower Bounds From Chi-Square Contraction. IEEE Transactions on Information Theory 66, 12
(Dec. 2020), 7835–7855.
[4] AERTS, S., LAMBRECHTS, D., MAITY, S., VAN LOO, P., COESSENS, B., DE SMET, F.,
TRANCHEVENT, L.-C., DE MOOR, B., MARYNEN, P., HASSAN, B., ET AL. Gene prioritiza-
tion through genomic data fusion. Nature biotechnology 24, 5 (2006), 537–544.
[5] ALTMAN, E. I.
Financial ratios, discriminant analysis and the prediction of corporate
bankruptcy. The journal of ﬁnance 23, 4 (1968), 589–609.
[6] ALTMAN, E. I., IWANICZ-DROZDOWSKA, M., LAITINEN, E. K., AND SUVAS, A. Distressed
ﬁrm and bankruptcy prediction in an international context: A review and empirical analysis of
altman’s z-score model. Available at SSRN 2536340 (2014).
[7] BARAUD, Y. Non-asymptotic minimax rates of testing in signal detection. Bernoulli (2002),
577–606.
[8] BARNES, L. P., HAN, Y., AND ÖZGÜR, A. Lower bounds for learning distributions under
communication constraints via ﬁsher information. The Journal of Machine Learning Research
21, 1 (2020), 9583–9612.
[9] BIRNBAUM, A.
Combining independent tests of signiﬁcance.
Journal of the American
Statistical Association 49, 267 (1954), 559–574.
[10] CAI, T. T., AND WEI, H. Distributed nonparametric function estimation: Optimal rate of
convergence and cost of adaptation. The Annals of Statistics 50, 2 (2022), 698–725.
[11] CARTER, A. V. Deﬁciency distance between multinomial and multivariate normal experiments.
The Annals of Statistics 30, 3 (2002), 708 – 730.
[12] CHEN, Z. Optimal tests for combining p-values. Applied Sciences 12, 1 (2021), 322.
[13] CLEMENTS, N., SARKAR, S. K., AND GUO, W. Astronomical transient detection controlling
the false discovery rate. In Statistical challenges in modern astronomy V (2012), Springer,
pp. 383–396.
[14] EDGINGTON, E. S. An additive method for combining probability values from independent
experiments. The Journal of Psychology 80, 2 (1972), 351–363.
[15] EFRON, B. Large-scale inference: empirical Bayes methods for estimation, testing, and
prediction, vol. 1. Cambridge University Press, 2012.
[16] EVANGELOU, E., AND IOANNIDIS, J. P. Meta-analysis methods for genome-wide association
studies and beyond. Nature Reviews Genetics 14, 6 (2013), 379–389.
[17] FINNER, H., AND ROTERS, M. Log-concavity and inequalities for chi-square, f and beta
distributions with applications in multiple comparisons. Statistica Sinica (1997), 771–787.
11
[18] FISHER, R. A. Statistical methods for research workers. In Breakthroughs in statistics. Springer,
1992, pp. 66–70.
[19] FROMONT, M., LERASLE, M., AND REYNAUD-BOURET, P. Family-Wise Separation Rates
for multiple testing. The Annals of Statistics 44, 6 (2016), 2533 – 2563.
[20] GINE, E., AND NICKL, R. Mathematical Foundations of Inﬁnite-Dimensional Statistical
Models. Cambridge University Press, Cambridge, 2016.
[21] GOOD, I. On the weighted combination of signiﬁcance tests. Journal of the Royal Statistical
Society: Series B (Methodological) 17, 2 (1955), 264–265.
[22] GRÜNWALD, P., DE HEIDE, R., AND KOOLEN, W. M. Safe testing. In 2020 Information
Theory and Applications Workshop (ITA) (2020), pp. 1–54.
[23] GUGLIELMETTI, F., FISCHER, R., AND DOSE, V. Background–source separation in astro-
nomical images with bayesian probability theory–i. the method. Monthly Notices of the Royal
Astronomical Society 396, 1 (2009), 165–190.
[24] HOSPEDALES, T., ANTONIOU, A., MICAELLI, P., AND STORKEY, A. Meta-learning in neural
networks: A survey. IEEE transactions on pattern analysis and machine intelligence 44, 9
(2021), 5149–5169.
[25] INGSTER, Y. I. Minimax testing of nonparametric hypotheses on a distribution density in the
$l_p$ metrics. 333–337. Number: 2.
[26] JOHNSTONE, I. M., AND SILVERMAN, B. W. Needles and straw in haystacks: Empirical
Bayes estimates of possibly sparse sequences. The Annals of Statistics 32, 4 (2004), 1594 –
1649.
[27] KRÄMER, A., GREEN, J., POLLARD JR, J., AND TUGENDREICH, S. Causal analysis ap-
proaches in ingenuity pathway analysis. Bioinformatics 30, 4 (2014), 523–530.
[28] LIPTÁK, T. On the combination of independent tests. Magyar Tud Akad Mat Kutato Int Kozl 3
(1958), 171–197.
[29] LOUGHIN, T. M. A systematic comparison of methods for combining p-values from indepen-
dent tests. Computational statistics & data analysis 47, 3 (2004), 467–485.
[30] MALONE, B. M., TAN, F., BRIDGES, S. M., AND PENG, Z. Comparison of four chip-seq
analytical algorithms using rice endosperm h3k27 trimethylation proﬁling data. PloS one 6, 9
(2011), e25260.
[31] MUDHOLKAR, G. S., AND GEORGE, E. The logit statistic for combining probabilities-an
overview.
[32] PEARSON, K. On a new method of determining"" goodness of ﬁt"". Biometrika 26, 4 (1934),
425–442.
[33] QUACKENBUSH, J. Microarray data normalization and transformation. Nature genetics 32, 4
(2002), 496–501.
[34] SHAFER, G., ET AL. Testing by betting: A strategy for statistical and scientiﬁc communication.
Journal of the Royal Statistical Society: Series A (Statistics in Society) 184, 2 (2021), 407–431.
[35] SHAFER, G., SHEN, A., VERESHCHAGIN, N., AND VOVK, V. Test Martingales, Bayes Factors
and $p$-Values. Statistical Science 26, 1 (Feb. 2011), 84–101. arXiv: 0912.4269.
[36] STOUFFER, S. A., SUCHMAN, E. A., DEVINNEY, L. C., STAR, S. A., AND WILLIAMS JR,
R. M. The american soldier: Adjustment during army life.(studies in social psychology in
world war ii), vol. 1.
[37] SZABÓ, B., AND VAN ZANTEN, H. Adaptive distributed methods under communication
constraints. The Annals of Statistics 48, 4 (2020), 2347 – 2380.
12
[38] SZABÓ, B., AND VAN ZANTEN, H. Distributed function estimation: Adaptation using minimal
communication. Mathematical Statistics and Learning 5, 3 (2022), 159–199.
[39] SZABÓ, B., VUURSTEEN, L., AND VAN ZANTEN, H. Optimal distributed composite testing in
high-dimensional gaussian models with 1-bit communication. IEEE Transactions on Information
Theory 68, 6 (2022), 4070–4084.
[40] SZABÓ, B., VUURSTEEN, L., AND VAN ZANTEN, H. Optimal high-dimensional and non-
parametric distributed testing under communication constraints. The Annals of Statistics 51, 3
(2023), 909–934.
[41] THOMAS, J. G., OLSON, J. M., TAPSCOTT, S. J., AND ZHAO, L. P. An efﬁcient and
robust statistical modeling approach to discover differentially expressed genes using genomic
expression proﬁles. Genome Research 11, 7 (2001), 1227–1236.
[42] TIPPETT, L. H. C., ET AL. The methods of statistics. an introduction mainly for experimentalists.
The methods of statistics. An introduction mainly for experimentalists. (1941).
[43] TSYBAKOV, A. B. Introduction to nonparametric estimation. Springer series in statistics.
Springer, New York ; London, 2009. OCLC: ocn300399286.
[44] VAART, A. W. V. D. Asymptotic statistics. Cambridge series in statistical and probabilistic
mathematics. Cambridge University Press.
[45] VAN ZWET, W., AND OOSTERHOFF, J. On the combination of independent test statistics. The
Annals of Mathematical Statistics 38, 3 (1967), 659–680.
[46] VERSHYNIN, R. High-Dimensional Probability: An Introduction with Applications in Data
Science, 1 ed. Cambridge University Press, Sept. 2018.
[47] VOVK, V., WANG, B., AND WANG, R. Admissible ways of merging p-values under arbitrary
dependence. The Annals of Statistics 50, 1 (2022), 351–375.
[48] VOVK, V., AND WANG, R. Combining p-values via averaging. Biometrika 107, 4 (2020),
791–808.
[49] VOVK, V., AND WANG, R. E-values: Calibration, combination and applications. The Annals
of Statistics 49, 3 (2021), 1736–1754.
[50] WHITLOCK, M. C. Combining probability from independent tests: the weighted z-method is
superior to ﬁsher’s approach. Journal of evolutionary biology 18, 5 (2005), 1368–1373.
[51] YOON, S., BAIK, B., PARK, T., AND NAM, D. Powerful p-value combination methods to
detect incomplete association. Scientiﬁc reports 11, 1 (2021), 6980.
[52] ZAMAN, A., AND SZABÓ, B. Distributed nonparametric estimation under communication
constraints. arXiv preprint arXiv:2204.10373 (2022).
[53] ZHANG, Y., DUCHI, J., JORDAN, M. I., AND WAINWRIGHT, M. J. Information-theoretic
lower bounds for distributed statistical estimation with communication constraints. Advances in
Neural Information Processing Systems 26 (2013).
[54] ZHU, Y., AND LAFFERTY, J. Distributed nonparametric regression under communication
constraints. In International Conference on Machine Learning (2018), PMLR, pp. 6009–6017.
13
"
20282,2023,Regret-Optimal Model-Free Reinforcement Learning for Discounted MDPs with Short Burn-In Time,"Regret-Optimal Model-Free Reinforcement Learning
for Discounted MDPs with Short Burn-In Time
Xiang Ji ∗
Princeton
Gen Li †
CUHK
Abstract
A crucial problem in reinforcement learning is learning the optimal policy. We
study this in tabular infinite-horizon discounted Markov decision processes under
the online setting. The existing algorithms either fail to achieve regret optimality or
have to incur a high memory and computational cost. In addition, existing optimal
algorithms all require a long burn-in time in order to achieve optimal sample
efficiency, i.e., their optimality is not guaranteed unless sample size surpasses
a high threshold. We address both open problems by introducing a model-free
algorithm that employs variance reduction and a novel technique that switches the
execution policy in a slow-yet-adaptive manner. This is the first regret-optimal
model-free algorithm in the discounted setting, with the additional benefit of a low
burn-in time.
1
Introduction
In reinforcement learning (RL), a crucial task is to find the optimal policy that maximizes its expected
cumulative reward in any given environment with unknown dynamics. An immense body of literature
is dedicated to finding algorithms that solve this task with as few samples as possible, which is
the prime goal under this task. Ideally, one hopes to find an algorithm with a theoretical guarantee
of optimal sample efficiency. At the same time, this task might be accompanied with additional
requirements such as low space complexity and computational cost, as it is common that the state
and action spaces exhibit high dimensions in modern applications. The combination of these various
goals and requirements presents an important yet challenging problem in algorithm design.
The task of searching for optimal policy has been well-studied by existing work in the generative
setting [33; 34; 21; 1]. This fundamental setting allows the freedom of querying samples at any
state-action pair. In contrast, it is more realistic but difficult to consider the same task in the online
setting, in which samples can only be collected along trajectories generated from executing a policy
in the unknown Markov decision process (MDP). Solving this task with optimal sample efficiency
requires a careful balance between exploration and exploitation, especially when coupled with other
goals such as memory and computational efficiency.
MDPs can be divided into two types: the episodic finite-horizon MDPs and the infinite-horizon MDPs.
Although these two types of MDPs can be approached in similar ways under the generative setting,
there is a clear dichotomy between them in the online setting. In an episodic MDP, sample trajectories
are only defined in fixed-length episodes, so samples are collected in episodes, and a reset to an
arbitrary initial state occurs at the end of every online episode. Its transition kernel is usually assumed
to be non-stationary over time. In contrast, the transition kernel of an infinite-horizon MDP stays
stationary over time, and the online sample collection process amounts to drawing a single infinitely
long sample trajectory with no reset. These differences render most optimal algorithms for episodic
∗Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ 08544, USA.
†Department of Statistics, The Chinese University of Hong Kong, Hong Kong, China.
37th Conference on Neural Information Processing Systems (NeurIPS 2023).
MDPs suboptimal when applied to infinite-horizon MDPs. Without reset and non-stationarity, the
high dependency between consecutive trajectory steps in the infinite-horizon setting presents a new
challenge over the episodic setting. In this work, we consider the infinite-horizon discounted MDPs,
which is widely used in practice but still has some fundamental questions unanswered in theory.
1.1
Sample Efficiency in Infinite-Horizon MDPs
To evaluate the sample efficiency of online RL algorithms, a natural and widely-accepted metric is the
cumulative regret. It captures the performance difference between the optimal policy and the learned
policy of an algorithm over its online interactions with a given MDP. The notion of cumulative regret
was first introduced in the bandit literature and later adopted in the RL literature [2; 15]. It is profusely
used in the online episodic RL literature. Such works aim to prove regret guarantees for algorithms
and provide analyses that characterize such regret guarantees in terms of all problem parameters
such as state space, action space and sample size in a non-asymptotic fashion. A cumulative regret
guarantee can also suggest the sample complexity needed to reach a certain level of average regret.
In the online infinite-horizon setting, many works study a different metric called the sample complexity
of exploration, first introduced in [17]. In essence, given a target accuracy level ϵ, this metric
characterizes the total number of ϵ-suboptimal steps committed by an algorithm over an infinitely-
long trajectory in the MDP. While this is indicative of the sample efficiency of an algorithm, the focus
of this metric is very different from that of cumulative regret, as it only reflects the total number of
failures but does not distinguish their sizes. As [24; 12] point out, even an optimal guarantee on
the sample complexity of exploration can only be converted to a very suboptimal guarantee on the
cumulative regret. To obtain a more quantitative characterization of the total volume of failures in
the regime of finite samples, some works have turned to studying cumulative regret guarantees for
algorithms.
It was not until recently that some works [24; 51; 12; 18] begin to research into the problem of
cumulative regret minimization in infinite-horizon discounted MDPs. Among them, [51] focus on
linear MDPs while others study tabular MDPs. In this work, we study the regret minimization
problem in the tabular case. Hereafter and throughout, we denote the size of the state space, the size
of the action space and the discount factor of the problem MDP with S, A and γ, respectively, and let
T denote the sample size.
1.2
Model-Based and Model-Free Methods
Since modern RL applications are often large-scale, algorithms with low space complexity and
computational complexity are much desired. This renders the distinction between model-based
algorithms and model-free algorithms particularly important. The procedure of a model-based method
includes a model estimation stage that involves estimating the transition kernel and a subsequent
planning stage that searches the optimal policy in the learned model. Thus, O(S2A) space is required
to store the estimated model. This is unfavorable when the state space is large and a memory constraint
is present. Additionally, updating the transition kernel estimate brings a large computational burden.
In comparison, model-free methods do not learn the entire model and thus can run with o(S2A)
space. Notably, most value-based methods such as Q-learning only require storage of an estimated
Q-function, which can take as little as O(SA) memory. In the infinite-horizon discounted setting,
although UCBVI-γ in [12] can achieve optimal regret, its model-based nature exacts a O(S2A)
memory and computational cost; conversely, the algorithms in [24] and [18] are model-free but have
suboptimal regret guarantee.
1.3
Burn-in Cost in Regret-Optimal RL
Naturally, one aims to develop algorithms that find the optimal policy with the fewest number of
samples. In regards to regret, this motivates numerous works to work towards algorithms with
minimax-optimal cumulative regret. However, the job is not done once such an algorithm is found.
As can be seen in the episodic RL literature, algorithms that achieve optimal regret as sample
size T tends towards infinity can still have different performance in the regime when T is limited.
Specifically, for every existing algorithm, there exists a certain sample size threshold such that regret
is suboptimal before T exceeds it. Such threshold is commonly referred to as the initial burn-in time
of the algorithm. Therefore, it is of great interest to find an algorithm with low burn-in time so that it
2
Algorithm
Sample complexity
of exploration
Cumulative
Regret
Range of T with
optimal regret
Space
complexity
Delayed Q-learning
SA
(1−γ)8ϵ4
S
1
5 A
1
5 T
4
5
(1−γ)
9
5
never
SA
[35]
R-Max
S2A
(1−γ)6ϵ3
S
1
2 A
1
4 T
3
4
(1−γ)
7
4
never
S2A
[7]
UCB-Q
SA
(1−γ)7ϵ2
S
1
3 A
1
3 T
2
3
(1−γ)
8
3
never
SA
[8]
MoRmax
SA
(1−γ)6ϵ2
S
1
3 A
1
3 T
2
3
(1−γ)
7
3
never
S2A
[36]
UCRL
S2A
(1−γ)3ϵ2
S
2
3 A
1
3 T
2
3
(1−γ)
4
3
never
S2A
[20]
UCB-multistage
SA
(1−γ)
11
2 ϵ2
S
1
3 A
1
3 T
2
3
(1−γ)
13
6
never
SA
[49]
UCB-multistage-adv1
SA
(1−γ)3ϵ2
S
1
3 A
1
3 T
2
3
(1−γ)
4
3
never
SA
[49]
MAIN2
N/A
κ
q
(S4+S2A2)T
(1−γ)8
never
SA
[18]
Double Q-learning
N/A
q
SAT
(1−γ)5
never
SA
[24]
UCBVI-γ3
N/A
q
SAT
(1−γ)3
h
S3A2
(1−γ)4 , ∞

S2A
[12]
Q-SlowSwitch-Adv
N/A
q
SAT
(1−γ)3
h
SA
(1−γ)13 , ∞

SA
(This work)
Lower bound
SA
(1−γ)3ϵ2
q
SAT
(1−γ)3
N/A
N/A
[20]; [12]
Table 1: A comparison between our results and existing work in the online infinite-horizon discounted
setting. Logarithmic factors are omitted for clearer presentation. The second column shows the
sample complexity when the target accuracy ϵ is sufficiently small. The third column shows the
regret when sample size T is sufficiently large (beyond the burn-in period). The algorithms in the
first seven rows only have sample complexity results in their original works; their regret bounds are
derived from their respective sample complexity bounds and presented in this table for completeness.
Details about the conversions can be found in [12]. The fourth column lists the sample size range
in which regret optimality can be attained, which shows the burn-in time. We would like to point
out that the results in [12; 24] are under slightly different regret definitions from the regret definition
in [18] and this work. In fact, their regret metric can be more lenient, and our algorithm can also
achieve eO(
q
SAT
(1−γ)3 ) optimal regret under it. This is further discussed in Remark 1 and Appendix B.
can still attain optimal regret in the sample-starved regime. Such effort has been made by [21; 1] in
the generative setting and by [23; 26] in the online episodic setting. Yet, this important issue has not
been addressed in the infinite-horizon setting, as optimal algorithms all suffer long burn-in times.
Specifically, while UCBVI-γ in [12] achieves a state-of-the-art regret guarantee of eO
q
SAT
(1−γ)3

,
which they prove minimax-optimal, their theory does not guarantee optimality unless the samples
size T becomes as large as
T ≥
S3A2
(1 −γ)4 .
1UCB-multistage-adv achieves optimal sample complexity only in the high-accuracy regime when ϵ ≤
S−2A−2(1 −γ)14. This is similar to a burn-in threshold in that the optimal guarantee cannot be achieved unless
in a specific range.
2The regret analysis for MAIN assumes an ergodicity parameter κ.
3UCBVI-γ achieves optimal regret for T ≥
S3A2
(1−γ)4 only if the MDP satisfies SA ≥
1
1−γ .
3
This threshold can be prohibitively large when S and A are huge, which is true in most applications.
Thus, this makes reducing these factors in the burn-in cost particularly important. For instance, a
5-by-5 tic-tac-toe has a state space of size 325. While this is a manageable number in modern machine
learning, any higher power of it may cause computational difficulties; in contrast, the horizon of
this game is much smaller—no more than 25. Since no lower bound precludes regret optimality for
T ≥
SA
(1−γ)4 , one might hope to design an algorithm with smaller S and A factors in the burn-in cost
so that it can achieve optimality even in the sample-starved regime.
1.4
Summary of Contributions
While it is encouraging to see recent works have shown that in the discounted setting, model-
free methods can provide nearly optimal guarantees on sample complexity of exploration and that
model-based methods can provide nearly optimal finite-sample regret guarantees, there still lacks
a model-free approach that can attain regret optimality. In the orthogonal direction, there is still a
vacancy for algorithms that can attain optimal regret for a broader sample size range, i.e., with fewer
samples than
S3A2
poly(1−γ).
In fact, we can summarize these two lingering theoretical questions as follows:
Is there an algorithm that can achieve minimax regret optimality with low space complexity and
computational complexity in the infinite-horizon discounted setting, even when sample size is limited?
We answer this question affirmatively with a new algorithm Q-SlowSwitch-Adv, which uses variance
reduction and a novel adaptive switching technique. It is the first model-free algorithm that achieves
optimal regret in the infinite-horizon discounted setting. This result can be summarized as follows:
Theorem (informal). For any sample size T ≥
SA
poly(1−γ), Q-SlowSwitch-Adv is guaranteed to
achieve near-optimal cumulative regret eO
q
SAT
(1−γ)3

with space complexity O(SA) and computa-
tional complexity O(T).
A formal theorem is presented in Section 4; its proof can be found in the full version [14]. We also
provide a complete summary of related prior results in Table 1. A discussion about the additional
related work is deferred to Appendix A.
2
Problem Formulation
Let us specify the problem we aim to study in this section. Throughout this paper, we let ∆(X)
denote the probability simplex over any set X. We also introduce the notation [m] := {1, 2, · · · , m}
for a positive integer m.
2.1
Infinite-Horizon Discounted Markov Decision Process
We consider an infinite-horizon discounted Markov decision process (MDP) represented with
(S, A, γ, P, r). Notably, we consider a tabular one, in which S := {1, 2, · · · , S} denotes the state
space with size S and A := {1, 2, · · · , A} denotes the action space with size A. P : S × A →∆(S)
denotes the probability transition kernel in that P(·|s, a) ∈∆(S) is the transition probability vector
from state s ∈S when action a ∈A is taken. r : S × A →[0, 1] denotes the reward function, which
is assumed to be deterministic in this work. Specifically, r(s, a) is the immediate reward for taking
action a ∈A at state s ∈S. Lastly, γ denotes the discount factor for the reward, which makes
1
1−γ
the effective horizon.
A (stationary) policy π : S →∆(A) specifies a rule for action selection in that π(·|s) ∈∆(A) is the
action selection probability vector at state s ∈S. We overload this notation by letting π(s) denote
the action policy π takes at state s. Given a policy π, the Q-function of π is defined as
Qπ(s, a) := E
"" ∞
X
t=0
γtr(st, at)
 s0 = s, a0 = a
#
,
4
in which st+1 ∼P(·|st, at) for t ≥0 and at ∼π(·|st) for t ≥1. Moreover, the value function of π
is defined as
V π(s) := E
"" ∞
X
t=0
γtr(st, at)
 s0 = s
#
,
in which st+1 ∼P(·|st, at) and at ∼π(·|st) for t ≥0. The Q-function and value function satisfy
an equation, called the Bellman equation [6]:
Qπ(s, a) = r(s, a) + γEs′∼P (·|s,a) [V π(s′)] .
(1)
A policy π⋆is called an optimal policy if it maximizes the value function for all states simultaneously.
The optimal value function and optimal Q-function can be defined as
V ⋆(s) := max
π
V π(s) = V π⋆(s)
Q⋆(s, a) := max
π
Qπ(s, a) = Qπ⋆(s, a),
which satisfy
V ⋆(s) = V π⋆(s)
and
Q⋆(s, a) = Qπ⋆(s, a)
for any optimal policy π⋆. The optimal policy always exists and satisfies the Bellman optimality
equation [30]:
Qπ⋆(s, a) = r(s, a) + γEs′∼P (·|s,a)

max
a′∈A Qπ⋆(s′, a′)

= r(s, a) + γEs′∼P (·|s,a) [V ⋆(s′)] .
(2)
2.2
Online Learning in an Infinite-Horizon MDP
We consider the online (single-trajectory) setting, in which the agent is permitted to execute a total of
T steps sequentially in the MDP. More specifically, the agent starts from an arbitrary (and possibly
adversarial) initial state s1. At each step t ∈[T], the agent at state st computes policy πt, takes action
at based on πt(·|st), receives reward r(st, at), and transitions to state st+1 in the following step. At
the end of execution, the agent generates a trajectory (s1, a1, r1, s2, a2, r2, · · · , sT , aT , rT ), which
amounts to T samples.
2.3
Problem: Regret Minimization
As a standard metric to evaluate the performance of the aforementioned agent over a finite number of
T steps, the cumulative regret with respect to the sequence of stationary policies {πt}T
t=1 learned by
the algorithm is defined as follows:
Regret(T) :=
T
X
t=1

V ⋆(st) −V πt(st)

.
(3)
Verbally, the regret measures the cumulative suboptimality between the optimal policy and the
execution policy πt at each step throughout the T-step online interaction process. Naturally, one
aims to minimize this regret by finding an algorithm whose regret scales optimally in T. This would
require a strategic balance between exploration and exploitation, which can be difficult when sample
size T is small.
Remark 1. In the infinite-horizon setting, many prior works [12; 24] consider slightly different regret
definitions with respect to non-stationary policies. Specifically, at each st along the trajectory, this
different regret metric compares the optimal value function V ⋆(st) against the expected cumulative
reward of running the non-stationary policy {πk}∞
k=t starting from st. By doing this, it is effectively
evaluating the cumulative reward difference between the stationary optimal policy and a non-stationary
algorithm. While there exists no formal conversion between the regret defined in this way and the
one in (3), it is expected to be smaller and thus more easily controlled than (3), because the execution
policy πt improves over time. In addition, we can show our algorithm also achieves the same level of
5
Algorithm 1: Q-SlowSwitch-Adv
1 Initialize: ∀(s, a), Qlazy(s, a), Q(s, a), QUCB(s, a), QR(s, a), QM(s, a) ←
1
1−γ ;
N(s, a) ←0; V (s), V R(s) ←
1
1−γ ; QLCB(s, a), θ(s, a) ←0; D ←dict();
µref(s, a), σref(s, a), µadv(s, a), σadv(s, a), BR(s, a), δR(s, a) ←0; uswitch ←False;
uref(s) ←True; H = ⌈
2
1−γ ⌉; ι = log SAT
δ
.
2 for t = 1, · · · , T do
3
Take action at = πt(st) = arg maxa Qlazy(st, a), and draw st+1 ∼P(·|st, at);
4
N(st, at) ←N(st, at) + 1; n ←N(st, at);
# Update the counter
5
ηn ←H+1
H+n;
# Update the learning rate
6
QUCB(st, at) ←update-q-ucb();
# Compute the UCB. See Algorithm 2
7
QLCB(st, at) ←update-q-lcb();
# Compute the LCB. See Algorithm 2
8
QR(st, at) ←update-q-reference();
# Compute the reference value. See Algorithm 2
9
Q(st, at) ←min{QR(st, at), QUCB(st, at), Q(st, at)};
10
V (st) ←maxa Q(st, a);
11
V LCB(st) ←max{maxa QLCB(st, a), V LCB(st)};
12
θ(st, at) ←θ(st, at) + QM(st, at) −Q(st, at).
# Track the staleness of current policy
13
if uswitch = True then
14
Qlazy ←update-q-lazy();
# Update execution policy’s Q-function (switch policy)
15
D ←dict();
# Reset the buffer
16
uswitch ←False;
17
D[(st, at)] ←Q(st, at).
# Add the new transition and Q entry to the buffer
18
""""""Switch policy when the staleness tracker is large""""""
19
if θ(st, at) >
1
1−γ then
20
QM(st, at) ←Q(st, at);
# Save the current Q entry for staleness determination later
21
uswitch ←True;
# Signal to switch policy at the following step
22
θ(st, at) ←0;
# Reset the staleness tracker
23
if V (st) −V LCB(st) > 3 then
24
V R(st) ←V (st), uref(st) = True;
25
else if uref(st) = True then
26
V R(st) ←V (st), uref(st) = False.
# Update the reference only on certain conditions
regret under this different definition with an analysis specifically tailored to our algorithm, which
is deferred to Appendix B. Furthermore, since the transition kernel in the infinite-horizon setting is
invariant over time and the optimal policy itself is also stationary, it is more natural to compare the
optimal policy to a stationary policy, e.g., the policy πt deployed by the algorithm at each step, as in
(3). Before this work, this has also been recently studied in [49; 18].
Notation.
Given any vector x ∈RSA that represents a function x : S × A →R, we use x(s, a) to
denote the entry corresponding to the state-action pair (s, a). We also denote the probability transition
vector at (s, a) with
Ps,a = P(· | s, a) ∈R1×S,
(4)
that is, given any V ∈RS, Ps,aV = Es′∼P (·|s,a)[V (s′)]. For two vectors x, y ∈RSA, we override
the notation x ≤y to mean that x(s, a) ≤y(s, a) in every dimension (s, a).
3
Algorithm
In this section, we present our algorithm Q-SlowSwitch-Adv and some relevant discussion.
6
Algorithm 2: Auxiliary functions
1 Function update-q-ucb():
2
QUCB(st, at) ←(1 −ηn)QUCB(st, at) + ηn

r(st, at) + γV (st+1) + cb
q
ι
(1−γ)3n

.
3 Function update-q-lcb():
4
QLCB(st, at) ←(1 −ηn)QLCB(st, at) + ηn

r(st, at) + γV LCB(st+1) −cb
q
ι
(1−γ)3n

.
5 Function update-q-lazy():
6
for every ((s, a), q) ∈D do Qlazy(s, a) ←q.
# Update execution policy with the buffer
7 Function update-q-reference():
8
[µref, σref](st, at) ←update-moments();
9
[δR, BR](st, at) ←update-reference-bonus();
10
bR ←BR(st, at) + (1 −ηn) δR(st,at)
ηn
+ cb
ι2
n3/4(1−γ)2 ;
11
QR(st, at) ←
(1 −ηn)QR(st, at) + ηn
"
20283,2023,Convolutional State Space Models for Long-Range Spatiotemporal Modeling,"Convolutional State Space Models for
Long-Range Spatiotemporal Modeling
Jimmy T.H. Smith*,2,4, Shalini De Mello1, Jan Kautz1, Scott W. Linderman3, 4, Wonmin Byeon1
1NVIDIA, *Work performed during internship at NVIDIA
2Institute for Computational and Mathematical Engineering, Stanford University.
3Department of Statistics, Stanford University.
4Wu Tsai Neurosciences Institute, Stanford University.
{jsmith14,scott.linderman}@stanford.edu
{shalinig,jkautz,wbyeon}@nvidia.com.
Abstract
Effectively modeling long spatiotemporal sequences is challenging due to the need
to model complex spatial correlations and long-range temporal dependencies simul-
taneously. ConvLSTMs attempt to address this by updating tensor-valued states
with recurrent neural networks, but their sequential computation makes them slow
to train. In contrast, Transformers can process an entire spatiotemporal sequence,
compressed into tokens, in parallel. However, the cost of attention scales quadrat-
ically in length, limiting their scalability to longer sequences. Here, we address
the challenges of prior methods and introduce convolutional state space models
(ConvSSM)1 that combine the tensor modeling ideas of ConvLSTM with the long
sequence modeling approaches of state space methods such as S4 and S5. First,
we demonstrate how parallel scans can be applied to convolutional recurrences to
achieve subquadratic parallelization and fast autoregressive generation. We then
establish an equivalence between the dynamics of ConvSSMs and SSMs, which
motivates parameterization and initialization strategies for modeling long-range
dependencies. The result is ConvS5, an efficient ConvSSM variant for long-range
spatiotemporal modeling. ConvS5 significantly outperforms Transformers and
ConvLSTM on a long horizon Moving-MNIST experiment while training 3×
faster than ConvLSTM and generating samples 400× faster than Transformers. In
addition, ConvS5 matches or exceeds the performance of state-of-the-art methods
on challenging DMLab, Minecraft and Habitat prediction benchmarks and enables
new directions for modeling long spatiotemporal sequences.
1
Introduction
Developing methods that efficiently and effectively model long-range spatiotemporal dependencies
is a challenging problem in machine learning. Whether predicting future video frames [1, 2],
modeling traffic patterns [3, 4], or forecasting weather [5, 6], deep spatiotemporal modeling requires
simultaneously capturing local spatial structure and long-range temporal dependencies. Although
there has been progress in deep generative modeling of complex spatiotemporal data [7–12], most
prior work has only considered short sequences of 20-50 timesteps due to the costs of processing long
spatiotemporal sequences. Recent work has begun considering sequences of hundreds to thousands
of timesteps [13–16]. As hardware and data collection of long spatiotemporal sequences continue
to improve, new modeling approaches are required that scale efficiently with sequence length and
effectively capture long-range dependencies.
1Implementation available at: https://github.com/NVlabs/ConvSSM.
37th Conference on Neural Information Processing Systems (NeurIPS 2023).
ABlock 2 RHW P ⇥HW P
217
5
A 2 R
214
B 2 RP ⇥U⇥kB⇥kB
215
X (t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
B 2 R
215
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
A 2 R
214
B 2 RP ⇥U⇥kB⇥kB
215
X (t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
,
p
,
p
( )
g
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X (t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
,
p
,
p
( )
g
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X (t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
pp
y
(
y
)
p
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
X(t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX(t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX (t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to desc
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard tim
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actu
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kern
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshapin
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagon
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM w
230
SSMs with the same dynamics as in S4/S5 methods that are important for mo
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange t
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional re
233
advantageous dynamical properties. Note the ConvSSM formulation is easier
234
forming the large, block-diagonal SSM state update explicitly and allows leveragin
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is
239
leverages parallel scans and deep SSM parameterization/initialization schemes.
240
6
X 0(t)i,j = ASSMX (t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there
216
is applicable to any HxWxC tensor (which is the only case we consider).
217
operations, and has a paper we can cite. I am open to suggestions, but w
218
cleaner way of describing what we need here. I feel like saying im2col
219
Proposition 3. Consider a ConvSSM state update as in (7)
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearran
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivale
223
into x(t), x0(t) 2 RHW P respectively, to the following different
224
x0(t) = ABlockx(t) + BBlocku
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk
226
columns formed by performing an im2col [74, 75] operation on
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially s
229
disretizing with a learnable timescale parameter to obtain AS
230
SSMs with the same dynamics as in S4/S5 methods that are i
231
dependencies. Due to the equivalence of Proposition 3, we can
232
the discrete ConvSSM state and input kernels of 9 to give the
233
advantageous dynamical properties. Note the ConvSSM form
234
forming the large, block-diagonal SSM state update explicitly and
235
convolution operations in modern deep learning frameworks [76
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: Con
237
In this section, we introduce ConvS5 which combines ideas
238
recurrences (Section 3.2) and the SSM connection (Section
239
leverages parallel scans and deep SSM parameterization/initiali
240
6
state, X(t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X(t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX(t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
( )i,j
X (t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX (t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X (t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
state, X(t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X(t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX(t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
state, X(t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
P ⇥Uk2
B
206
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
207
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
208
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
209
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
210
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
211
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
212
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
213
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
214
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
215
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
216
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
217
columns formed by performing an im2col [74, 75] operation on the input U(t).
218
Proof. See Appendix C.3.
219
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
220
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
221
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
222
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
223
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
224
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
225
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
226
convolution operations in modern deep learning frameworks [76–78].
227
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
228
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
229
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
230
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
231
3, we can implicitly parameterize a pointwise state kernel, A 2 RP ⇥P ⇥1⇥1 and input kernel
232
B 2 RP ⇥U⇥kB⇥kB in (7) using SSM parameters as used by S5 [36], AS5 2 RP ⇥P and BS5 2
233
RP ⇥(Uk2
B). We can discretize these S5 SSM parameters as discussed in Section 2.2.1 to give
234
AS5 = DISCRETIZEA(AS5, ∆),
BS5 = DISCRETIZEB(AS5, BS5, ∆),
(13)
and then rearrange to give the ConvS5 state update kernels:
235
AS5 2 RP ⇥P
rearrange
−−−−−−! AConvS5 2 RP ⇥P ⇥1⇥1
(14)
BS5 2 RP ⇥(Uk2
B)
rearrange
−−−−−−! BConvS5 2 RP ⇥U⇥kB⇥kB.
(15)
We then run the discretized ConvSSM system of Eqs (9, 10), where the recurrence can be computed
236
using parallel scans. Note that in practice this setup actually allows us to parameterize ConvS5 using
237
a diagonal state [34–36] which reduces the cost of applying the parallel scan in Proposition 2 to
238
O(LPHW). See Appendix A for a more detailed discussion of parameterization, initialization and
239
discretization.
240
6
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX (t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in G
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty pre
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrang
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a m
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X (t) and X
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenatin
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-r
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optim
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolut
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Propos
240
6
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX(t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another
207
is applicable to any HxWxC tensor (which is the only case we consider). It is als
208
operations, and has a paper we can cite. I am open to suggestions, but was havi
209
cleaner way of describing what we need here. I feel like saying im2col and cit
210
Proposition 3. Consider a ConvSSM state update as in (7) with 
211
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2
212
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the
213
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, aft
214
into x(t), x0(t) 2 RHW P respectively, to the following differential equ
215
x0(t) = ABlockx(t) + BBlocku(t),
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are blo
216
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is th
217
columns formed by performing an im2col [74, 75] operation on the inp
218
Proof. See Appendix C.3.
219
Thus, parameterizing and initializing ASSM with the specially structu
220
disretizing with a learnable timescale parameter to obtain ASSM an
221
SSMs with the same dynamics as in S4/S5 methods that are import
222
dependencies. Due to the equivalence of Proposition 3, we can then r
223
the discrete ConvSSM state and input kernels of 9 to give the convo
224
advantageous dynamical properties. Note the ConvSSM formulation
225
forming the large, block-diagonal SSM state update explicitly and allow
226
convolution operations in modern deep learning frameworks [76–78].
227
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
228
In this section, we introduce ConvS5 which combines ideas of par
229
recurrences (Section 3.2) and the SSM connection (Section 3.3).
230
leverages parallel scans and deep SSM parameterization/initialization
231
3, we can implicitly parameterize a pointwise state kernel, A 2 R
232
B 2 RP ⇥U⇥kB⇥kB in (7) using SSM parameters as used by S5 [36]
233
RP ⇥(Uk2
B). We can discretize these S5 SSM parameters as discussed i
234
AS5 = DISCRETIZEA(AS5, ∆),
BS5 = DISCRETIZ
and then rearrange to give the ConvS5 state update kernels:
235
AS5 2 RP ⇥P
rearrange
−−−−−−! AConvS5 2 RP ⇥P
BS5 2 RP ⇥(Uk2
B)
rearrange
−−−−−−! BConvS5 2 RP ⇥U⇥
We then run the discretized ConvSSM system of Eqs (9, 10), where the
236
using parallel scans. Note that in practice this setup actually allows us t
237
a diagonal state [34–36] which reduces the cost of applying the para
238
O(LPHW). See Appendix A for a more detailed discussion of param
239
discretization.
240
6
Given a 1-D sequence of inputs u1:L 2 RU, an RNN updates its state xk 2 RP at each time step k
73
with a state update equation xk = F(xk−1, uk), where F() represents some nonlinear function. For
74
example, one can represent a vanilla RNN (ignoring the bias term) as
75
xk = tanh(Axk−1 + Buk)
(1)
with state matrix A 2 RP⇥P , input matrix B 2 RP⇥U and the hyperbolic tangent function tanh()
76
applied elementwise. Other RNNs such as LSTM [13] and GRU [14] deﬁne more sophisticated
77
formulations of F() .
78
Convolutional recurrent neural networks [11, 12] (ConvRNNs) model spatiotemporal sequences
79
by replacing the 1-D states and inputs of RNNs with N-D tensors and replacing the matrix-vector
80
multiplications with convolutions as in convolutional neural networks (CNNs). Given a length L
81
sequence of frames, U1:L 2 RL⇥H0⇥W 0⇥U, with height H0, width W 0 and U features [SD: minor
82
point, but it is more typical to write WxH instead of HxW] [JS: Interesting, can you point me to some examples?
83
The H ⇥W convention matches the expected shapes of Torch and JAX/Flax’s conv2d operations and matches
84
the height and width of the rows ⇥columns of a matrix, so I currently have a preference to keep it as is], a
85
ConvRNN updates its state, Xk 2 RH⇥W⇥P , with a state update equation Xk = G(Xk−1, Uk),
86
2
an RNN updates its state xk 2 R
at each time step k
uk), where F() represents some nonlinear function. For
ignoring the bias term) as
nh(Axk−1 + Buk)
(1)
B 2 RP ⇥U and the hyperbolic tangent function tanh()
LSTM [13] and GRU [14] deﬁne more sophisticated
11, 12] (ConvRNNs) model spatiotemporal sequences
NNs with N-D tensors and replacing the matrix-vector
volutional neural networks (CNNs). Given a length L
, with height H0, width W 0 and U features [SD: minor
of HxW] [JS: Interesting, can you point me to some examples?
apes of Torch and JAX/Flax’s conv2d operations and matches
a matrix, so I currently have a preference to keep it as is], a
⇥P , with a state update equation Xk = G(Xk−1, Uk),
2
nh(Axk−1 + Buk)
(1)
B 2 RP ⇥U and the hyperbolic tangent function tanh()
LSTM [13] and GRU [14] deﬁne more sophisticated
1, 12] (ConvRNNs) model spatiotemporal sequences
NNs with N-D tensors and replacing the matrix-vector
volutional neural networks (CNNs). Given a length L
, with height H0, width W 0 and U features [SD: minor
of HxW] [JS: Interesting, can you point me to some examples?
apes of Torch and JAX/Flax’s conv2d operations and matches
a matrix, so I currently have a preference to keep it as is], a
⇥P , with a state update equation Xk = G(Xk−1, Uk),
2
2.2
Deep State Space Models
95
This section provides a brief background on the ideas of deep SSM methods such as S4 [33] and
96
S5 [36] that were developed for 1-D sequence modeling and whose insights we leverage for our
97
spatiotemporal ConvS5 approach.
98
2.2.1
Linear State Space Models
99
Given a continuous input signal u(t) 2 RU, a latent state x(t) 2 RP and an output signal y(t) 2 RM,
100
a continuous-time, linear SSM is deﬁned by the differential equation:
101
x0(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t),
(3)
and is parameterized by a state matrix A 2 RP ⇥P , an input matrix B 2 RP ⇥U, an output matrix
102
C 2 RM⇥P and a feedthrough matrix D 2 RM⇥U. Given a sampled sequence, u1:L 2 RL⇥U, the
103
SSM can be discretized to deﬁne a discrete-time SSM
104
xk = Axk−1 + Buk,
yk = Cxk + Duk,
(4)
where the discrete-time parameters are a function of the continuous-time parameters and a timescale
105
parameter, ∆. We deﬁne A = DISCRETIZEA(A, ∆) and B = DISCRETIZEB(A, B, ∆) where
106
DISCRETIZE() is a discretization method such as Euler, bilinear or zero-order hold [69].
107
[SD: I feel like the recurrence part of SSM is not very clearly explained and hence hard to follow/understand.
108
This is point is also important to understand the Parallel Scan and why that is important.] [JS: Agreed this is
109
important. Can you point toward the part that is most unclear or maybe what seems missing?]
110
2.2.2
State Space Layers: S4 and S5
111
Gu et al. [33] proposed the structured state space sequence (S4) layer, which efﬁciently models
112
long sequences with subquadratic complexity in the sequence length. An S4 layer consists of many
113
continuous-time parameterized single-input, single-output (SISO) SSMs, an explicit discretization
114
step with learnable timescale parameters, and position-wise nonlinear activation functions applied to
115
the SSM outputs to produce the layer output sequence. Multiple layers can be stacked to form deep
116
sequence models that can represent nonlinear systems. An S4 layer can use its linear SSMs to process
117
a sequence in parallel by using 1-D convolutions. It can also run its linear SSMs as RNNs to allow
118
for fast autoregressive generation. Smith et al. [36] showed that with several architecture changes,
119
the approach could be simpliﬁed and made more ﬂexible by replacing the convolutions with parallel
120
scans, resulting in the simpliﬁed S4 (S5) layer. An S5 layer replaces S4’s many SISO SSMs with one
121
multi-input, multi-output SSM as in 3 and is a fully recurrent, stateful model for both parallel and
122
sequential computations.
123
2.2.3
SSM Parameterization and Initialization
124
Parameterization and initialization are important aspects of deep SSMs such as S4 and S5 that
125
allows them to capture long-range dependencies. These methods rely on continuous-time SSM
126
parameters, explicitly performing a discretization step with a learnable timescale parameter, and
127
a deterministic initialization of the state matrix A with specially structured matrices inspired by
128
the HiPPO framework [47]. Many ablations have been performed highlighting the importance of
129
this setup for deep SSMs to achieve high performance on challenging long-range tasks [33, 36, 70].
130
Concurrent work [71] has studied these initializations in more detail and provides insight into the
131
favorable initial eigenvalue distributions and normalization effects of this setup.
132
3
This section provides a brief background on the ideas of deep SSM methods such as S4 [33] and
96
S5 [36] that were developed for 1-D sequence modeling and whose insights we leverage for our
97
spatiotemporal ConvS5 approach.
98
2.2.1
Linear State Space Models
99
Given a continuous input signal u(t) 2 RU, a latent state x(t) 2 RP and an output signal y(t) 2 RM,
100
a continuous-time, linear SSM is deﬁned by the differential equation:
101
x0(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t),
(3)
and is parameterized by a state matrix A 2 RP ⇥P , an input matrix B 2 RP ⇥U, an output matrix
102
C 2 RM⇥P and a feedthrough matrix D 2 RM⇥U. Given a sampled sequence, u1:L 2 RL⇥U, the
103
SSM can be discretized to deﬁne a discrete-time SSM
104
xk = Axk−1 + Buk,
yk = Cxk + Duk,
(4)
where the discrete-time parameters are a function of the continuous-time parameters and a timescale
105
parameter, ∆. We deﬁne A = DISCRETIZEA(A, ∆) and B = DISCRETIZEB(A, B, ∆) where
106
DISCRETIZE() is a discretization method such as Euler, bilinear or zero-order hold [69].
107
[SD: I feel like the recurrence part of SSM is not very clearly explained and hence hard to follow/understand.
108
This is point is also important to understand the Parallel Scan and why that is important.] [JS: Agreed this is
109
important. Can you point toward the part that is most unclear or maybe what seems missing?]
110
2.2.2
State Space Layers: S4 and S5
111
Gu et al. [33] proposed the structured state space sequence (S4) layer, which efﬁciently models
112
long sequences with subquadratic complexity in the sequence length. An S4 layer consists of many
113
continuous-time parameterized single-input, single-output (SISO) SSMs, an explicit discretization
114
step with learnable timescale parameters, and position-wise nonlinear activation functions applied to
115
the SSM outputs to produce the layer output sequence. Multiple layers can be stacked to form deep
116
sequence models that can represent nonlinear systems. An S4 layer can use its linear SSMs to process
117
a sequence in parallel by using 1-D convolutions. It can also run its linear SSMs as RNNs to allow
118
for fast autoregressive generation. Smith et al. [36] showed that with several architecture changes,
119
the approach could be simpliﬁed and made more ﬂexible by replacing the convolutions with parallel
120
scans, resulting in the simpliﬁed S4 (S5) layer. An S5 layer replaces S4’s many SISO SSMs with one
121
multi-input, multi-output SSM as in 3 and is a fully recurrent, stateful model for both parallel and
122
sequential computations.
123
2.2.3
SSM Parameterization and Initialization
124
Parameterization and initialization are important aspects of deep SSMs such as S4 and S5 that
125
allows them to capture long-range dependencies. These methods rely on continuous-time SSM
126
parameters, explicitly performing a discretization step with a learnable timescale parameter, and
127
a deterministic initialization of the state matrix A with specially structured matrices inspired by
128
the HiPPO framework [47]. Many ablations have been performed highlighting the importance of
129
this setup for deep SSMs to achieve high performance on challenging long-range tasks [33, 36, 70].
130
Concurrent work [71] has studied these initializations in more detail and provides insight into the
131
favorable initial eigenvalue distributions and normalization effects of this setup.
132
3
This section provides a brief background on the ideas of deep SSM methods such as S4 [33] and
96
S5 [36] that were developed for 1-D sequence modeling and whose insights we leverage for our
97
spatiotemporal ConvS5 approach.
98
2.2.1
Linear State Space Models
99
Given a continuous input signal u(t) 2 RU, a latent state x(t) 2 RP and an output signal y(t) 2 RM,
100
a continuous-time, linear SSM is deﬁned by the differential equation:
101
x0(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t),
(3)
and is parameterized by a state matrix A 2 RP ⇥P , an input matrix B 2 RP ⇥U, an output matrix
102
C 2 RM⇥P and a feedthrough matrix D 2 RM⇥U. Given a sampled sequence, u1:L 2 RL⇥U, the
103
SSM can be discretized to deﬁne a discrete-time SSM
104
xk = Axk−1 + Buk,
yk = Cxk + Duk,
(4)
where the discrete-time parameters are a function of the continuous-time parameters and a timescale
105
parameter, ∆. We deﬁne A = DISCRETIZEA(A, ∆) and B = DISCRETIZEB(A, B, ∆) where
106
DISCRETIZE() is a discretization method such as Euler, bilinear or zero-order hold [69].
107
[SD: I feel like the recurrence part of SSM is not very clearly explained and hence hard to follow/understand.
108
This is point is also important to understand the Parallel Scan and why that is important.] [JS: Agreed this is
109
important. Can you point toward the part that is most unclear or maybe what seems missing?]
110
2.2.2
State Space Layers: S4 and S5
111
Gu et al. [33] proposed the structured state space sequence (S4) layer, which efﬁciently models
112
long sequences with subquadratic complexity in the sequence length. An S4 layer consists of many
113
continuous-time parameterized single-input, single-output (SISO) SSMs, an explicit discretization
114
step with learnable timescale parameters, and position-wise nonlinear activation functions applied to
115
the SSM outputs to produce the layer output sequence. Multiple layers can be stacked to form deep
116
sequence models that can represent nonlinear systems. An S4 layer can use its linear SSMs to process
117
a sequence in parallel by using 1-D convolutions. It can also run its linear SSMs as RNNs to allow
118
for fast autoregressive generation. Smith et al. [36] showed that with several architecture changes,
119
the approach could be simpliﬁed and made more ﬂexible by replacing the convolutions with parallel
120
scans, resulting in the simpliﬁed S4 (S5) layer. An S5 layer replaces S4’s many SISO SSMs with one
121
multi-input, multi-output SSM as in 3 and is a fully recurrent, stateful model for both parallel and
122
sequential computations.
123
2.2.3
SSM Parameterization and Initialization
124
Parameterization and initialization are important aspects of deep SSMs such as S4 and S5 that
125
allows them to capture long-range dependencies. These methods rely on continuous-time SSM
126
parameters, explicitly performing a discretization step with a learnable timescale parameter, and
127
a deterministic initialization of the state matrix A with specially structured matrices inspired by
128
the HiPPO framework [47]. Many ablations have been performed highlighting the importance of
129
this setup for deep SSMs to achieve high performance on challenging long-range tasks [33, 36, 70].
130
Concurrent work [71] has studied these initializations in more detail and provides insight into the
131
favorable initial eigenvalue distributions and normalization effects of this setup.
132
3
S5 [36] that were developed for 1 D sequence modeling and whose insights we leverage for our
97
spatiotemporal ConvS5 approach.
98
2.2.1
Linear State Space Models
99
Given a continuous input signal u(t) 2 RU, a latent state x(t) 2 RP and an output signal y(t) 2 RM,
100
a continuous-time, linear SSM is deﬁned by the differential equation:
101
x0(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t),
(3)
and is parameterized by a state matrix A 2 RP ⇥P , an input matrix B 2 RP ⇥U, an output matrix
102
C 2 RM⇥P and a feedthrough matrix D 2 RM⇥U. Given a sampled sequence, u1:L 2 RL⇥U, the
103
SSM can be discretized to deﬁne a discrete-time SSM
104
xk = Axk−1 + Buk,
yk = Cxk + Duk,
(4)
where the discrete-time parameters are a function of the continuous-time parameters and a timescale
105
parameter, ∆. We deﬁne A = DISCRETIZEA(A, ∆) and B = DISCRETIZEB(A, B, ∆) where
106
DISCRETIZE() is a discretization method such as Euler, bilinear or zero-order hold [69].
107
[SD: I feel like the recurrence part of SSM is not very clearly explained and hence hard to follow/understand.
108
This is point is also important to understand the Parallel Scan and why that is important.] [JS: Agreed this is
109
important. Can you point toward the part that is most unclear or maybe what seems missing?]
110
2.2.2
State Space Layers: S4 and S5
111
Gu et al. [33] proposed the structured state space sequence (S4) layer, which efﬁciently models
112
long sequences with subquadratic complexity in the sequence length. An S4 layer consists of many
113
continuous-time parameterized single-input, single-output (SISO) SSMs, an explicit discretization
114
step with learnable timescale parameters, and position-wise nonlinear activation functions applied to
115
the SSM outputs to produce the layer output sequence. Multiple layers can be stacked to form deep
116
sequence models that can represent nonlinear systems. An S4 layer can use its linear SSMs to process
117
a sequence in parallel by using 1-D convolutions. It can also run its linear SSMs as RNNs to allow
118
for fast autoregressive generation. Smith et al. [36] showed that with several architecture changes,
119
the approach could be simpliﬁed and made more ﬂexible by replacing the convolutions with parallel
120
scans, resulting in the simpliﬁed S4 (S5) layer. An S5 layer replaces S4’s many SISO SSMs with one
121
multi-input, multi-output SSM as in 3 and is a fully recurrent, stateful model for both parallel and
122
sequential computations.
123
2.2.3
SSM Parameterization and Initialization
124
Parameterization and initialization are important aspects of deep SSMs such as S4 and S5 that
125
allows them to capture long-range dependencies. These methods rely on continuous-time SSM
126
parameters, explicitly performing a discretization step with a learnable timescale parameter, and
127
a deterministic initialization of the state matrix A with specially structured matrices inspired by
128
the HiPPO framework [47]. Many ablations have been performed highlighting the importance of
129
this setup for deep SSMs to achieve high performance on challenging long-range tasks [33, 36, 70].
130
Concurrent work [71] has studied these initializations in more detail and provides insight into the
131
favorable initial eigenvalue distributions and normalization effects of this setup.
132
3
equation would be
85
Xk = tanh(A ⇤Xk−1 + B ⇤Uk),
(2)
Xk = G(A ⇤Xk−1 + B ⇤Uk),
(3)
where ⇤is a spatial convolution operator with state kernel A 2 RP ⇥P ⇥kA⇥kA (using an [output
86
features, input features, kernel height, kernel width] convention), input kernel B 2 RP ⇥U⇥kB⇥kB
87
and the tanh() function is applied elementwise. More commonly, sophisticated updates such as
88
ConvLSTM [11] and ConvGRU [12] are used by making similar changes to the 1-D LSTM and GRU
89
equations respectively. ConvRNNs have been used for biomedical, robotics, trafﬁc modeling, weather
90
forecasting and numerous other applications [49–60] and many variants have been proposed [61–68].
91
2.2
Deep State Space Models
92
This section provides a brief background on the ideas of deep SSM methods such as S4 [33] and
93
S5 [36] that were developed for 1-D sequence modeling and whose insights we leverage for our
94
spatiotemporal ConvS5 approach.
95
2.2.1
Linear State Space Models
96
Given a continuous input signal u(t) 2 RU, a latent state x(t) 2 RP and an output signal y(t) 2 RM,
97
a continuous-time, linear SSM is deﬁned by the differential equation:
98
x0(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t),
(4)
and is parameterized by a state matrix A 2 RP ⇥P , an input matrix B 2 RP ⇥U, an output matrix
99
C 2 RM⇥P and a feedthrough matrix D 2 RM⇥U. Given a sampled sequence, u1:L 2 RL⇥U, the
100
SSM can be discretized to deﬁne a discrete-time SSM
101
xk = Axk−1 + Buk,
yk = Cxk + Duk,
(5)
where the discrete-time parameters are a function of the continuous-time parameters and a timescale
102
parameter, ∆. We deﬁne A = DISCRETIZEA(A, ∆) and B = DISCRETIZEB(A, B, ∆) where
103
DISCRETIZE() is a discretization method such as Euler, bilinear or zero-order hold [69].
104
2.2.2
State Space Layers: S4 and S5
105
Gu et al. [33] proposed the structured state space sequence (S4) layer, which efﬁciently models
106
long sequences with subquadratic complexity in the sequence length. An S4 layer consists of many
107
continuous-time parameterized single-input, single-output (SISO) SSMs, an explicit discretization
108
step with learnable timescale parameters, and position-wise nonlinear activation functions applied to
109
the SSM outputs to produce the layer output sequence. Multiple layers can be stacked to form deep
110
sequence models that can represent nonlinear systems. An S4 layer can use its linear SSMs to process
111
a sequence in parallel by using 1-D convolutions. It can also run its linear SSMs as RNNs to allow
112
for fast autoregressive generation. Smith et al. [36] showed that with several architecture changes,
113
the approach could be simpliﬁed and made more ﬂexible by replacing the convolutions with parallel
114
scans, resulting in the simpliﬁed S4 (S5) layer. An S5 layer replaces S4’s many SISO SSMs with one
115
multi-input, multi-output SSM as in 4 and is a fully recurrent, stateful model for both parallel and
116
sequential computations.
117
2.2.3
SSM Parameterization and Initialization
118
Parameterization and initialization are important aspects of deep SSMs such as S4 and S5 that
119
allows them to capture long-range dependencies. These methods rely on continuous-time SSM
120
parameters, explicitly performing a discretization step with a learnable timescale parameter, and
121
a deterministic initialization of the state matrix A with specially structured matrices inspired by
122
the HiPPO framework [47]. Many ablations have been performed highlighting the importance of
123
this setup for deep SSMs to achieve high performance on challenging long-range tasks [33, 36, 70].
124
Concurrent work [71] has studied these initializations in more detail and provides insight into the
125
favorable initial eigenvalue distributions and normalization effects of this setup.
126
3
equation would be
85
Xk = tanh(A ⇤Xk−1 + B ⇤Uk),
h(xk)
86
h(Xk)
87
u0
k
88
U0
k
89
U1:L 2 RL⇥H0⇥W 0⇥U
90
u1:L 2 RL⇥U
91
U0
1:L 2 RL⇥H0⇥W 0⇥U
92
u0
1:L 2 RL⇥U
93
where ⇤is a spatial convolution operator with state kernel A 2 RP ⇥P ⇥kA⇥kA
94
features, input features, kernel height, kernel width] convention), input kernel B
95
and the tanh() function is applied elementwise. More commonly, sophisticated
96
ConvLSTM [11] and ConvGRU [12] are used by making similar changes to the 1-D
97
equations respectively. ConvRNNs have been used for biomedical, robotics, trafﬁc m
98
forecasting and numerous other applications [49–60] and many variants have been p
99
2.2
Deep State Space Models
100
This section provides a brief background on the ideas of deep SSM methods suc
101
S5 [36] that were developed for 1-D sequence modeling and whose insights we
102
spatiotemporal ConvS5 approach.
103
2.2.1
Linear State Space Models
104
Given a continuous input signal u(t) 2 RU, a latent state x(t) 2 RP and an output s
105
a continuous-time, linear SSM is deﬁned by the differential equation:
106
x0(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t),
and is parameterized by a state matrix A 2 RP ⇥P , an input matrix B 2 RP ⇥U,
107
C 2 RM⇥P and a feedthrough matrix D 2 RM⇥U. Given a sampled sequence, u
108
SSM can be discretized to deﬁne a discrete-time SSM
109
xk = Axk−1 + Buk,
yk = Cxk + Duk,
where the discrete-time parameters are a function of the continuous-time parameter
110
parameter, ∆. We deﬁne A = DISCRETIZEA(A, ∆) and B = DISCRETIZEB
111
DISCRETIZE() is a discretization method such as Euler, bilinear or zero-order h
112
2.2.2
State Space Layers: S4 and S5
113
Gu et al. [33] proposed the structured state space sequence (S4) layer, which e
114
long sequences with subquadratic complexity in the sequence length. An S4 layer
115
continuous-time parameterized single-input, single-output (SISO) SSMs, an expl
116
step with learnable timescale parameters, and position-wise nonlinear activation fun
117
the SSM outputs to produce the layer output sequence. Multiple layers can be stac
118
sequence models that can represent nonlinear systems. An S4 layer can use its linear
119
a sequence in parallel by using 1-D convolutions. It can also run its linear SSMs a
120
for fast autoregressive generation. Smith et al. [36] showed that with several arch
121
the approach could be simpliﬁed and made more ﬂexible by replacing the convolut
122
scans, resulting in the simpliﬁed S4 (S5) layer. An S5 layer replaces S4’s many SIS
123
multi-input, multi-output SSM as in 3 and is a fully recurrent, stateful model for
124
sequential computations.
125
3
equation would be
85
Xk = tanh(A ⇤Xk−1 + B ⇤Uk),
(2)
h(xk)
86
h(Xk)
87
u0
k
88
U0
k
89
U1:L 2 RL⇥H0⇥W 0⇥U
90
u1:L 2 RL⇥U
91
U0
1:L 2 RL⇥H0⇥W 0⇥U
92
u0
1:L 2 RL⇥U
93
where ⇤is a spatial convolution operator with state kernel A 2 RP ⇥P ⇥kA⇥kA (using an [output
94
features, input features, kernel height, kernel width] convention), input kernel B 2 RP ⇥U⇥kB⇥kB
95
and the tanh() function is applied elementwise. More commonly, sophisticated updates such as
96
ConvLSTM [11] and ConvGRU [12] are used by making similar changes to the 1-D LSTM and GRU
97
equations respectively. ConvRNNs have been used for biomedical, robotics, trafﬁc modeling, weather
98
forecasting and numerous other applications [49–60] and many variants have been proposed [61–68].
99
2.2
Deep State Space Models
100
This section provides a brief background on the ideas of deep SSM methods such as S4 [33] and
101
S5 [36] that were developed for 1-D sequence modeling and whose insights we leverage for our
102
spatiotemporal ConvS5 approach.
103
2.2.1
Linear State Space Models
104
Given a continuous input signal u(t) 2 RU, a latent state x(t) 2 RP and an output signal y(t) 2 RM,
105
a continuous-time, linear SSM is deﬁned by the differential equation:
106
x0(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t),
(3)
and is parameterized by a state matrix A 2 RP ⇥P , an input matrix B 2 RP ⇥U, an output matrix
107
C 2 RM⇥P and a feedthrough matrix D 2 RM⇥U. Given a sampled sequence, u1:L 2 RL⇥U, the
108
SSM can be discretized to deﬁne a discrete-time SSM
109
xk = Axk−1 + Buk,
yk = Cxk + Duk,
(4)
where the discrete-time parameters are a function of the continuous-time parameters and a timescale
110
parameter, ∆. We deﬁne A = DISCRETIZEA(A, ∆) and B = DISCRETIZEB(A, B, ∆) where
111
DISCRETIZE() is a discretization method such as Euler, bilinear or zero-order hold [69].
112
2.2.2
State Space Layers: S4 and S5
113
Gu et al. [33] proposed the structured state space sequence (S4) layer, which efﬁciently models
114
long sequences with subquadratic complexity in the sequence length. An S4 layer consists of many
115
continuous-time parameterized single-input, single-output (SISO) SSMs, an explicit discretization
116
step with learnable timescale parameters, and position-wise nonlinear activation functions applied to
117
the SSM outputs to produce the layer output sequence. Multiple layers can be stacked to form deep
118
sequence models that can represent nonlinear systems. An S4 layer can use its linear SSMs to process
119
a sequence in parallel by using 1-D convolutions. It can also run its linear SSMs as RNNs to allow
120
for fast autoregressive generation. Smith et al. [36] showed that with several architecture changes,
121
the approach could be simpliﬁed and made more ﬂexible by replacing the convolutions with parallel
122
scans, resulting in the simpliﬁed S4 (S5) layer. An S5 layer replaces S4’s many SISO SSMs with one
123
multi-input, multi-output SSM as in 3 and is a fully recurrent, stateful model for both parallel and
124
sequential computations.
125
3
equation would be
85
Xk = tanh(A ⇤Xk−1 + B ⇤Uk),
(2)
h(xk)
86
h(Xk)
87
u0
k
88
U0
k
89
U1:L 2 RL⇥H0⇥W 0⇥U
90
u1:L 2 RL⇥U
91
U0
1:L 2 RL⇥H0⇥W 0⇥U
92
u0
1:L 2 RL⇥U
93
where ⇤is a spatial convolution operator with state kernel A 2 RP ⇥P ⇥kA⇥kA (using an [output
94
features, input features, kernel height, kernel width] convention), input kernel B 2 RP ⇥U⇥kB⇥kB
95
and the tanh() function is applied elementwise. More commonly, sophisticated updates such as
96
ConvLSTM [11] and ConvGRU [12] are used by making similar changes to the 1-D LSTM and GRU
97
equations respectively. ConvRNNs have been used for biomedical, robotics, trafﬁc modeling, weather
98
forecasting and numerous other applications [49–60] and many variants have been proposed [61–68].
99
2.2
Deep State Space Models
100
This section provides a brief background on the ideas of deep SSM methods such as S4 [33] and
101
S5 [36] that were developed for 1-D sequence modeling and whose insights we leverage for our
102
spatiotemporal ConvS5 approach.
103
2.2.1
Linear State Space Models
104
Given a continuous input signal u(t) 2 RU, a latent state x(t) 2 RP and an output signal y(t) 2 RM,
105
a continuous-time, linear SSM is deﬁned by the differential equation:
106
x0(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t),
(3)
and is parameterized by a state matrix A 2 RP ⇥P , an input matrix B 2 RP ⇥U, an output matrix
107
C 2 RM⇥P and a feedthrough matrix D 2 RM⇥U. Given a sampled sequence, u1:L 2 RL⇥U, the
108
SSM can be discretized to deﬁne a discrete-time SSM
109
xk = Axk−1 + Buk,
yk = Cxk + Duk,
(4)
where the discrete-time parameters are a function of the continuous-time parameters and a timescale
110
parameter, ∆. We deﬁne A = DISCRETIZEA(A, ∆) and B = DISCRETIZEB(A, B, ∆) where
111
DISCRETIZE() is a discretization method such as Euler, bilinear or zero-order hold [69].
112
2.2.2
State Space Layers: S4 and S5
113
Gu et al. [33] proposed the structured state space sequence (S4) layer, which efﬁciently models
114
long sequences with subquadratic complexity in the sequence length. An S4 layer consists of many
115
continuous-time parameterized single-input, single-output (SISO) SSMs, an explicit discretization
116
step with learnable timescale parameters, and position-wise nonlinear activation functions applied to
117
the SSM outputs to produce the layer output sequence. Multiple layers can be stacked to form deep
118
sequence models that can represent nonlinear systems. An S4 layer can use its linear SSMs to process
119
a sequence in parallel by using 1-D convolutions. It can also run its linear SSMs as RNNs to allow
120
for fast autoregressive generation. Smith et al. [36] showed that with several architecture changes,
121
the approach could be simpliﬁed and made more ﬂexible by replacing the convolutions with parallel
122
scans, resulting in the simpliﬁed S4 (S5) layer. An S5 layer replaces S4’s many SISO SSMs with one
123
multi-input, multi-output SSM as in 3 and is a fully recurrent, stateful model for both parallel and
124
sequential computations.
125
3
example, one can represent a vanilla RNN (ignoring the bias term) as
75
xk = tanh(Axk−1 + Buk)
(1)
with state matrix A 2 RP ⇥P , input matrix B 2 RP ⇥U and the hyperbolic tangent function tanh()
76
applied elementwise. Other RNNs such as LSTM [13] and GRU [14] deﬁne more sophisticated
77
formulations of F() .
78
Convolutional recurrent neural networks [11, 12] (ConvRNNs) model spatiotemporal sequences
79
by replacing the 1-D states and inputs of RNNs with N-D tensors and replacing the matrix-vector
80
multiplications with convolutions as in convolutional neural networks (CNNs). Given a length L
81
sequence of frames, U1:L 2 RL⇥H0⇥W 0⇥U, with height H0, width W 0 and U features, a ConvRNN
82
updates its state, Xk 2 RH⇥W ⇥P , with a state update equation Xk = G(Xk−1, Uk), where G() is
83
a nonlinear function. For a concrete example analogous to (1), the vanilla ConvRNN state update
84
1Implementation is available at: https://github.com/anonymous.
2
Given a 1-D sequence of inputs u1:L 2 RU, an RNN updates its state xk 2 RP at each time step k
73
with a state update equation xk = F(xk−1, uk), where F() represents some nonlinear function. For
74
example, one can represent a vanilla RNN (ignoring the bias term) as
75
xk = tanh(Axk−1 + Buk)
(1)
with state matrix A 2 RP⇥P , input matrix B 2 RP⇥U and the hyperbolic tangent function tanh()
76
applied elementwise. Other RNNs such as LSTM [13] and GRU [14] deﬁne more sophisticated
77
formulations of F() .
78
Convolutional recurrent neural networks [11, 12] (ConvRNNs) model spatiotemporal sequences
79
by replacing the 1-D states and inputs of RNNs with N-D tensors and replacing the matrix-vector
80
multiplications with convolutions as in convolutional neural networks (CNNs). Given a length L
81
sequence of frames, U1:L 2 RL⇥H0⇥W 0⇥U, with height H0, width W 0 and U features [SD: minor
82
point, but it is more typical to write WxH instead of HxW] [JS: Interesting, can you point me to some examples?
83
The H ⇥W convention matches the expected shapes of Torch and JAX/Flax’s conv2d operations and matches
84
the height and width of the rows ⇥columns of a matrix, so I currently have a preference to keep it as is], a
85
ConvRNN updates its state, Xk 2 RH⇥W⇥P , with a state update equation Xk = G(Xk−1, Uk),
86
2
Given a 1 D sequence of inputs u1:L 2 R , an RNN updates its state xk 2 R
at each time step k
73
with a state update equation xk = F(xk−1, uk), where F() represents some nonlinear function. For
74
example, one can represent a vanilla RNN (ignoring the bias term) as
75
xk = tanh(Axk−1 + Buk)
(1)
with state matrix A 2 RP ⇥P , input matrix B 2 RP ⇥U and the hyperbolic tangent function tanh()
76
applied elementwise. Other RNNs such as LSTM [13] and GRU [14] deﬁne more sophisticated
77
formulations of F() .
78
Convolutional recurrent neural networks [11, 12] (ConvRNNs) model spatiotemporal sequences
79
by replacing the 1-D states and inputs of RNNs with N-D tensors and replacing the matrix-vector
80
multiplications with convolutions as in convolutional neural networks (CNNs). Given a length L
81
sequence of frames, U1:L 2 RL⇥H0⇥W 0⇥U, with height H0, width W 0 and U features [SD: minor
82
point, but it is more typical to write WxH instead of HxW] [JS: Interesting, can you point me to some examples?
83
The H ⇥W convention matches the expected shapes of Torch and JAX/Flax’s conv2d operations and matches
84
the height and width of the rows ⇥columns of a matrix, so I currently have a preference to keep it as is], a
85
ConvRNN updates its state, Xk 2 RH⇥W ⇥P , with a state update equation Xk = G(Xk−1, Uk),
86
2
xk = tanh(Axk−1 + Buk)
(1)
with state matrix A 2 RP ⇥P , input matrix B 2 RP ⇥U and the hyperbolic tangent function tanh()
76
applied elementwise. Other RNNs such as LSTM [13] and GRU [14] deﬁne more sophisticated
77
formulations of F() .
78
Convolutional recurrent neural networks [11, 12] (ConvRNNs) model spatiotemporal sequences
79
by replacing the 1-D states and inputs of RNNs with N-D tensors and replacing the matrix-vector
80
multiplications with convolutions as in convolutional neural networks (CNNs). Given a length L
81
sequence of frames, U1:L 2 RL⇥H0⇥W 0⇥U, with height H0, width W 0 and U features [SD: minor
82
point, but it is more typical to write WxH instead of HxW] [JS: Interesting, can you point me to some examples?
83
The H ⇥W convention matches the expected shapes of Torch and JAX/Flax’s conv2d operations and matches
84
the height and width of the rows ⇥columns of a matrix, so I currently have a preference to keep it as is], a
85
ConvRNN updates its state, Xk 2 RH⇥W ⇥P , with a state update equation Xk = G(Xk−1, Uk),
86
2
equation would be
85
Xk = tanh(A ⇤Xk
h(xk)
86
h(Xk)
87
u0
k
88
U0
k
89
U1:L 2 RL⇥H0⇥W 0⇥U
90
u1:L 2 RL⇥U
91
U0
1:L 2 RL⇥H0⇥W 0⇥U
92
u0
1:L 2 RL⇥U
93
where ⇤is a spatial convolution operator with state
94
features, input features, kernel height, kernel width]
95
and the tanh() function is applied elementwise. M
96
ConvLSTM [11] and ConvGRU [12] are used by mak
97
equations respectively. ConvRNNs have been used for
98
forecasting and numerous other applications [49–60]
99
2.2
Deep State Space Models
100
This section provides a brief background on the ide
101
S5 [36] that were developed for 1-D sequence mod
102
spatiotemporal ConvS5 approach.
103
2.2.1
Linear State Space Models
104
Given a continuous input signal u(t) 2 RU, a latent st
105
a continuous-time, linear SSM is deﬁned by the diffe
106
x0(t) = Ax(t) + Bu(t),
and is parameterized by a state matrix A 2 RP ⇥P ,
107
C 2 RM⇥P and a feedthrough matrix D 2 RM⇥U.
108
SSM can be discretized to deﬁne a discrete-time SSM
109
xk = Axk−1 + Buk,
where the discrete-time parameters are a function of t
110
parameter, ∆. We deﬁne A = DISCRETIZEA(A, ∆
111
DISCRETIZE() is a discretization method such as E
112
2.2.2
State Space Layers: S4 and S5
113
Gu et al. [33] proposed the structured state space s
114
long sequences with subquadratic complexity in the
115
continuous-time parameterized single-input, single-o
116
step with learnable timescale parameters, and position
117
the SSM outputs to produce the layer output sequenc
118
sequence models that can represent nonlinear systems
119
a sequence in parallel by using 1-D convolutions. It
120
for fast autoregressive generation. Smith et al. [36]
121
the approach could be simpliﬁed and made more ﬂex
122
scans, resulting in the simpliﬁed S4 (S5) layer. An S5
123
multi-input, multi-output SSM as in 3 and is a fully
124
sequential computations.
125
3
equation would be
85
Xk = tanh(A
h(xk)
86
h(Xk)
87
u0
k
88
U0
k
89
U1:L 2 RL⇥H0⇥W 0⇥U
90
u1:L 2 RL⇥U
91
U0
1:L 2 RL⇥H0⇥W 0⇥U
92
u0
1:L 2 RL⇥U
93
where ⇤is a spatial convolution operator wit
94
features, input features, kernel height, kernel
95
and the tanh() function is applied elementw
96
ConvLSTM [11] and ConvGRU [12] are used
97
equations respectively. ConvRNNs have been u
98
forecasting and numerous other applications [4
99
2.2
Deep State Space Models
100
This section provides a brief background on
101
S5 [36] that were developed for 1-D sequenc
102
spatiotemporal ConvS5 approach.
103
2.2.1
Linear State Space Models
104
Given a continuous input signal u(t) 2 RU, a l
105
a continuous-time, linear SSM is deﬁned by th
106
x0(t) = Ax(t) + Bu(t
and is parameterized by a state matrix A 2 R
107
C 2 RM⇥P and a feedthrough matrix D 2 R
108
SSM can be discretized to deﬁne a discrete-tim
109
xk = Axk−1 + Bu
where the discrete-time parameters are a funct
110
parameter, ∆. We deﬁne A = DISCRETIZE
111
DISCRETIZE() is a discretization method su
112
2.2.2
State Space Layers: S4 and S5
113
Gu et al. [33] proposed the structured state
114
long sequences with subquadratic complexity
115
continuous-time parameterized single-input, s
116
step with learnable timescale parameters, and
117
the SSM outputs to produce the layer output s
118
sequence models that can represent nonlinear s
119
a sequence in parallel by using 1-D convoluti
120
for fast autoregressive generation. Smith et a
121
the approach could be simpliﬁed and made mo
122
scans, resulting in the simpliﬁed S4 (S5) layer.
123
multi-input, multi-output SSM as in 3 and is
124
sequential computations.
125
ConvS5 s parameterization and initialization to enable capturing long range dependencies.
149
3.1
Convolutional State Space Models
150
Consider a continuous-time tensor-valued input signal U(t) 2 RH0⇥W 0⇥U with height H0, width W 0,
151
and number of input features U. We will deﬁne a continuous-time, linear convolutional state space
152
model (ConvSSM) with state X(t) 2 RH⇥W ⇥P , derivative X 0(t) 2 RH⇥W ⇥P and output Y(t) 2
153
RH⇥W ⇥U, as the differential equation:
154
X 0(t) = A ⇤X(t) + B ⇤U(t)
(7)
Y(t) = C ⇤X(t) + D ⇤U(t)
(8)
where ⇤denotes the convolution operator, A 2 RP ⇥P ⇥kA⇥kA is the state kernel, B 2 RP ⇥U⇥kB⇥kB
155
is the input kernel, C 2 RU⇥P ⇥kC⇥kC is the output kernel, and D 2 RU⇥U⇥kD⇥kD is the
156
feedthrough kernel. We assume proper padding is used to ensure the same spatial resolution, H⇥W, is
157
maintained in the states and outputs. Similarly, given a sequence of L inputs, U1:L 2 RL⇥H0⇥W 0⇥U,
158
we can deﬁne a discrete-time convolutional state space model as
159
Xk = A ⇤Xk−1 + B ⇤Uk
(9)
Yk = C ⇤Xk + D ⇤Uk
(10)
where A 2 RP ⇥P ⇥kA⇥kA and B 2 RP ⇥U⇥kB⇥kB denote that these kernels are in discrete-time.
160
Note that these deﬁnitions are analogous to those of ConvRNNs discussed in Section 2.1, since we
161
have replaced the SSM’s vector-valued inputs, states, and outputs with tensors and replaced the
162
matrix-vector multiplications convolutions.
163
3.2
Parallelizing Convolutional Recurrences
164
We desire to leverage parallel scans to efﬁciently parallelize the computation of the discrete-time
165
convolutional recurrence in (9). As discussed in Section 2.2, this requires a binary associative operator.
166
Given the fact that convolution operators are associative, we show the following:
167
Proposition 1. Consider a convolutional recurrence as in (9) and deﬁne initial parallel scan elements
168
ck = (ck,a, ck,b) := (A, B ⇤Uk). The binary operator ~, deﬁned as:
169
qi ~ qj := (qj,a ◦qi,a, qj,a ⇤qi,b + qj,b),
(11)
where ◦denotes the convolution of two kernels, ⇤denotes convolution and + denotes elementwise
170
addition, is associative.
171
4
ConvRNN
SSM
ConvSSM (this paper)
Nonlinear function
Linear function
example, one can represent a vanilla RNN (ignoring the bias term) as
75
xk = tanh(Axk−1 + Buk)
with state matrix A 2 RP ⇥P , input matrix B 2 RP ⇥U and the hyperbolic tangent function tan
76
applied elementwise. Other RNNs such as LSTM [13] and GRU [14] deﬁne more sophisticat
77
formulations of F() .
78
Convolutional recurrent neural networks [11, 12] (ConvRNNs) model spatiotemporal sequenc
79
by replacing the 1-D states and inputs of RNNs with N-D tensors and replacing the matrix-vec
80
multiplications with convolutions as in convolutional neural networks (CNNs). Given a length
81
sequence of frames, U1:L 2 RL⇥H0⇥W 0⇥U, with height H0, width W 0 and U features, a ConvRN
82
updates its state, Xk 2 RH⇥W ⇥P , with a state update equation Xk = G(Xk−1, Uk), where G()
83
a nonlinear function. For a concrete example analogous to (1), the vanilla ConvRNN state upd
84
1Implementation is available at: https://github.com/anonymous.
2
2
Background
70
This section provides the background necessary to introduce ConvSSMs and ConvS5 in Section 3.
71
2.1
Convolutional Recurrent Networks
72
Given a 1-D sequence of inputs u1:L 2 RL⇥U, an RNN updates its state xk 2 RP at each time step
73
k with a state update equation xk = F(xk−1, uk), where F() represents some nonlinear function.
74
For example, one can represent a vanilla RNN (ignoring the bias term) as
75
xk = tanh(Axk−1 + Buk)
(1)
with state matrix A 2 RP ⇥P , input matrix B 2 RP ⇥U and the hyperbolic tangent function tanh()
76
applied elementwise. Other RNNs such as LSTM [13] and GRU [14] deﬁne more sophisticated
77
formulations of F() .
78
Convolutional recurrent neural networks [11, 12] (ConvRNNs) model spatiotemporal sequences
79
by replacing the 1-D states and inputs of RNNs with N-D tensors and replacing the matrix-vector
80
multiplications with convolutions as in convolutional neural networks (CNNs). Given a length L
81
sequence of frames, U1:L 2 RL⇥H0⇥W 0⇥U, with height H0, width W 0 and U features, a ConvRNN
82
updates its state, Xk 2 RH⇥W ⇥P , with a state update equation Xk = G(Xk−1, Uk), where G() is
83
a nonlinear function. For a concrete example analogous to (1), the vanilla ConvRNN state update
84
1Implementation is available at: https://github.com/anonymous.
2
equation would be
85
Xk = tanh(A ⇤Xk−1 + B ⇤Uk),
h(xk)
86
h(Xk)
87
u0
k
88
U0
k
89
U1:L 2 RL⇥H0⇥W 0⇥U
90
u1:L 2 RL⇥U
91
U0
1:L 2 RL⇥H0⇥W 0⇥U
92
u0
1:L 2 RL⇥U
93
where ⇤is a spatial convolution operator with state kernel A 2 RP ⇥P ⇥kA⇥kA (using an [
94
features, input features, kernel height, kernel width] convention), input kernel B 2 RP ⇥U⇥
95
and the tanh() function is applied elementwise. More commonly, sophisticated updates s
96
ConvLSTM [11] and ConvGRU [12] are used by making similar changes to the 1-D LSTM an
97
equations respectively. ConvRNNs have been used for biomedical, robotics, trafﬁc modeling, w
98
forecasting and numerous other applications [49–60] and many variants have been proposed [6
99
2.2
Deep State Space Models
100
This section provides a brief background on the ideas of deep SSM methods such as S4 [3
101
S5 [36] that were developed for 1-D sequence modeling and whose insights we leverage f
102
spatiotemporal ConvS5 approach.
103
2.2.1
Linear State Space Models
104
Given a continuous input signal u(t) 2 RU, a latent state x(t) 2 RP and an output signal y(t)
105
a continuous-time, linear SSM is deﬁned by the differential equation:
106
x0(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t),
and is parameterized by a state matrix A 2 RP ⇥P , an input matrix B 2 RP ⇥U, an output
107
C 2 RM⇥P and a feedthrough matrix D 2 RM⇥U. Given a sampled sequence, u1:L 2 RL⇥
108
SSM can be discretized to deﬁne a discrete-time SSM
109
xk = Axk−1 + Buk,
yk = Cxk + Duk,
where the discrete-time parameters are a function of the continuous-time parameters and a tim
110
parameter, ∆. We deﬁne A = DISCRETIZEA(A, ∆) and B = DISCRETIZEB(A, B, ∆)
111
DISCRETIZE() is a discretization method such as Euler, bilinear or zero-order hold [69].
112
2.2.2
State Space Layers: S4 and S5
113
Gu et al. [33] proposed the structured state space sequence (S4) layer, which efﬁciently m
114
long sequences with subquadratic complexity in the sequence length. An S4 layer consists o
115
continuous-time parameterized single-input, single-output (SISO) SSMs, an explicit discret
116
step with learnable timescale parameters, and position-wise nonlinear activation functions app
117
the SSM outputs to produce the layer output sequence. Multiple layers can be stacked to form
118
sequence models that can represent nonlinear systems. An S4 layer can use its linear SSMs to p
119
a sequence in parallel by using 1-D convolutions. It can also run its linear SSMs as RNNs to
120
for fast autoregressive generation. Smith et al. [36] showed that with several architecture ch
121
the approach could be simpliﬁed and made more ﬂexible by replacing the convolutions with p
122
scans, resulting in the simpliﬁed S4 (S5) layer. An S5 layer replaces S4’s many SISO SSMs w
123
multi-input, multi-output SSM as in 3 and is a fully recurrent, stateful model for both paral
124
sequential computations.
125
3
Figure 1: ConvRNNs [17, 18] (left) model spatiotemporal sequences using tensor-valued states, Xk,
and a nonlinear RNN update, G(), that uses convolutions instead of matrix-vector multiplications.
A position-wise nonlinear function, h(), transforms the states into the output sequence. Deep
SSMs [19, 20] (center) model vector-valued input sequences using a discretized linear SSM. The linear
dynamics can be exploited to parallelize computations across the sequence and capture long-range
dependencies. We introduce ConvSSMs (right) that model spatiotemporal data using tensor states,
like ConvRNNs, and linear dynamics, like SSMs. We also introduce an efficient ConvSSM variant,
ConvS5, that can be parallelized across the sequence with parallel scans, has fast autoregressive
generation, and captures long-range dependencies.
Convolutional recurrent networks (ConvRNNs) such as ConvLSTM [17] and ConvGRU [18] are
common approaches for spatiotemporal modeling. These methods encode the spatial information
using tensor-structured states. The states are updated with recurrent neural network (RNN) equations
that use convolutions instead of the matrix-vector multiplications in standard RNNs (e.g., LSTM/-
GRUs [21, 22]). This approach allows the RNN states to reflect the spatial structure of the data
while simultaneously capturing temporal dynamics. ConvRNNs inherit both the benefits and the
weaknesses of RNNs: they allow fast, stateful autoregressive generation and an unbounded context
window, but they are slow to train due to their inherently sequential structure and can suffer from the
vanishing/exploding gradient problem [23].
Transformer-based methods [9, 13, 14, 24–27] operate on an entire sequence in parallel, avoiding these
training challenges. Transformers typically require sophisticated compression schemes [28–30] to
reduce the spatiotemporal sequence into tokens. Moreover, Transformers use an attention mechanism
that has a bounded context window and whose computational complexity scales quadratically in
sequence length for training and inference [31, 32]. More efficient Transformer methods improve
on the complexity of attention [33–39], but these methods can fail on sequences with long-range
dependencies [40, 13]. Some approaches combine Transformers with specialized training frameworks
to address the attention costs [13]. However, recent work in deep state space models (SSMs) [19,
41, 42, 20, 43], like S4 [19] and S5 [20], has sought to overcome attention’s quadratic complexity
while maintaining the parallelizability and performance of attention and the statefulness of RNNs.
These SSM layers have proven to be effective in various domains such as speech [44], images [45]
and video classification [45, 46]; reinforcement learning [47, 48]; forecasting [49] and language
modeling [50–53].
Inspired by modeling ideas from ConvRNNs and SSMs, we introduce convolutional state space
models (ConvSSMs), which have a tensor-structured state like ConvRNNs but a continuous-time
parameterization and linear state updates like SSM layers. See Figure 1. However, there are
challenges to make this approach scalable and effective for modeling long-range spatiotemporal
data. In this paper, we address these challenges and provide a rigorous framework that ensures
both computational efficiency and modeling performance for spatiotemporal sequence modeling.
First, we discuss computational efficiency and parallelization of ConvSSMs across the sequence for
scalable training and fast inference. We show how to parallelize linear convolutional recurrences
using a binary associative operator and demonstrate how this can be exploited to use parallel scans
for subquadratic parallelization across the spatiotemporal sequence. We discuss both theoretical
and practical considerations (Section 3.2) required to make this feasible and efficient. Next, we
address how to capture long-range spatiotemporal dependencies. We develop a connection between
2
the dynamics of SSMs and ConvSSMs (Section 3.3) and leverage this, in Section 3.4, to introduce a
parameterization and initialization design that can capture long-range spatiotemporal dependencies.
As a result, we introduce ConvS5, a new spatiotemporal layer that is an efficient ConvSSM variant. It is
parallelizable and overcomes difficulties during training (e.g., vanishing/exploding gradient problems)
that traditional ConvRNN approaches experience. ConvS5 does not require compressing frames into
tokens and provides an unbounded context. It also provides fast (constant time and memory per step)
autoregressive generation compared to Transformers. ConvS5 significantly outperforms Transformers
and ConvLSTM on a challenging long horizon Moving-MNIST [54] experiment requiring methods
to train on 600 frames and generate up to 1,200 frames. In addition, ConvS5 trains 3× faster than
ConvLSTM on this task and generates samples 400× faster than the Transformer. Finally, we show
that ConvS5 matches or exceeds the performance of various state-of-the-art methods on challenging
DMLab, Minecraft, and Habitat long-range video prediction benchmarks [13].
2
Background
This section provides the background necessary for ConvSSMs and ConvS5, introduced in Section 3.
2.1
Convolutional Recurrent Networks
Given a sequence of inputs u1:L ∈RL×U, an RNN updates its state, xk ∈RP , using the state update
equation xk = F(xk−1, uk), where F() is a nonlinear function. For example, a vanilla RNN can be
represented (ignoring the bias term) as
xk = tanh(Axk−1 + Buk)
(1)
with state matrix A ∈RP ×P , input matrix B ∈RP ×U and tanh() applied elementwise. Other
RNNs such as LSTM [21] and GRU [22] utilize more intricate formulations of F().
Convolutional recurrent neural networks [17, 18] (ConvRNNs) are designed to model spatiotemporal
sequences by replacing the vector-valued states and inputs of traditional RNNs with tensors and
substituting matrix-vector multiplications with convolutions. Given a length L sequence of frames,
U1:L ∈RL×H′×W ′×U, with height H′, width W ′ and U features, a ConvRNN updates its state,
Xk ∈RH×W ×P , with a state update equation Xk = G(Xk−1, Uk), where G() is a nonlinear
function. Analogous to (1), we can express the state update equation for a vanilla ConvRNN as
Xk = tanh(A ∗Xk−1 + B ∗Uk),
(2)
where ∗is a spatial convolution operator with state kernel A ∈RP ×P ×kA×kA (using an [output
features, input features, kernel height, kernel width] convention), input kernel B ∈RP ×U×kB×kB and
tanh() is applied elementwise. More complex updates such as ConvLSTM [17] and ConvGRU [18]
are commonly used by making similar changes to the LSTM and GRU equations, respectively.
2.2
Deep State Space Models
This section briefly introduces deep SSMs such as S4 [19] and S5 [20] designed for modeling long
sequences. The ConvS5 approach we introduce in Section 3 extends these ideas to the spatiotemporal
domain.
Linear State Space Models
Given a continuous input signal u(t) ∈RU, a latent state x(t) ∈RP
and an output signal y(t) ∈RM, a continuous-time, linear SSM is defined using a differential
equation:
x′(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t),
(3)
and is parameterized by a state matrix A ∈RP ×P , an input matrix B ∈RP ×U, an output matrix
C ∈RM×P and a feedthrough matrix D ∈RM×U. Given a sequence, u1:L ∈RL×U, the SSM can
be discretized to define a discrete-time SSM
xk = Axk−1 + Buk,
yk = Cxk + Duk,
(4)
where the discrete-time parameters are a function of the continuous-time parameters and a timescale
parameter, ∆. We define A = DISCRETIZEA(A, ∆) and B = DISCRETIZEB(A, B, ∆) where
DISCRETIZE() is a discretization method such as Euler, bilinear or zero-order hold [55].
3
S4 and S5
Gu et al. [19] introduced the structured state space sequence (S4) layer to efficiently
model long sequences. An S4 layer uses many continuous-time linear SSMs, an explicit discretization
step with learnable timescale parameters, and position-wise nonlinear activation functions applied to
the SSM outputs. Smith et al. [20] showed that with several architecture changes, the approach could
be simplified and made more flexible by just using one SSM as in (3) and utilizing parallel scans.
SSM layers, such as S4 and S5, take advantage of the fact that linear dynamics can be parallelized
with subquadratic complexity in the sequence length. They can also be run sequentially as stateful
RNNs for fast autoregressive generation. While a single SSM layer such as S4 or S5 has only linear
dynamics, the nonlinear activations applied to the SSM outputs allow representing nonlinear systems
by stacking multiple SSM layers [56–58].
SSM Parameterization and Initialization
Parameterization and initialization are crucial aspects
that allow deep SSMs to capture long-range dependencies more effectively than prior attempts
at linear RNNs [59–61]. The general setup includes continuous-time SSM parameters, explicit
discretization with learnable timescale parameters, and state matrix initialization using structured
matrices inspired by the HiPPO framework [62]. Prior research emphasizes the significance of these
choices in achieving high performance on challenging long-range tasks [19, 20, 56, 57]. Recent
work [57] has studied these parameterizations/initializations in more detail and provides insight into
this setup’s favorable initial eigenvalue distributions and normalization effects.
2.3
Parallel Scans
We briefly introduce parallel scans, as used by S5, since they are important for parallelizing the
ConvS5 method we introduce in Section 3. See Blelloch [63] for a more detailed review. A scan
operation, given a binary associative operator • (i.e. (a • b) • c = a • (b • c)) and a sequence of L
elements [a1, a2, ..., aL], yields the sequence: [a1, (a1 • a2), ..., (a1 • a2 • ... • aL)].
Parallel scans use the fact that associative operators can be computed in any order. A parallel scan
can be defined for the linear recurrence of the state update in (4) by forming the initial scan tuples
ck = (ck,a, ck,b) := (A, Buk) and utilizing a binary associative operator that takes two tuples
qi, qj (either the initial tuples ci, cj or intermediate tuples) and produces a new tuple of the same
type, qi • qj := (qj,a ⊙qi,a, qj,a ⊗qi,b + qj,b), where ⊙is matrix-matrix multiplication and ⊗
is matrix-vector multiplication. Given sufficient processors, the parallel scan computes the linear
recurrence of (4) in O(log L) sequential steps (i.e., depth or span) [63].
3
Method
This section introduces convolutional state space models (ConvSSMs). We show how ConvSSMs can
be parallelized with parallel scans. We then connect the dynamics of ConvSSMs to SSMs to motivate
parameterization. Finally, we use these insights to introduce an efficient ConvSSM variant, ConvS5.
3.1
Convolutional State Space Models
Consider a continuous tensor-valued input U(t) ∈RH′×W ′×U with height H′, width W ′, and
number of input features U. We will define a continuous-time, linear convolutional state space
model (ConvSSM) with state X(t) ∈RH×W ×P , derivative X ′(t) ∈RH×W ×P and output Y(t) ∈
RH×W ×U, using a differential equation:
X ′(t) = A ∗X(t) + B ∗U(t)
(5)
Y(t) = C ∗X(t) + D ∗U(t)
(6)
where ∗denotes the convolution operator, A ∈RP ×P ×kA×kA is the state kernel, B ∈RP ×U×kB×kB
is the input kernel, C ∈RU×P ×kC×kC is the output kernel, and D ∈RU×U×kD×kD is the
feedthrough kernel. For simplicity, we pad the convolution to ensure the same spatial resolu-
tion, H × W, is maintained in the states and outputs.
Similarly, given a sequence of L in-
puts, U1:L ∈RL×H′×W ′×U, we define a discrete-time convolutional state space model as
Xk = A ∗Xk−1 + B ∗Uk
(7)
Yk = C ∗Xk + D ∗Uk
(8)
where A ∈RP ×P ×kA×kA and B ∈RP ×U×kB×kB denote that these kernels are in discrete-time.
4
State evolution of ConvSSM with pointwise state kernel
State pixels evolve according to SSM state update
O(UPk2HWL).
204
Proof. See Appendix C.1.
205
3.3
Connection to State Space Models
206
We show in this section that an equivalence can be established between the dynamics of a ConvSSM
207
using pointwise state kernels and the dynamics of a large block-diagonal SSM system. Thus, we can
208
use this fact to leverage the parameterization and initialization ideas from deep SSMs discussed in
209
Section 2.2.3 to allow ConvSSMs to effectively model long-range dependencies.
210
X 0(t) = A ⇤X(t) + B ⇤U(t)
211
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
We show in this section that an equivalence can be established between the dynamics of a ConvSSM
207
using pointwise state kernels and the dynamics of a large block-diagonal SSM system. Thus, we can
208
use this fact to leverage the parameterization and initialization ideas from deep SSMs discussed in
209
Section 2.2.3 to allow ConvSSMs to effectively model long-range dependencies.
210
X 0(t) = A ⇤X(t) + B ⇤U(t)
211
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
us g po tw se state e
e s a d t e dy a
cs o a a ge b oc
d ago a SS
syste .
us, we ca
08
use this fact to leverage the parameterization and initialization ideas from deep SSMs discussed in
209
Section 2.2.3 to allow ConvSSMs to effectively model long-range dependencies.
210
X 0(t) = A ⇤X(t) + B ⇤U(t)
211
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
using pointwise state kernels and the dynamics of a large block diagonal SSM
208
use this fact to leverage the parameterization and initialization ideas from de
209
Section 2.2.3 to allow ConvSSMs to effectively model long-range dependenc
210
X 0(t) = A ⇤X(t) + B ⇤U(t)
211
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
We show in this section that an equivalence can be established betw
207
using pointwise state kernels and the dynamics of a large block-dia
208
use this fact to leverage the parameterization and initialization ide
209
Section 2.2.3 to allow ConvSSMs to effectively model long-range
210
X 0(t) = A ⇤X (t) + B ⇤U(t)
211
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X (t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
3.3
Connection to State Space Models
206
We show in this section that an equivalence can be established between the dynamics of a ConvS
207
using pointwise state kernels and the dynamics of a large block-diagonal SSM system. Thus, we
208
use this fact to leverage the parameterization and initialization ideas from deep SSMs discusse
209
Section 2.2.3 to allow ConvSSMs to effectively model long-range dependencies.
210
X 0(t) = A ⇤X(t) + B ⇤U(t)
211
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
Proof. See Appendix C.1.
205
3.3
Connection to State Space Models
206
We show in this section that an equivalence can be established between the dynamics of a ConvS
207
using pointwise state kernels and the dynamics of a large block-diagonal SSM system. Thus, we
208
use this fact to leverage the parameterization and initialization ideas from deep SSMs discusse
209
Section 2.2.3 to allow ConvSSMs to effectively model long-range dependencies.
210
X 0(t) = A ⇤X(t) + B ⇤U(t)
211
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
We show in this section that an equivalence can be es
207
using pointwise state kernels and the dynamics of a la
208
use this fact to leverage the parameterization and ini
209
Section 2.2.3 to allow ConvSSMs to effectively mod
210
X 0(t) = A ⇤X (t) + B ⇤U(t)
211
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X (t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
Proof. See Appendix C.1.
205
3.3
Connection to State Space Models
206
We show in this section that an equivalence can be established between the dy
207
using pointwise state kernels and the dynamics of a large block-diagonal SSM
208
use this fact to leverage the parameterization and initialization ideas from d
209
Section 2.2.3 to allow ConvSSMs to effectively model long-range dependenc
210
X 0(t) = A ⇤X (t) + B ⇤U(t)
211
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X (t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
can be efﬁciently parallelized with subquadratic complexity with respect to the sequence length
202
Proposition 2. The computational cost of the convolutional recurrence in Equation ?
203
O(UPk2HWL).
204
Proof. See Appendix C.1.
205
3.3
Connection to State Space Models
206
We show in this section that an equivalence can be established between the dynamics of a ConvS
207
using pointwise state kernels and the dynamics of a large block-diagonal SSM system. Thus, we
208
use this fact to leverage the parameterization and initialization ideas from deep SSMs discusse
209
Section 2.2.3 to allow ConvSSMs to effectively model long-range dependencies.
210
X 0(t) = A ⇤X(t) + B ⇤U(t)
211
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
gg
p
y
p
or compared to ConvLSTM with a 3 ⇥3 kernel. Computationally, we now have a construction
201
can be efﬁciently parallelized with subquadratic complexity with respect to the sequence length
202
Proposition 2. The computational cost of the convolutional recurrence in Equation ??
203
O(UPk2HWL).
204
Proof. See Appendix C.1.
205
3.3
Connection to State Space Models
206
We show in this section that an equivalence can be established between the dynamics of a ConvS
207
using pointwise state kernels and the dynamics of a large block-diagonal SSM system. Thus, we
208
use this fact to leverage the parameterization and initialization ideas from deep SSMs discusse
209
Section 2.2.3 to allow ConvSSMs to effectively model long-range dependencies.
210
X 0(t) = A ⇤X(t) + B ⇤U(t)
211
U(t) 2 RH0⇥W 0⇥U
212
X 0(t) 2 RH⇥W ⇥P
213
A 2 RP ⇥P ⇥1⇥1
214
B 2 RP ⇥U⇥kB⇥kB
215
X(t) 2 RH⇥W ⇥P
216
ABlock 2 RHW P ⇥HW P
217
5
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X (t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X (t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX (t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X (t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X(t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X(t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX(t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X (t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X (t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX (t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X (t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X(t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X(t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX(t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X(t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X(t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX(t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X(t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X(t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX(t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently des
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elem
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be desc
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of p
200
state kernels as described in the previous section provides an alternative SSM equivalenc
201
lends a special structure that can leverage the deep SSM parameterization and initializati
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pix
203
state, X (t)i,j 2 RP can be equivalently described as evolving according to a differential
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X (t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX (t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [J
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation i
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kern
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearr
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X (t) a
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with A
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concaten
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endo
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling lon
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matr
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence t
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work w
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly o
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of conv
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvS
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Pro
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be e
197
matrix-vector multiplications using large, circulant matrices consisting of
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvS
199
a large SSM with a circulant dynamics matrix. However, we show here
200
state kernels as described in the previous section provides an alternative
201
lends a special structure that can leverage the deep SSM parameterizatio
202
discussed in Section 2.2.3 for modeling long-range dependencies. We sh
203
state, X (t)i,j 2 RP can be equivalently described as evolving according
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X (t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX (t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an
217
operations, and has a paper we can cite. I am open to suggestions, but was having a
218
cleaner way of describing what we need here. I feel like saying im2col and citing i
219
Proposition 3. Consider a ConvSSM state update as in (7) with poin
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the inp
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after re
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equatio
224
x0(t) = ABlockx(t) + BBlocku(t),
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-d
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the re
226
columns formed by performing an im2col [74, 75] operation on the input U
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured H
229
disretizing with a learnable timescale parameter to obtain ASSM and B
230
SSMs with the same dynamics as in S4/S5 methods that are important
231
dependencies. Due to the equivalence of Proposition 3, we can then rearr
232
the discrete ConvSSM state and input kernels of 9 to give the convolutio
233
advantageous dynamical properties. Note the ConvSSM formulation is
234
forming the large, block-diagonal SSM state update explicitly and allows lev
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallel
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). Con
239
leverages parallel scans and deep SSM parameterization/initialization sch
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X(t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X(t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX(t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X (t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X (t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX (t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X (t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X(t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X(t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX(t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X(t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
P ⇥Uk2
B
206
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
207
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
208
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
209
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
210
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
211
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
212
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
213
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
214
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
215
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
216
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
217
columns formed by performing an im2col [74, 75] operation on the input U(t).
218
Proof. See Appendix C.3.
219
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
220
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
221
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
222
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
223
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
224
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
225
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
226
convolution operations in modern deep learning frameworks [76–78].
227
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
228
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
229
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
230
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
231
3, we can implicitly parameterize a pointwise state kernel, A 2 RP ⇥P ⇥1⇥1 and input kernel
232
B 2 RP ⇥U⇥kB⇥kB in (7) using SSM parameters as used by S5 [36], AS5 2 RP ⇥P and BS5 2
233
RP ⇥(Uk2
B). We can discretize these S5 SSM parameters as discussed in Section 2.2.1 to give
234
AS5 = DISCRETIZEA(AS5, ∆),
BS5 = DISCRETIZEB(AS5, BS5, ∆),
(13)
and then rearrange to give the ConvS5 state update kernels:
235
AS5 2 RP ⇥P
rearrange
−−−−−−! AConvS5 2 RP ⇥P ⇥1⇥1
(14)
BS5 2 RP ⇥(Uk2
B)
rearrange
−−−−−−! BConvS5 2 RP ⇥U⇥kB⇥kB.
(15)
We then run the discretized ConvSSM system of Eqs (9, 10), where the recurrence can be computed
236
using parallel scans. Note that in practice this setup actually allows us to parameterize ConvS5 using
237
a diagonal state [34–36] which reduces the cost of applying the parallel scan in Proposition 2 to
238
O(LPHW). See Appendix A for a more detailed discussion of parameterization, initialization and
239
discretization.
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X (t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X (t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX (t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X (t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalently described as
197
matrix-vector multiplications using large, circulant matrices consisting of the kernel elements and
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can be described as
199
a large SSM with a circulant dynamics matrix. However, we show here that the use of pointwise
200
state kernels as described in the previous section provides an alternative SSM equivalence, which
201
lends a special structure that can leverage the deep SSM parameterization and initialization ideas
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that each pixel of the
203
state, X(t)i,j 2 RP can be equivalently described as evolving according to a differential equation
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
X 0(t)i,j
P
206
X(t)i,j
P
207
ASSM
P ⇥P
208
BSSM
P ⇥(Uk2
B)
209
X 0(t)i,j = ASSMX(t)i,j + BSSMUim2col(t)i,j
210
Uk2
B
211
H0 ⇥W 0 ⇥U
212
P ⇥U ⇥kB ⇥kB
213
P ⇥P ⇥1 ⇥1
214
H ⇥W ⇥P
215
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describe it?] [JS: im2col
216
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial operation in GEMM
217
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time coming up with a
218
cleaner way of describing what we need here. I feel like saying im2col and citing it is actually pretty precise.]
219
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise state kernel A 2
220
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U. Rearrange the
221
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel B into a matrix
222
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping X(t) and X 0(t)
223
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
224
x0(t) = ABlockx(t) + BBlocku(t),
(12)
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal with ASSM and
225
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of concatenating the
226
columns formed by performing an im2col [74, 75] operation on the input U(t).
227
Proof. See Appendix C.3.
228
Thus, parameterizing and initializing ASSM with the specially structured HiPPO matrices [47] and
229
disretizing with a learnable timescale parameter to obtain ASSM and BSSM would endow these
230
SSMs with the same dynamics as in S4/S5 methods that are important for modeling long-range
231
dependencies. Due to the equivalence of Proposition 3, we can then rearrange these matrices into
232
the discrete ConvSSM state and input kernels of 9 to give the convolutional recurrence the same
233
advantageous dynamical properties. Note the ConvSSM formulation is easier to work with than
234
forming the large, block-diagonal SSM state update explicitly and allows leveraging highly optimized
235
convolution operations in modern deep learning frameworks [76–78].
236
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
237
In this section, we introduce ConvS5 which combines ideas of parallelization of convolutional
238
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a ConvSSM that
239
leverages parallel scans and deep SSM parameterization/initialization schemes. Given Proposition
240
6
3.3
Connection to State Space Models
196
Since the convolutions in 7-8 and 9-10 are linear operations, they can be equivalen
197
matrix-vector multiplications using large, circulant matrices consisting of the kern
198
ﬂattening the input and state tensors into vectors [73]. Thus, any ConvSSM can
199
a large SSM with a circulant dynamics matrix. However, we show here that the u
200
state kernels as described in the previous section provides an alternative SSM equ
201
lends a special structure that can leverage the deep SSM parameterization and init
202
discussed in Section 2.2.3 for modeling long-range dependencies. We show that e
203
state, X(t)i,j 2 RP can be equivalently described as evolving according to a diffe
204
with a shared state matrix, ASSM, and input matrix, BSSM. See Figure 1.
205
Uim2col(t)i,j
206
[WB: Deﬁne im2col before eq 12. im2cal is speciﬁc to images. Is there another way to describ
207
is applicable to any HxWxC tensor (which is the only case we consider). It is also an ofﬁcial op
208
operations, and has a paper we can cite. I am open to suggestions, but was having a hard time
209
cleaner way of describing what we need here. I feel like saying im2col and citing it is actuall
210
Proposition 3. Consider a ConvSSM state update as in (7) with pointwise sta
211
RP ⇥P ⇥1⇥1, input kernel B 2 RP ⇥U⇥kB⇥kB, and input U(t) 2 RH0⇥W 0⇥U.
212
pointwise state kernel A into a matrix ASSM 2 RP ⇥P . Rearrange the input kernel
213
BSSM 2 RP ⇥(Uk2
B). The differential equation of (7) is equivalent, after reshaping
214
into x(t), x0(t) 2 RHW P respectively, to the following differential equation
215
x0(t) = ABlockx(t) + BBlocku(t),
where ABlock 2 RHW P ⇥HW P and BBlock 2 RHW P ⇥HW Uk2
b are block-diagonal
216
BSSM on the diagonal blocks respectively, and u(t) 2 RHW Uk2
b is the result of co
217
columns formed by performing an im2col [74, 75] operation on the input U(t).
218
Proof. See Appendix C.3.
219
Thus, parameterizing and initializing ASSM with the specially structured HiPPO m
220
disretizing with a learnable timescale parameter to obtain ASSM and BSSM wou
221
SSMs with the same dynamics as in S4/S5 methods that are important for mode
222
dependencies. Due to the equivalence of Proposition 3, we can then rearrange the
223
the discrete ConvSSM state and input kernels of 9 to give the convolutional recur
224
advantageous dynamical properties. Note the ConvSSM formulation is easier to
225
forming the large, block-diagonal SSM state update explicitly and allows leveraging h
226
convolution operations in modern deep learning frameworks [76–78].
227
3.4
Efﬁcient ConvSSM for Long-Range Dependencies: ConvS5
228
In this section, we introduce ConvS5 which combines ideas of parallelization o
229
recurrences (Section 3.2) and the SSM connection (Section 3.3). ConvS5 is a
230
leverages parallel scans and deep SSM parameterization/initialization schemes. Gi
231
3, we can implicitly parameterize a pointwise state kernel, A 2 RP ⇥P ⇥1⇥1 a
232
B 2 RP ⇥U⇥kB⇥kB in (7) using SSM parameters as used by S5 [36], AS5 2 RP
233
RP ⇥(Uk2
B). We can discretize these S5 SSM parameters as discussed in Section 2.2
234
AS5 = DISCRETIZEA(AS5, ∆),
BS5 = DISCRETIZEB(AS5, BS
and then rearrange to give the ConvS5 state update kernels:
235
AS5 2 RP ⇥P
rearrange
−−−−−−! AConvS5 2 RP ⇥P ⇥1⇥1
BS5 2 RP ⇥(Uk2
B)
rearrange
−−−−−−! BConvS5 2 RP ⇥U⇥kB⇥kB.
We then run the discretized ConvSSM system of Eqs (9, 10), where the recurrence c
236
using parallel scans. Note that in practice this setup actually allows us to parameteriz
237
a diagonal state [34–36] which reduces the cost of applying the parallel scan in P
238
O(LPHW). See Appendix A for a more detailed discussion of parameterization, in
239
discretization.
240
6
Figure 2: The dynamics of a ConvSSM with pointwise state kernel (top) can be equivalently viewed
as the dynamics of an SSM (bottom). See Proposition 3. Each ConvSSM state pixel evolves according
to an SSM state update with shared state matrix, ASSM, and input matrix, BSSM, that can be formed
by reshaping the ConvSSM’s state kernel and input kernel. This allows leveraging parameterization
insights from deep SSMs [19, 41, 42, 20, 57] to equip ConvS5 to model long-range dependencies.
3.2
Parallelizing Convolutional Recurrences
ConvS5 leverages parallel scans to efficiently parallelize the recurrence in (7). As discussed in Section
2.3, this requires a binary associative operator. Given that convolutions are associative, we show:
Proposition 1. Consider a convolutional recurrence as in (7) and define initial parallel scan elements
ck = (ck,a, ck,b) := (A, B ∗Uk). The binary operator ⊛, defined below, is associative.
qi ⊛qj := (qj,a ◦qi,a, qj,a ∗qi,b + qj,b),
(9)
where ◦denotes convolution of two kernels, ∗denotes convolution and + is elementwise addition.
Proof. See Appendix A.1.
Therefore, in theory, we can use this binary operator with a parallel scan to compute the recurrence
in (7). However, the binary operator, ⊛, requires convolving two kA × kA resolution state kernels
together. To maintain equivalence with the sequential scan, the resulting kernel will have resolution
2ka −1 × 2ka −1. This implies that the state kernel will grow during the parallel scan computations
for general kernels with a resolution greater than 1 × 1. This allows the receptive field to grow in the
time direction, a useful feature for capturing spatiotemporal context. However, this kernel growth is
computationally infeasible for long sequences.
We address this challenge by taking further inspiration from deep SSMs. These methods opt for
simple but computationally advantageous operations in the time direction (linear dynamics) and
utilize more complex operations (nonlinear activations) in the depth direction of the model. These
nonlinear activations allow a stack of SSM layers with linear dynamics to represent nonlinear systems.
Analogously, we choose to use 1 × 1 state kernels and perform pointwise state convolutions for the
convolutional recurrence of (7). When we stack multiple layers of these ConvSSMs, the receptive
field grows in the depth direction of the network and allows the stack of layers to capture the
spatiotemporal context [64]. Computationally, we now have a construction that can be parallelized
with subquadratic complexity with respect to the sequence length.
Proposition 2. Given the effective inputs B ∗U1:L ∈RL×H×W ×P and a pointwise state kernel
A ∈RP ×P ×1×1, the computational cost of computing the convolutional recurrence in Equation 7
with a parallel scan is O
"
20284,2023,"CRoSS: Diffusion Model Makes Controllable, Robust and Secure Image Steganography","CRoSS: Diffusion Model Makes
Controllable, Robust and Secure Image Steganography
Jiwen Yu1
Xuanyu Zhang1
Youmin Xu1,2
Jian Zhang1†
1 Peking University Shenzhen Graduate School
2 Peng Cheng Laboratory
Abstract
Current image steganography techniques are mainly focused on cover-based meth-
ods, which commonly have the risk of leaking secret images and poor robustness
against degraded container images. Inspired by recent developments in diffu-
sion models, we discovered that two properties of diffusion models, the ability to
achieve translation between two images without training, and robustness to noisy
data, can be used to improve security and natural robustness in image steganogra-
phy tasks. For the choice of diffusion model, we selected Stable Diffusion, a type
of conditional diffusion model, and fully utilized the latest tools from open-source
communities, such as LoRAs and ControlNets, to improve the controllability and
diversity of container images. In summary, we propose a novel image steganog-
raphy framework, named Controllable, Robust and Secure Image Steganography
(CRoSS), which has significant advantages in controllability, robustness, and secu-
rity compared to cover-based image steganography methods. These benefits are
obtained without additional training. To our knowledge, this is the first work to
introduce diffusion models to the field of image steganography. In the experimental
section, we conducted detailed experiments to demonstrate the advantages of our
proposed CRoSS framework in controllability, robustness, and security. Code is
available at https://github.com/vvictoryuki/CRoSS.
1
Introduction
With the explosive development of digital communication and AIGC (AI-generated content), the
privacy, security, and protection of data have aroused significant concerns. As a widely studied
technique, steganography [10] aims to hide messages like audio, image, and text into the container
image in an undetected manner. In its reveal process, it is only possible for the receivers with pre-
defined revealing operations to reconstruct secret information from the container image. It has a wide
range of applications, such as copyright protection [4], digital watermarking [15], e-commerce [11],
anti-visual detection [34], spoken language understanding [12, 13] and cloud computing [76].
For image steganography, traditional methods tend to transform the secret messages in the spatial
or adaptive domains [27], such as fewer significant bits [9] or indistinguishable parts. With the
development of deep neural networks, researchers begin to use auto-encoder networks [5, 6] or
invertible neural networks (INN) [35, 26]to hide data, namely deep steganography.
The essential targets of image steganography are security, reconstruction quality, and robustness [9,
45, 77]. Since most previous methods use cover images to hide secret images, they tend to explicitly
retain some secret information as artifacts or local details in the container image, which poses a risk
of information leakage and reduces the security of transmission. Meanwhile, although previous
works can maintain well reconstruction fidelity of the revealed images, they tend to train models in a
noise-free simulation environment and can not withstand noise, compression artifacts, and non-linear
transformations in practice, which severely hampers their practical values and robustness [30, 44, 25].
†Corresponding author. This work was supported by National Natural Science Foundation of China under
Grant 62372016.
37th Conference on Neural Information Processing Systems (NeurIPS 2023).
To address security and robustness concerns, researchers have shifted their focus toward coverless
steganography. This approach aims to create a container image that bears no relation to the secret
information, thereby enhancing its security. Current coverless steganography methods frequently
employ frameworks such as CycleGAN [78] and encoder-decoder models [76], leveraging the
principle of cycle consistency. However, the controllability of the container images generated by
existing coverless methods remains limited. Their container images are only randomly sampled from
the generative model and cannot be determined by the user. Moreover, existing approaches [47] tend
to only involve hiding bits into container images, ignoring the more complex hiding of secret images.
Overall, current methods, whether cover-based or coverless, have not been able to achieve good unity
in terms of security, controllability, and robustness. Thus, our focus is to propose a new framework
that can simultaneously improve existing methods in these three aspects.
Recently, research on diffusion-based generative models [22, 55, 56] has been very popular, with
various unique properties such as the ability to perform many tasks in a zero-shot manner [36, 28, 64,
63, 72, 37, 20], strong control over the generation process [16, 49, 74, 40, 19, 50], natural robustness
to noise in images [64, 28, 14, 65], and the ability to achieve image-to-image translation [75, 8, 20,
39, 57, 14, 29, 37]. We were pleasantly surprised to find that these properties perfectly match the
goals we mentioned above for image steganography: (1) Security: By utilizing the DDIM Inversion
technique [54] for diffusion-based image translation, we ensure the invertibility of the translation
process. This invertible translation process enables a coverless steganography framework, ensuring
the security of the hidden image. (2) Controllability: The powerful control capabilities of conditional
diffusion models make the container image highly controllable, and its visual quality is guaranteed
by the generative prior of the diffusion model; (3) Robustness: Diffusion models are essentially
Gaussian denoisers and have natural robustness to noise and perturbations. Even if the container
image is degraded during transmission, we can still reveal the main content of the secret image.
We believe that the fusion of diffusion models and image steganography is not simply a matter of
mechanically combining them, but rather an elegant and instructive integration that takes into account
the real concerns of image steganography. Based on these ideas, we propose the Controllable, Robust
and Secure Image Steganography (CRoSS) framework, a new image steganography framework that
aims to simultaneously achieve gains in security, controllability, and robustness.
Our contributions can be summarized as follows:
• We identify the limitations of existing image steganography methods and propose a unified goal of
achieving security, controllability, and robustness. We also demonstrate that the diffusion model
can seamlessly integrate with image steganography to achieve these goals using diffusion-based
invertible image translation technique without requiring any additional training.
• We propose a new image steganography framework: Controllable, Robust and Secure Image
Steganography (CRoSS). To the best of our knowledge, this is the first attempt to apply the
diffusion model to the field of image steganography and gain better performance.
• We leveraged the progress of the rapidly growing Stable Diffusion community to propose variants
of CRoSS using prompts, LoRAs, and ControlNets, enhancing its controllability and diversity.
• We conducted comprehensive experiments focusing on the three targets of security, controllability,
and robustness, demonstrating the advantages of CRoSS compared to existing methods.
2
Related Work
2.1
Steganography Methods
Cover-based Image Steganography.
Unlike cryptography, steganography aims to hide secret
data in a host to produce an information container. For image steganography, a cover image is
required to hide the secret image in it [5]. Traditionally, spatial-based [24, 41, 43, 46] methods
utilize the Least Significant Bits (LSB), pixel value differencing (PVD) [43], histogram shifting [60],
multiple bit-planes [41] and palettes [24, 42] to hide images, which may arise statistical suspicion
and are vulnerable to steganalysis methods. Adaptive methods [45, 31] decompose the steganography
into embedding distortion minimization and data coding, which is indistinguishable by appearance
but limited in capacity. Various transform-based schemes [10, 27] including JSteg [46] and DCT
steganography [21] also fail to offer high payload capacity. Recently, various deep learning-based
2
schemes have been proposed to solve image steganography. Baluja [5] proposed the first deep-
learning method to hide a full-size image into another image. Generative adversarial networks
(GANs) [53] are introduced to synthesize container images. Probability map methods focus on
generating various cost functions satisfying minimal-distortion embedding [45, 59]. [69] proposes
a generator based on U-Net. [58] presents an adversarial scheme under distortion minimization.
Three-player game methods like SteganoGAN [73] and HiDDeN [77] learn information embedding
and recovery by auto-encoder architecture to adversarially resist steganalysis. Recent attempts [66] to
introduce invertible neural networks (INN) into low-level inverse problems like denoising, rescaling,
and colorization show impressive potential over auto-encoder, GAN [3], and other learning-based
architectures. Recently, [35, 26] proposed designing the steganography model as an invertible neural
network (INN) [17, 18] to perform image hiding and recovering with a single INN model.
Coverless Steganography.
Coverless steganography is an emerging technique in the field of
information hiding, which aims to embed secret information within a medium without modifying the
cover object [47]. Unlike traditional steganography methods that require a cover medium (e.g., an
image or audio file) to be altered for hiding information, coverless steganography seeks to achieve
secure communication without introducing any changes to the cover object [33]. This makes it more
challenging for adversaries to detect the presence of hidden data, as there are no observable changes
in the medium’s properties [38]. To the best of our knowledge, existing coverless steganography
methods [34] still focus on hiding bits into container images, and few explorations involve hiding
images without resorting to cover images.
2.2
Diffusion Models
Diffusion models [22, 55, 56] are a type of generative model that is trained to learn the target image
distribution from a noise distribution. Recently, due to their powerful generative capabilities, diffusion
models have been widely used in various image applications, including image generation [16, 48,
51, 49], restoration [52, 28, 64], translation [14, 29, 37, 75], and more. Large-scale diffusion model
communities have also emerged on the Internet, with the aim of promoting the development of
AIGC(AI-generated content)-related fields by applying the latest advanced techniques.
In these communities, the Stable Diffusion [49] community is currently one of the most popular and
thriving ones, with a large number of open-source tools available for free, including model checkpoints
finetuned on various specialized datasets. Additionally, various LoRAs [23] and ControlNets [74] are
available in these communities for efficient control over the results generated by Stable Diffusion.
LoRAs achieve control by efficiently modifying some network parameters in a low-rank way, while
ControlNets introduce an additional network to modify the intermediate features of Stable Diffusion
for control. These mentioned recent developments have enhanced our CRoSS framework.
3
Method
3.1
Definition of Image Steganography
Hide Process
Reveal Process
Transmission
Figure 1: Illustration used to show the
definition of image steganography.
Before introducing our specific method, we first define the
image steganography task as consisting of three images
and two processes (as shown in Fig. 1): the three images
refer to the secret image xsec, container image xcont, and
revealed image xrev, while the two processes are the hide
process and reveal process. The secret image xsec is the
image we want to hide and is hidden in the container
image xcont through the hide process. After transmission
over the Internet, the container image xcont may become
degraded, resulting in a degraded container image x′
cont,
from which we extract the revealed image xrev through
the reveal process. Our goal is to make our proposed framework have the following properties: (1)
Security: even if the container image xcont is intercepted by other receivers, the hidden secret image
xsec cannot be leaked. (2) Controllability: the content in the container image xcont can be controlled
by the user, and its visual quality is high. (3) Robustness: the reveal process can still generate
semantically consistent results (xrev ≈xsec) even if there is deviation in the x′
cont compared to the
xcont (x′
cont = d(xcont), d(·) denotes the degradation process). According to the above definition,
3
Diffusion
Forward
Translation
（b）DDIM Inversion
（a）Image Translation using Different Conditions
Diffusion
Backward
Invertible?
prompt：“cat”
prompt：“tiger”
Deterministic
Forward
Deterministic
Backward
Figure 2: In part (a), Conditional diffusion models can be used with different conditions to perform
image translation. In this example, we use two different prompts (“cat"" and “tiger"") to translate a cat
image into a tiger image. However, a critical challenge for coverless image steganography is whether
we can reveal the original image from the translated image. The answer is yes, and we can use DDIM
Inversion (shown in part (b)) to achieve dual-direction translation between the image distribution and
noise distribution, allowing for invertible image translation.
we can consider the hide process as a translation between the secret image xsec and the container
image xcont, and the reveal process as the inverse process of the hide process. In Sec. 3.2, we will
introduce how to use diffusion models to implement these ideas, and in Sec. 3.3, we will provide a
detailed description of our proposed framework CRoSS for coverless image steganography.
3.2
Invertible Image Translation using Diffusion Model
Diffusion Model Defined by DDIM.
A complete diffusion model process consists of two stages:
the forward phase adds noise to a clean image, while the backward sampling phase denoises it step
by step. In DDIM [54], the formula for the forward process is given by:
xt = √αtxt−1 +
√
1 −αtϵ,
ϵ ∼N(0, I),
(1)
where xt denotes the noisy image in the t-th step, ϵ denotes the randomly sampled Gaussian noise,
αt is a predefined parameter and the range of time step t is [1, T]. The formula of DDIM for the
backward sampling process is given by:
xs = √¯αsfθ(xt, t) +
p
1 −¯αs −σ2sϵθ(xt, t) + σsϵ,
fθ(xt, t) = xt −√1 −¯αtϵθ(xt, t)
√¯αt
, (2)
where ϵ ∼N(0, I) is a randomly sampled Gaussian noise with σ2
s as the noise variance, fθ(·, t) is a
denoising function based on the pre-trained noise estimator ϵθ(·, t), and ¯αt = Qt
i=1 αi. DDIM does
not require the two steps in its sampling formula to be adjacent (i.e., t = s + 1). Therefore, s and
t can be any two steps that satisfy s < t. This makes DDIM a popular algorithm for accelerating
sampling. Furthermore, if σs in Eq.2 is set to 0, the DDIM sampling process becomes deterministic.
In this case, the sampling result is solely determined by the initial value xT , which can be considered
as a latent code. The sampling process can also be equivalently described as solving an Ordinary
Differential Equation (ODE) using an ODE solver [54]. In our work, we choose deterministic DDIM
to implement the diffusion model and use the following formula:
x0 = ODESolve(xT ; ϵθ, T, 0)
(3)
to represent the process of sampling from xT to x0 using a pretrained noise estimator ϵθ.
Image Translation using Diffusion Model.
A large number of image translation methods [75, 8,
20, 39, 57, 14, 29, 37] based on diffusion models have been proposed. In our method, we will adopt
a simple approach. First, we assume that the diffusion models used in our work are all conditional
diffusion models that support condition c as input to control the generated results. Taking the example
shown in Fig. 2 (a), suppose we want to transform an image of a cat into an image of a tiger. We add
noise to the cat image using the forward process (Eq. 1) to obtain the intermediate noise, and then
control the backward sampling process (Eq. 2) from noise by inputting a condition (prompt=“tiger”),
resulting in a new tiger image. In general, if the sampling condition is set to c, our conditional
sampling process can be expressed based on Eq. 3 as follows:
x0 = ODESolve(xT ; ϵθ, c, T, 0).
(4)
For image translation, there are two properties that need to be considered: the structural consistency
of the two images before and after the translation, and whether the translation process is invertible.
4
Hide Process
Reveal Process
Private Key
Public Key
Private Key
Public Key
Social Media
Internet
Transmission
Figure 3: Our coverless image steganography framework CRoSS. The diffusion model we choose is
a conditional diffusion model, which supports conditional inputs to control the generation results. We
choose the deterministic DDIM as the sampling strategy and use the two different conditions (kpri
and kpub) given to the model as the private key and the public key.
Algorithm 1 The Hide Process of CRoSS.
Input: The secret image xsec which will be hidden, a pre-trained conditional diffusion model with
noise estimator ϵθ, the number T of time steps for sampling and two different conditions kpri and
kpub which serve as the private and public keys.
Output: The container image xcont used to hide the secret image xsec.
xnoise = ODESolve(xsec; ϵθ, kpri, 0, T)
xcont = ODESolve(xnoise; ϵθ, kpub, T, 0)
return xcont
Structural consistency is crucial for most applications related to image translation, but for coverless
image steganography, ensuring the invertibility of the translation process is the more important goal.
To achieve invertible image translation, we utilize DDIM Inversion based on deterministic DDIM.
DDIM Inversion Makes an Invertible Image Translation.
DDIM Inversion (shown in Fig. 2
(b)), as the name implies, refers to the process of using DDIM to achieve the conversion from an
image to a latent noise and back to the original image. The idea is based on the approximation of
forward and backward differentials in solving ordinary differential equations [54, 29]. Intuitively, in
the case of deterministic DDIM, it allows s and t in Eq. 2 to be any two steps (i.e., allowing s < t
and s > t). When s < t, Eq. 2 performs the backward process, and when s > t, Eq. 2 performs the
forward process. As the trajectories of forward and backward processes are similar, the input and
output images are very close, and the intermediate noise xT can be considered as the latent variable
of the inversion. In our work, we use the following formulas:
xT = ODESolve(x0; ϵθ, c, 0, T),
x′
0 = ODESolve(xT ; ϵθ, c, T, 0),
(5)
to represent the DDIM Inversion process from the original image x0 to the latent code xT and from
the latent code xT back to the original image x0 (the output image is denoted as x′
0 and x′
0 ≈x0).
Based on DDIM Inversion, we have achieved the invertible relationship between images and latent
noises. As long as we use deterministic DDIM to construct the image translation framework, the
entire framework can achieve invertibility with two DDIM Inversion loops. It is the basis of our
coverless image steganography framework, which will be described in detail in the next subsection.
3.3
The Coverless Image Steganography Framework CRoSS
Our basic framework CRoSS is based on a conditional diffusion model, whose noise estimator is
represented by ϵθ, and two different conditions that serve as inputs to the diffusion model. In our
work, these two conditions can serve as the private key and public key (denoted as kpri and kpub), as
shown in Fig.3, with detailed workflow described in Algo.1 and Algo. 2. We will introduce the entire
CRoSS framework in two parts: the hide process and the reveal process.
The Process of Hide Stage.
In the hide stage, we attempt to perform translation between the
secret image xsec and the container image xcont using the forward and backward processes of
deterministic DDIM. In order to make the images before and after the translation different, we use
the pre-trained conditional diffusion model with different conditions in the forward and backward
processes respectively. These two different conditions also serve as private and public keys in the
CRoSS framework. Specifically, the private key kpri is used for the forward process, while the
5
Algorithm 2 The Reveal Process of CRoSS.
Input: The container image x′
cont that has been transmitted over the Internet (may be degraded
from xcont), the pre-trained conditional diffusion model with noise estimator ϵθ, the number T of
time steps for sampling, the private key kpri and public key kpub.
Output: The revealed image xrev.
x′
noise = ODESolve(x′
cont; ϵθ, kpub, 0, T)
xrev = ODESolve(x′
noise; ϵθ, kpri, T, 0)
return xrev
Reveal Backward
Reveal Forward
Social Media
Internet
Transmission
Candidate Revealed Images
Scenario#2
Guessed Public Key
Scenario#1
Possible Private Keys
“What is the secret 
image behind the 
container image? I 
just see a tiger in the 
container image.
Maybe we can take 
this word as public key 
to try.”
Receiver
Receiver
“I guess the private key 
may be something related 
to animals, like a cat, lion, 
leopard, ... . I try to use 
these words as the private 
keys to generate some 
condidates, but I do not 
know which one is true:(”
Receiver
“I got this from social media and there 
are no evidences for me to judge if this 
image is a container. The visual quality of 
this image is high and I can not find any 
difference between this image and other 
natural images.”
Scenario#3
Security for Avoiding Detection
Transmitted Container Image
“cat”
“lion”
“leopard”
Figure 4: Further explanation of the CRoSS framework. We simulated the possible problems that a
receiver may encounter in three different scenarios during the reveal process.
public key kpub is used for the backward process. After getting the container image xcont, it will be
transmitted over the Internet and publicly accessible to all potential receivers.
The Roles of the Private and Public Keys in Our CRoSS Framework.
In CRoSS, we found
that these given conditions can act as keys in practical use. The private key is used to describe
the content in the secret image, while the public key is used to control the content in the container
image. For the public key, it is associated with the content in the container image, so even if it is
not manually transmitted over the network, the receiver can guess it based on the received container
image (described in Scenario#2 of Fig. 4). For the private key, it determines whether the receiver can
successfully reveal the original image, so it cannot be transmitted over public channels.
The Process of Reveal Stage.
In the reveal stage, assuming that the container image has been
transmitted over the Internet and may have been damaged as x′
cont, the receiver needs to reveal it
back to the secret image through the same forward and backward process using the same conditional
diffusion model with corresponding keys. Throughout the entire coverless image steganography
process, we do not train or fine-tune the diffusion models specifically for image steganography tasks
but rely on the inherent invertible image translation guaranteed by the DDIM Inversion.
The Security Guaranteed by CRoSS.
Some questions about security may be raised, such as:
What if the private key is guessed by the receivers? Does the container image imply the possible
hidden secret image? We clarify these questions from two aspects: (1) Since the revealed image is
generated by the diffusion model, the visual quality of the revealed image is relatively high regardless
of whether the input private key is correct or not. The receiver may guess the private key by exhaustive
method, but it is impossible to judge which revealed image is the true secret image from a pile of
candidate revealed images (described in Scenario#1 of Fig. 4). (2) Since the container image is
also generated by the diffusion model, its visual quality is guaranteed by the generative prior of the
diffusion model. Moreover, unlike cover-based methods that explicitly store clues in the container
image, the container image in CRoSS does not contain any clues that can be detected or used to extract
the secret image. Therefore, it is hard for the receiver to discover that the container image hides other
images or to reveal the secret image using some detection method (described in Scenario#3 of Fig. 4).
Various Variants for Public and Private Keys.
Our proposed CRoSS relies on pre-trained con-
ditional diffusion models with different conditions kpub, kpri and these conditions serve as keys in
the CRoSS framework. In practical applications, we can distinguish different types of conditions of
diffusion models in various ways. Here are some examples: (1) Prompts: using the same checkpoint
6
Figure 5: Deep steganalysis results by the latest SID [61]. As the number of leaked samples increases,
methods whose detection accuracy curves grow more slowly and approach 50% exhibit higher
security. The right is the recall curve of different methods under the StegExpose [7] detector. The
closer the area enclosed by the curve and the coordinate axis is to 0.5, the closer the method is to the
ideal evasion of the detector.
of text-to-image diffusion models like Stable Diffusion [49] but different prompts as input condi-
tions; (2) LoRAs [23]: using the same checkpoint initialization, but loading different LoRAs; (3)
ControlNets [74]: loading the same checkpoint but using ControlNet with different conditions.
4
Experiment
4.1
Implementation Details
Experimental Settings. In our experiment, we chose Stable Diffusion [49] v1.5 as the conditional
diffusion model, and we used the deterministic DDIM [54] sampling algorithm. Both the forward
and backward processes consisted of 50 steps. To achieve invertible image translation, we set the
guidance scale of Stable Diffusion to 1. For the given conditions, which serve as the private and
public keys, we had three options: prompts, conditions for ControlNets [74] (depth maps, scribbles,
segmentation maps), and LoRAs [23]. All experiments were conducted on a GeForce RTX 3090
GPU card, and our method did not require any additional training or fine-tuning for the diffusion
model. The methods we compared include RIIS [68], HiNet [26], Baluja [6], and ISN [35].
Data Preparation. To perform a quantitative and qualitative analysis of our method, we collect a
benchmark with a total of 260 images and generate corresponding prompt keys specifically tailored
for the coverless image steganography, dubbed Stego260. We categorize the dataset into three classes,
namely humans, animals, and general objects (such as architecture, plants, food, furniture, etc.). The
images in the dataset are sourced from publicly available datasets [1, 2] and Google search engines.
For generating prompt keys, we utilize BLIP [32] to generate private keys and employ ChatGPT or
artificial adjustment to perform semantic modifications and produce public keys in batches. More
details about the dataset can be found in the supplementary material.
4.2
Property Study#1: Security
Methods
NIQE ↓
|Detection Accuracy - 50| ↓
XuNet [67]
YedroudjNet [70]
KeNet [71]
Baluja [6]
3.43±0.08
45.18±1.69
43.12±2.18
46.88±2.37
ISN [35]
2.87±0.02
5.14±0.44
3.01±0.29
8.62±1.19
HiNet [26]
2.94±0.02
5.29±0.44
3.12±0.36
8.33±1.22
RIIS [68]
3.13±0.05
0.73±0.13
0.24±0.08
4.88±1.15
CRoSS (ours)
3.04
1.32
0.18
2.11
Table 1: Security analysis. NIQE indicates the vi-
sual quality of container images, lower is better.
The closer the detection rate of a method approxi-
mates 50%, the more secure the method is consid-
ered, as it suggests its output is indistinguishable
from random chance. The best results are red and
the second-best results are blue.
In Fig. 5, the recent learning-based steganalysis
method Size-Independent-Detector (SID) [61]
is retrained with leaked samples from testing
results of various methods on Stego260. The
detection accuracy of CRoSS increases more
gradually as the number of leaked samples rises,
compared to other methods. The recall curves
on the right also reveal the lower detection ac-
curacy of our CRoSS, indicating superior anti-
steganalysis performance.
Our security encompasses two aspects: imper-
ceptibility in visual quality against human suspi-
cion and resilience against steganalysis attacks.
NIQE is a no-reference image quality assessment (IQA) model to measure the naturalness and visual
7
Prompt1: a young cute chinese girl with long hair
Prompt2: a baby with long hair
Prompt1: a koala is sitting on a branch 
Prompt2: a baby raccoon cub is walking on a branch
Prompt1: a grey chair in the living room 
Prompt2: a grey sofa in the living room
Prompt1: Sydney Opera House 
Prompt2: a boat
Secret
Container
Revealed
Prompt1: leaning tower of pisa
Prompt2: a lighthouse with a red flag
Prompt1: a baby badger cub is walking through the grass
Prompt2: a baby raccoon cub is walking through the grass
Prompt1: a young girl with blond hair
Prompt2: a wrinkled elderly woman with white hair
Prompt1: a multi-layer hamburger
Prompt2: a three-layer sandwich
Secret
Container
Revealed
Prompt1: a cute rabbit
Prompt2: a cute cat
Prompt1: Eiffel Tower under the blue sky
Prompt2: a tree under the blue sky
Prompt1: Obama is giving a speech
Prompt2: Biden is giving a speech
Prompt1: tomatoes hanging on tree
Prompt2: green apples hanging on tree
Secret
Container
Revealed
Figure 6: Visual results of the proposed CRoSS controlled by different prompts. The container
images are realistic and the revealed images have well semantic consistency with the secret images.
Secret
Container
Revealed
Secret
Container
Revealed
Secret
Container
Revealed
ControlNets
LoRAs
Figure 7: Visual results of our CRoSS controlled by different ControlNets and LoRAs. Depth maps,
scribbles, and segmentation maps are presented in the lower right corner of the images.
security without any reference image or human feedback. In Tab. 1, the lower the NIQE score, the
less likely it is for the human eye to identify the image as a potentially generated container for hiding
secret information. Our NIQE is close to those of other methods, as well as the original input image
(2.85), making it difficult to discern with human suspicion. Anti-analysis security is evaluated by
three steganalysis models XuNet[67], YedroudjNet[70], and KeNet[71], for which lower detection
accuracy denotes higher security. Our CRoSS demonstrates the highest or near-highest resistance
against various steganalysis methods.
4.3
Property Study#2: Controllability
To verify the controllability and flexibility of the proposed CRoSS, various types of private and public
keys such as prompts, ControlNets, and LoRAs † are incorporated in our framework. As illustrated in
Fig. 6, our framework is capable of effectively hiding the secret images in the container images based
on the user-provided “Prompt2” without noticeable artifacts or unrealistic image details. The container
image allows for the seamless modification of a person’s identity information, facial attributes, as
†The last row of Fig. 7 are generated via LoRAs downloaded from https://civitai.com/.
8
Revealed image
Secret image
Clean
Shoot
WeChat
Clean
Shoot
WeChat
Clean
Shoot
WeChat
CRoSS
HiNet
RIIS
Figure 8: Visual comparisons of our CRoSS and other methods [68, 26] under two real-world
degradations, namely “WeChat” and “Shoot”. Obviously, our method can reconstruct the content of
secret images, while other methods exhibit significant color distortion or have completely failed.
Methods
clean
Gaussian noise
Gaussian denoiser [62]
JPEG compression
JPEG enhancer [62]
σ = 10
σ = 20
σ = 30
σ = 10
σ = 20
σ = 30
Q = 20
Q = 40
Q = 80
Q = 20
Q = 40
Q = 80
Baluja [6]
34.24
10.30
7.54
6.92
7.97
6.10
5.49
6.59
8.33
11.92
5.21
6.98
9.88
ISN [35]
41.83
12.75
10.98
9.93
11.94
9.44
6.65
7.15
9.69
13.44
5.88
8.08
11.63
HiNet [26]
42.98
12.91
11.54
10.23
11.87
9.32
6.87
7.03
9.78
13.23
5.59
8.21
11.88
RIIS [68]
43.78
26.03
18.89
15.85
20.89
15.97
13.92
22.03
25.41
27.02
13.88
16.74
20.13
CRoSS (ours)
23.79
21.89
20.19
18.77
21.39
21.24
21.02
21.74
22.74
23.51
20.60
21.22
21.19
Table 2: PSNR(dB) results of the proposed CRoSS and other methods under different levels of
degradations. The proposed CRoSS can achieve superior data fidelity in most settings. The best
results are red and the second-best results are blue.
well as species of animals. The concepts of these two prompts can also differ significantly such as
the Eiffel Tower and a tree, thereby enhancing the concealment capability and stealthiness of the
container images. Meanwhile, the revealed image extracted with “Prompt1” exhibits well fidelity by
accurately preserving the semantic information of secret images. Besides prompts, our CRoSS also
supports the utilization of various other control conditions as keys, such as depth maps, scribbles, and
segmentation maps. As depicted in Fig. 7, our methods can effectively hide and reveal the semantic
information of the secret image without significantly compromising the overall visual quality or
arousing suspicion. Our CRoSS can also adopt different LoRAs as keys, which is conducive to
personalized image steganography.
4.4
Property Study#3: Robustness
Simulation Degradation. To validate the robustness of our method, we conduct experiments on
simulation degradation such as Gaussian noise and JPEG compression. As reported in Tab. 2, our
CRoSS performs excellent adaptability to various levels of degradation with minimal performance
decrease, while other methods suffer significant drops in fidelity (over 20dB in PSNR). Meanwhile,
our method achieves the best PSNR at σ = 20 and σ = 30. Furthermore, when we perform nonlinear
image enhancement [62] on the degraded container images, all other methods have deteriorations but
our CRoSS can still maintain good performance and achieve improvements in the Gaussian noise
degradation. Noting that RIIS [68] is trained exclusively on degraded data, but our CRoSS is naturally
resistant to various degradations in a zero-shot manner and outperforms RIIS in most scenarios.
Real-World Degradation. We further choose two real-world degradations including “WeChat” and
“Shoot”. Specifically, we send and receive container images via the pipeline of WeChat to implement
network transmission. Simultaneously, we utilize the mobile phone to capture the container images
on the screen and then simply crop and warp them. Obviously, as shown in Fig. 8, all other methods
have completely failed or present severe color distortion subjected to these two extremely complex
degradations, yet our method can still reveal the approximate content of the secret images and
maintain well semantic consistency, which proves the superiority of our method.
5
Conclusion
We propose a coverless image steganography framework named CRoSS (Controllable, Robust, and
Secure Image Steganography) based on diffusion models. This framework leverages the unique
9
properties of diffusion models and demonstrates superior performance in terms of security, control-
lability, and robustness compared to existing methods. To the best of our knowledge, CRoSS is
the first attempt to integrate diffusion models into the field of image steganography. In the future,
diffusion-based image steganography techniques will continue to evolve, expanding their capacity
and improving fidelity while maintaining their existing advantages.
References
[1] https://github.com/aisegmentcn/matting_human_datasets, 2019.
[2] https://www.kaggle.com/datasets/iamsouravbanerjee/
animal-image-dataset-90-different-animals, 2022.
[3] Rameen Abdal, Yipeng Qin, and Peter Wonka. Image2stylegan: How to embed images into the
stylegan latent space? In Proceedings of the IEEE/CVF International Conference on Computer
Vision (ICCV), 2019.
[4] Alaa A Jabbar Altaay, Shahrin Bin Sahib, and Mazdak Zamani. An introduction to image
steganography techniques. In 2012 International Conference on Advanced Computer Science
Applications and Technologies (ACSAT), 2012.
[5] Shumeet Baluja. Hiding images in plain sight: Deep steganography. In Advances in Neural
Information Processing Systems (NeurIPS), 2017.
[6] Shumeet Baluja. Hiding images within images. IEEE transactions on pattern analysis and
machine intelligence (TPAMI), 2019.
[7] Benedikt Boehm.
Stegexpose-a tool for detecting lsb steganography.
arXiv preprint
arXiv:1410.6656, 2014.
[8] Tim Brooks, Aleksander Holynski, and Alexei A Efros. Instructpix2pix: Learning to follow
image editing instructions. arXiv preprint arXiv:2211.09800, 2022.
[9] Chi-Kwong Chan and Lee-Ming Cheng. Hiding data in images by simple lsb substitution.
Pattern recognition, 2004.
[10] Yambem Jina Chanu, Kh Manglem Singh, and Themrichon Tuithung. Image steganography
and steganalysis: A survey. International Journal of Computer Applications, 2012.
[11] Abbas Cheddad, Joan Condell, Kevin Curran, and Paul Mc Kevitt. Digital image steganography:
Survey and analysis of current methods. IEEE Transactions on Signal Processing (TIP), 2010.
[12] Xuxin Cheng, Bowen Cao, Qichen Ye, Zhihong Zhu, Hongxiang Li, and Yuexian Zou. Ml-lmcl:
Mutual learning and large-margin contrastive learning for improving asr robustness in spoken
language understanding. In Findings of the Association for Computational Linguistics (ACL),
2023.
[13] Xuxin Cheng, Qianqian Dong, Fengpeng Yue, Tom Ko, Mingxuan Wang, and Yuexian Zou. M
3 st: Mix at three levels for speech translation. In IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), 2023.
[14] Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon. Ilvr:
Conditioning method for denoising diffusion probabilistic models. In Proceedings of the
IEEE/CVF International Conference on Computer Vision (ICCV), 2021.
[15] Ingemar Cox, Matthew Miller, Jeffrey Bloom, Jessica Fridrich, and Ton Kalker. Digital
watermarking and steganography. Morgan kaufmann, 2007.
[16] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. In
Advances in Neural Information Processing Systems (NeurIPS), 2021.
[17] Laurent Dinh, David Krueger, and Yoshua Bengio. Nice: Non-linear independent components
estimation. arXiv preprint arXiv:1410.8516, 2014.
10
[18] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real NVP. In
International Conference on Learning Representations (ICLR), 2017.
[19] Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H Bermano, Gal Chechik, and
Daniel Cohen-Or. An image is worth one word: Personalizing text-to-image generation using
textual inversion. arXiv preprint arXiv:2208.01618, 2022.
[20] Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or.
Prompt-to-prompt image editing with cross attention control. arXiv preprint arXiv:2208.01626,
2022.
[21] Stefan Hetzl and Petra Mutzel. A graph–theoretic approach to steganography. In IFIP Interna-
tional Conference on Communications and Multimedia Security, 2005.
[22] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In
Advances in Neural Information Processing Systems (NeurIPS), 2020.
[23] Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang,
Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. In
International Conference on Learning Representations (ICLR), 2022.
[24] Shoko Imaizumi and Kei Ozawa. Multibit embedding algorithm for steganography of palette-
based images. In Image and Video Technology: 6th Pacific-Rim Symposium (PSIVT), 2013.
[25] Priyank Jaini, Kira A Selby, and Yaoliang Yu. Sum-of-squares polynomial flow. In International
Conference on Machine Learning (ICML), 2019.
[26] Junpeng Jing, Xin Deng, Mai Xu, Jianyi Wang, and Zhenyu Guan. Hinet: Deep image hiding
by invertible network. In Proceedings of the IEEE/CVF International Conference on Computer
Vision (ICCV), 2021.
[27] Inas Jawad Kadhim, Prashan Premaratne, Peter James Vial, and Brendan Halloran. Compre-
hensive survey of image steganography: Techniques, evaluations, and trends in future research.
Neurocomputing, 2019.
[28] Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. Denoising diffusion restoration
models. In Advances in Neural Information Processing Systems (NeurIPS), 2022.
[29] Gwanghyun Kim, Taesung Kwon, and Jong Chul Ye. Diffusionclip: Text-guided diffusion
models for robust image manipulation.
In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR), 2022.
[30] Durk P Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, and Max Welling.
Improved variational inference with inverse autoregressive flow. In Advances in Neural Infor-
mation Processing Systems (NeurIPS), 2016.
[31] Bin Li, Ming Wang, Jiwu Huang, and Xiaolong Li. A new cost function for spatial image
steganography. In Proceedings of the International Conference on Image Processing (ICIP),
2014.
[32] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi.
Blip: Bootstrapping language-
image pre-training for unified vision-language understanding and generation. In International
Conference on Machine Learning (ICML), 2022.
[33] Yung-Hui Li, Ching-Chun Chang, Guo-Dong Su, Kai-Lin Yang, Muhammad Saqlain Aslam,
and Yanjun Liu. Coverless image steganography using morphed face recognition based on
convolutional neural network. EURASIP Journal on Wireless Communications and Networking,
2022.
[34] Qiang Liu, Xuyu Xiang, Jiaohua Qin, Yun Tan, and Yao Qiu. Coverless image steganography
based on densenet feature mapping. EURASIP Journal on Image and Video Processing, 2020.
[35] Shao-Ping Lu, Rong Wang, Tao Zhong, and Paul L Rosin. Large-capacity image steganography
based on invertible neural networks. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR), 2021.
11
[36] Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte, and Luc
Van Gool. Repaint: Inpainting using denoising diffusion probabilistic models. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022.
[37] Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano
Ermon. SDEdit: Guided image synthesis and editing with stochastic differential equations. In
International Conference on Learning Representations (ICLR), 2022.
[38] Mohammed Saad Mohamed, EH Hafez, et al. Coverless image steganography based on jigsaw
puzzle image generation. Computers, Materials and Continua, 2021.
[39] Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or. Null-text inversion
for editing real images using guided diffusion models. arXiv preprint arXiv:2211.09794, 2022.
[40] Chong Mou, Xintao Wang, Liangbin Xie, Jian Zhang, Zhongang Qi, Ying Shan, and Xiaohu Qie.
T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion
models. arXiv preprint arXiv:2302.08453, 2023.
[41] Bui Cong Nguyen, Sang Moon Yoon, and Heung-Kyu Lee. Multi bit plane image steganography.
In International Workshop on Digital Watermarking, 2006.
[42] Michiharu Niimi, Hideki Noda, Eiji Kawaguchi, and Richard O Eason. High capacity and secure
digital steganography to palette-based images. In Proceedings of the International Conference
on Image Processing (ICIP), 2002.
[43] Feng Pan, Jun Li, and Xiaoyuan Yang. Image steganography method based on pvd and modulus
function. In International Conference on Electronics, Communications and Control (ICECC),
2011.
[44] George Papamakarios, Theo Pavlakou, and Iain Murray. Masked autoregressive flow for density
estimation. In Advances in Neural Information Processing Systems (NeurIPS), 2017.
[45] Tomáš Pevn`y, Tomáš Filler, and Patrick Bas. Using high-dimensional image models to perform
highly undetectable steganography. In Information Hiding: 12th International Conference
(IHIP), 2010.
[46] Niels Provos and Peter Honeyman. Hide and seek: An introduction to steganography. IEEE
Symposium on Security and Privacy, 2003.
[47] Jiaohua Qin, Yuanjing Luo, Xuyu Xiang, Yun Tan, and Huajun Huang. Coverless image
steganography: a survey. IEEE Access, 2019.
[48] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical
text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 2022.
[49] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-
resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition (CVPR), 2022.
[50] Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman.
Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
2023.
[51] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed
Kamyar Seyed Ghasemipour, Raphael Gontijo-Lopes, Burcu Karagol Ayan, Tim Salimans,
Jonathan Ho, David J. Fleet, and Mohammad Norouzi. Photorealistic text-to-image diffusion
models with deep language understanding. In Advances in Neural Information Processing
Systems (NeurIPS), 2022.
[52] Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J Fleet, and Mohammad
Norouzi. Image super-resolution via iterative refinement. IEEE Transactions on Pattern Analysis
and Machine Intelligence (TPAMI), 2022.
12
[53] Haichao Shi, Jing Dong, Wei Wang, Yinlong Qian, and Xiaoyu Zhang. Ssgan: secure steganog-
raphy based on generative adversarial networks. In Pacific Rim Conference on Multimedia,
2017.
[54] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In
International Conference on Learning Representations (ICLR), 2021.
[55] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data
distribution. In Advances in Neural Information Processing Systems (NeurIPS), 2019.
[56] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and
Ben Poole. Score-based generative modeling through stochastic differential equations. In
International Conference on Learning Representations (ICLR), 2021.
[57] Xuan Su, Jiaming Song, Chenlin Meng, and Stefano Ermon. Dual diffusion implicit bridges for
image-to-image translation. In International Conference on Learning Representations (ICLR),
2023.
[58] Weixuan Tang, Bin Li, Shunquan Tan, Mauro Barni, and Jiwu Huang. Cnn-based adversarial
embedding for image steganography. IEEE Transactions on Information Forensics and Security
(TIFS), 2019.
[59] Weixuan Tang, Shunquan Tan, Bin Li, and Jiwu Huang. Automatic steganographic distortion
learning using a generative adversarial network. IEEE Signal Processing Letters, 2017.
[60] Piyu Tsai, Yu-Chen Hu, and Hsiu-Lien Yeh. Reversible image hiding scheme using predictive
coding and histogram shifting. Signal Processing, 2009.
[61] Clement Fuji Tsang and Jessica Fridrich. Steganalyzing images of arbitrary size with cnns.
Electronic Imaging, 2018.
[62] Xintao Wang, Liangbin Xie, Chao Dong, and Ying Shan. Real-esrgan: Training real-world
blind super-resolution with pure synthetic data. In Proceedings of the IEEE/CVF International
Conference on Computer Vision (ICCV), 2021.
[63] Yinhuai Wang, Jiwen Yu, Runyi Yu, and Jian Zhang. Unlimited-size diffusion restoration.
In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
Workshops (CVPRW), 2023.
[64] Yinhuai Wang, Jiwen Yu, and Jian Zhang. Zero-shot image restoration using denoising diffusion
null-space model. In International Conference on Learning Representations (ICLR), 2023.
[65] Zhixin Wang, Xiaoyun Zhang, Ziying Zhang, Huangjie Zheng, Mingyuan Zhou, Ya Zhang, and
Yanfeng Wang. Dr2: Diffusion-based robust degradation remover for blind face restoration. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
2023.
[66] Mingqing Xiao, Shuxin Zheng, Chang Liu, Yaolong Wang, Di He, Guolin Ke, Jiang Bian,
Zhouchen Lin, and Tie-Yan Liu. Invertible image rescaling. In European Conference on
Computer Vision (ECCV), 2020.
[67] Guanshuo Xu, Han-Zhou Wu, and Yun-Qing Shi. Structural design of convolutional neural
networks for steganalysis. IEEE Signal Processing Letters, 2016.
[68] Youmin Xu, Chong Mou, Yujie Hu, Jingfen Xie, and Jian Zhang. Robust invertible image
steganography. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR), 2022.
[69] Jianhua Yang, Danyang Ruan, Jiwu Huang, Xiangui Kang, and Yun-Qing Shi. An embedding
cost learning framework using gan. IEEE Transactions on Information Forensics and Security
(TIFS), 2019.
[70] Mehdi Yedroudj, Frédéric Comby, and Marc Chaumont. Yedroudj-net: An efficient cnn
for spatial steganalysis. In IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP), 2018.
13
[71] Weike You, Hong Zhang, and Xianfeng Zhao. A siamese cnn for image steganalysis. IEEE
Transactions on Information Forensics and Security (TIFS), 2020.
[72] Jiwen Yu, Yinhuai Wang, Chen Zhao, Bernard Ghanem, and Jian Zhang. Freedom: Training-free
energy-guided conditional diffusion model. arXiv:2303.09833, 2023.
[73] Kevin Alex Zhang, Alfredo Cuesta-Infante, Lei Xu, and Kalyan Veeramachaneni. Steganogan:
High capacity image steganography with gans. arXiv preprint arXiv:1901.03892, 2019.
[74] Lvmin Zhang and Maneesh Agrawala. Adding conditional control to text-to-image diffusion
models. arXiv preprint arXiv:2302.05543, 2023.
[75] Min Zhao, Fan Bao, Chongxuan Li, and Jun Zhu. Egsde: Unpaired image-to-image transla-
tion via energy-guided stochastic differential equations. In Advances in Neural Information
Processing Systems (NeurIPS), 2022.
[76] Zhili Zhou, Huiyu Sun, Rohan Harit, Xianyi Chen, and Xingming Sun. Coverless image
steganography without embedding. In Cloud Computing and Security: First International
Conference (ICCCS), 2015.
[77] Jiren Zhu, Russell Kaplan, Justin Johnson, and Li Fei-Fei. Hidden: Hiding data with deep
networks. In European Conference on Computer Vision (ECCV), 2018.
[78] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image
translation using cycle-consistent adversarial networks. In Proceedings of the IEEE International
Conference on Computer Vision (ICCV), 2017.
14
"
20285,2023,American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers,"American Stories: A Large-Scale Structured Text
Dataset of Historical U.S. Newspapers
Melissa Dell1,2∗, Jacob Carlson1, Tom Bryan1, Emily Silcock1, Abhishek Arora1, Zejiang Shen3,
Luca D’Amico-Wong1, Quan Le4, Pablo Querubin2,5, Leander Heldring6
1Harvard University; Cambridge, MA, USA.
2National Bureau of Economic Research; Cambridge, MA, USA.
3Massachusetts Institute of Technology; Cambridge, MA, USA.
4Princeton University; Princeton, NJ, USA.
5New York University; New York, NY, USA.
6Kellogg School of Management, Northwestern University, Evanston, IL, USA.
∗Corresponding author: melissadell@fas.harvard.edu.
Abstract
Existing full text datasets of U.S. public domain newspapers do not recognize the
often complex layouts of newspaper scans, and as a result the digitized content
scrambles texts from articles, headlines, captions, advertisements, and other lay-
out regions. OCR quality can also be low. This study develops a novel, deep learn-
ing pipeline for extracting full article texts from newspaper images and applies it
to the nearly 20 million scans in Library of Congress’s public domain Chronicling
America collection. The pipeline includes layout detection, legibility classifica-
tion, custom OCR, and association of article texts spanning multiple bounding
boxes. To achieve high scalability, it is built with efficient architectures designed
for mobile phones. The resulting American Stories dataset provides high quality
data that could be used for pre-training a large language model to achieve better
understanding of historical English and historical world knowledge. The dataset
could also be added to the external database of a retrieval-augmented language
model to make historical information - ranging from interpretations of political
events to minutiae about the lives of people’s ancestors - more widely accessible.
Furthermore, structured article texts facilitate using transformer-based methods
for popular social science applications like topic classification, detection of repro-
duced content, and news story clustering. Finally, American Stories provides a
massive silver quality dataset for innovating multimodal layout analysis models
and other multimodal applications.
1
Introduction
Historical local newspapers provide a massive repository of texts about American communities and
their inhabitants that can elucidate topics ranging from semantic change to political polarization
to the construction of national and cultural identities to the minutiae of the daily lives of people’s
ancestors. Given the enormous breadth and depth of content, historical newspapers have been widely
studied, yet existing open source U.S. newspaper datasets have significant limitations that complicate
the extent to which modern deep learning methods can leverage and liberate their content.
Library of Congress’s Chronicling America project [19] is the primary public domain historical U.S.
newspaper dataset. It consists of around 20 million historical newspaper scans and their correspond-
ing digitized texts. Its content is concentrated before 1925, as this content has entered the public
37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Bench-
marks.
domain. Chronicling America does not recognize oftentimes complex newspaper layouts, and so
digitized texts are provided at the page level, often scrambling headlines, articles, advertisements,
captions, and other content regions together. Because a non-trivial share of the underlying scans
are illegible, incoherent texts are prevalent, with illegibility varying across space and time. This
complicates applying natural language processing (NLP) and statistical methods, and the data are
not of sufficient quality to use for training a large language model to achieve a better understanding
of historical English and historical world knowledge.
To address these limitations, we develop a pipeline for cheaply extracting high quality digitized ar-
ticle texts and layout regions from newspaper scans. First, layout detection predicts the coordinates
and classes of content regions - e.g. articles, headlines, bylines, advertisements, pictures, etc. - us-
ing object detection methods [34]. Then, an image classifier removes illegible text bounding boxes.
We next digitize the text regions using a novel optical character recognition (OCR) architecture that
yields highly scalable, accurate results within our constrained budget. The focus on cost effective-
ness makes the pipeline accessible to others with limited budgets who would like to digitize massive
historical document collections. Finally, we associate headline, byline, and article bounding boxes.
We do not process foreign language newspapers, as off-the-shelf OCR tends to perform poorly on
the diverse languages and scripts.
The resulting American Stories (Structured text on reporting in every state) dataset contains
1.14B content regions. The dataset has extensive geographic coverage across all states and has
content dating as far back as the 17th century, although the bulk of content comes from the early
20th century. Figure 1 shows the distribution of scans across years and states. The vast majority of
American Stories is older than the 72 year rule that the U.S. government uses to release personal
information (e.g., from the census) into the public domain.
(a) Scans Across Time
(b) Scans Across Space
Figure 1: Scans in the Chronicling America database across time and space.
We show that the pipeline produces accurate predictions. The resulting texts could be used for
historical language model training, or added to an external database of a retrieval augmented lan-
guage model to facilitate the study of topics ranging from international events to family history. The
layouts and corresponding texts could provide a massive silver quality dataset for applications like
multimodal layout analysis and classification. The American Stories dataset also yields signifi-
cantly better performance on social science analyses than the Chronicling America OCR and allows
analyses that would be impossible without structured article texts. For example, we cluster article
embeddings to detect which stories (e.g., Pancho Villa Expedition, 1916) received the most coverage
each year.
The rest of this study is organized as follows. Section 2 discussed related literature and Section 3
describes the American Stories dataset. Section 4 outlines the digitization pipeline, and Section
5 evaluates the quality of the outputs. Section 6 discusses applications and Section 7 considers
limitations and recommended usage.
2
Related Literature
Public domain newspaper datasets exist for many countries, but typically pipelines are proprietary,
as the norm is to outsource digitization to a private company. Commercial newspaper databases
2
likewise do not disclose their pipelines, resulting in a dearth of open-source methods. The most
closely related work to American Stories is the open-source Newspaper Navigator dataset [15].
The main, and crucial, difference between American Stories and [15] is that [15] does not detect
bounding boxes of articles. [15] focuses on 7 classes of visual content: headlines, photographs,
illustrations, maps, comics, editorial cartoons, and advertisements. Distinguishing articles enables
legibility classification, application of custom OCR, and association of articles across bounding
boxes. These tasks are at the core of our contribution, and enable the usefulness of our contribution
for downstream applications. In addition, the OCR in [15] is limited to Chronicling America’s OCR,
which we show leads to a quality deterioration.
While we focus exclusively on texts where the entire newspaper is indisputably in the public domain
(typically because it was published more than 95 years ago), it is worth noting that our pipeline
could help address some of the copyright issues that have limited the public availability of historical
newspapers. Outside of the nation’s most widely circulated newspapers, it was rare for local papers
to publish with a copyright notice or renew their copyright, required formalities until the latter half of
the 20th century. Hence, the majority of local papers well into the 20th century are off-copyright. Yet
these papers might sometimes print copyrighted content by third parties - e.g., frequently comics,
rarely ads, and occasional runs of syndicated fiction [23]. Individual news articles did not have
their copyrights renewed, as copyrighting yesterday’s news lacked commercial value. Detecting
individual content regions - e.g., so that ads and comics could be cropped out and fictional texts
removed with a classifier - is a prerequisite for removing content potentially under copyright. Some
copyright experts [23] have suggested this as a way forward for making historical newspapers more
accessible.
3
Dataset
Table 1 describes American Stories, totaling 1.14 billion content region bounding boxes. Head-
lines, images, bylines, and captions are OCR’ed if legible. The dataset contains 3,313 tokens per
page on average, making the full dataset 65.6 billion tokens.
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
Total
Text Bounding Boxes
Other Bounding Boxes
Boxes
Articles
Headlines
Captions
Bylines
Images
Ads
Tables
Mastheads
Legible
-
335M
368M
9.7M
14.7M
-
-
-
-
Illegible
-
26M
27M
0.9M
2.5M
-
-
-
-
Borderline
-
77M
22M
1.3M
1.2M
-
-
-
-
Total
1.14B
438M
417M
11.9M
18.4M
9.1M
221M
16.3M
4.9M
Table 1: American Stories dataset statistics.
American Stories provides the classes and coordinates for all content regions. Using the provided
metadata, it is straightforward for users to link the coordinates with the original scans, which can be
downloaded through the Library of Congress’s website. We do not OCR ads because they oftentimes
have unusual fonts and complex layouts, including scene text and complex tables with pricing or
schedule information, complicating OCR. The table class includes tabular article data, e.g. sporting
rosters. We do not transcribe these because accurately detecting and harmonizing the diversity of
table layouts is challenging with current technology. Newspaper headers are not OCR’ed because
most of their information is contained in the metadata. Mastheads - which contain subscription
information - and page numbers often used very small fonts and hence are disproportionately likely
to be illegible; page numbers can be inferred from the metadata.
Each text region is classified as legible, illegible, or borderline, with examples of each category
shown in Figure 2. Borderline forms the grey zone between clearly legible and clearly illegible texts
and is OCR’ed. Users can remove it if they would like to limit to the highest quality texts.
Substantial shares of illegible content can degrade language model training and bias downstream
applications. For example, it is common for social scientists to construct data based on the presence
of keyword terms [9], assigning a positive outcome if the term is present and a zero outcome oth-
erwise. Illegibility can bias downstream analyses if it is correlated with an underlying unobserved
factor. Figure 3 shows that illegibility is correlated with space and time, and hence likely to be cor-
3
Figure 2: Examples of legibility classification, as predicted by our trained model.
related with unobserved factors. Using our data, researchers can remove papers with high illegibility
rates if desired and more realistically assess selection into the database.
(a) Illegibility Across Time
(b) Illegibility Across Space
Figure 3: Illegible articles in the Chronicling America database across time and space.
American Stories has a Creative Commons CC-BY license, to encourage widespread use. The
data are available on the Hugging Face Hub1. The raw files are in a json format, and the Hugging
Face repo comes with a setup script that easily allows people to download both raw and parsed data
to facilitate language modeling and computational social science applications. The supplementary
materials and the Readme on the dataset repository provide a detailed usage guide.
4
Methods
Overview: The American Stories pipeline consists of four steps: layout/line detection, legibility
classification, OCR, and article association. The pipeline is available on Github2.
The pipeline’s modularity offers several advantages. Theoretically, localization (of layouts, lines,
words, and characters) and recognition (of characters, akin to classification) may rely on different
features of the image, suggesting modularity [31]. Practically, there are vast differences in the
number of labels required for training each component of the pipeline. Modularity also leads to
architectural simplicity. Swapping in different encoders is straightforward, which makes the pipeline
more customizable and future-proof. Off-the-shelf models performing a single pipeline task - like
Segment Anything [14] or an OCR engine - would be straightforward to swap in.
1https://huggingface.co/datasets/dell-research-harvard/AmericanStories
2https://github.com/dell-research-harvard/AmericanStories
4
The American Stories pipeline uses architectures designed for mobile phones - Yolo v8 [34] and
MobileNet v3 [10] - because the accuracy hit relative to much larger models was very modest and
deployment costs were over an order of magnitude lower. If budget is not a concern, it would be
straightforward to swap in a vision transformer, (e.g., [4, 1, 21]) and a two stage object detection
framework (e.g., [2]), variations that [3] examine quantitatively on Chronicling America.
The pipeline was run on Azure F-series CPU nodes. Training used an Nvidia A6000 GPU card.
Details are described in the Supplementary Materials.
Layout and Line Detection: Layout region coordinates and classes are detected using Yolo v8 [34],
with Figure 4 showing examples. We train the layout detection model on 2,202 labeled newspaper
images, consisting of 48,874 layout objects, with an average of 22 layout objects per page. All
annotations for the pipeline were created by undergraduate research assistants, with scans selected
randomly and using active learning [27]. To develop a general purpose model, we annotated scans
of public domain and off-copyright newspapers from throughout the 19th and 20th centuries. Scans
from Chronicling America comprise 13% of the training sample.
Figure 4: Variety of newspaper layouts with our layout detection pipeline outputs overlayed.
For content regions that are OCR’ed, we detect individual lines within each region using Yolo v8,
as lines are the input to OCR. The model is trained on 4,000 synthetic and 373 annotated line crops.
Yolo v8, like other object detection frameworks, takes square images as inputs. When the aspect
ratios of content regions differ significantly from squares, downstream OCR performance tends to
be adversely affected. Hence, for content regions with an aspect ratio greater than 2:1 (twice as
tall as wide), we split the layout region (with overlap), run line detection over each separate box,
and then run non-maximum suppression jointly over the resulting predictions. For the same reason,
before sending lines to OCR, we split lines with an aspect ratio below 1:30 (thirty times wider than
tall).
Legibility Classification: We classify headline, article, byline, and caption regions as legible, il-
legible, or borderline (see Figure 2) using an image classifier with a Mobilenet v3 backbone that is
trained on 1,094 double-labeled content region crops.
OCR: We aimed to deploy a highly accurate digitization pipeline within a constrained cloud com-
pute budget of $60,000 USD. As documented in detail in the supplementary materials, existing OCR
solutions did not meet these requirements. Commercial solutions were far too costly, and TrOCR
Base [18] - an open-source transformer sequence-to-sequence OCR that produced accurate results
- was nearly fifty times more costly to deploy on cloud CPUs than our budget. More scaleable
open-source OCR engines were noisy even when fine-tuned on newspaper annotations.
We met our accuracy and cost objectives with the EfficientOCR framework [3]. EfficientOCR uses
deep learning-based object detection methods to localize individual characters and/or words in an
image. Character/word recognition is modeled as a character/word-level image retrieval problem,
using a vision encoder contrastively trained on character/word crops, largely created through aug-
menting digital fonts. At inference time, character/word embeddings are decoded to text in parallel
by retrieving their nearest neighbor from an offline index of exemplar character or word embeddings,
created by rendering character/word images with a digital font. Distances are computed using cosine
similarity with a Facebook Artificial Intelligence Similarly Search (FAISS) backend [11].
5
Switching between character and word recognition is important. There are many terms that would
not appear in even a very large dictionary, as narrow newspaper columns imply that hyphenated
words at the end of lines are common.3 The texts also have a long-tailed distribution of proper
nouns and antiquated acronyms and words. Hence, at inference time, whenever a word crop is below
a tuned cosine similarity threshold of 0.82 from its nearest neighbor in the offline word embedding
index, we instead apply character-level EfficientOCR to individual character crops within the word.
The supplementary materials provide a detailed description of training and deployment.
Content Association: We associate headlines together (if spanning multiple boxes), associate them
with bylines (if present), and with the first article bounding box, using rule-based methods that
exploit the position of article and byline bounding boxes relative to headlines (see the Supplementary
Materials). Rule-based methods perform less well for articles spanning multiple columns or pages,
and language understanding is required. However, we find on a labeled sample that only around
3.8% of articles span multiple article bounding boxes, and only 0.2% of articles span multiple pages,
meaning there is little scope for gains from neural methods. (Articles spanning multiple columns
and pages become more common after the Chronicling America period, as the price of paper falls
and font size increases.) Since these cases are rare and our compute budget is limited, we do not
associate multiple article bounding boxes together for this release, but may do so in the future, using
the RoBERTa cross-encoder method developed in [29].
5
Pipeline Evaluation
Measurement: We use four carefully constructed datasets to evaluate the pipeline:
• Full page scans: Two student annotators labeled layout regions and hand-entered the texts
for 10 full page scans, resolving all discrepancies by hand. The set consists of 597 content
regions and 196,655 characters. It allows us to evaluate the end-to-end pipeline, which
requires transcribed full-page scans since layout analysis is applied at the page level. We
further use this sample for evaluating content association. It contains 214 headline-article
bounding box pairs.
• Transcribed day per decade sample: To evaluate line detection and OCR on highly di-
verse content, we hand-transcribe a randomly selected sample of 50 lines for each decade
between 1850-1920. During this period, printing and archival technology changes signif-
icantly. Examples of these textlines, with their accompanied EffOCR transcriptions, are
shown in the supplemental materials as Table 1.
• Transcriptions of randomly selected lines from Carlson et al. [3]: This sample is used
to report comparisons to other object detection frameworks, backbones, and OCR engines.
These comparisons are taken from [3], which develops EfficientOCR. This sample includes
64 textlines drawn randomly from random scans in the Chronicling America collection.
• Legibility sample: We evaluate legibility on a randomly selected (from legibility training
data), double labeled sample of 100 bounding boxes, 50 headlines and 50 articles. Tran-
scriptions are not included, as we cannot create character labels for illegible content.
We measure pipeline accuracy with the character error rate (CER), defined as the Levenshtein dis-
tance [16] between the end-to-end digitized content and the ground truth, divided by the length of
the ground truth. OCR is similarly evaluated by the character error rate on ground truth layout and
line annotations (and hence does not include transcriptions errors induced by errors in the layout
predictions). We also examine non-word rate, as it does not require costly-to-create labeled data
so can be evaluated on a much larger sample, though it is more difficult to interpret. To measure
3Our word dictionary consists of words rendered three times each: with all lowercase characters, all upper-
case characters (common in headlines), and capitalized. We select words by first taking the top 25,000 words
from a modern dictionary that ranks word frequency [5]. We remove 3,999 words that never appear in a sample
of all Chronicling America scans from one-day-per decade (1850s-1920s), OCR’ed with character Efficien-
tOCR. Inspection revealed that these were overwhelmingly words related to modern concepts like computing
and modern medicine. We then added the 500 words that most frequently appear in this sample but were not
frequent modern words - mostly consisting of terms from antiquated domains like traditional medicine - and
also added numbers, contractions, state and month abbreviations, and punctuation, for a total of 22,230 total
terms.
6
the quality of layout and line detection, we use mean average precision (mAP@50:95), as well as
decomposing what share of the overall character error rate is due to layout and line detection errors.
For full article association, we focus on confusability between legible and illegible scans. Finally,
we evaluate content association using F1.
Overall Pipeline Evaluation: The end-to-end CER is 0.051 (Table 2), showing the pipeline’s high
overall accuracy. Some of the errors - e.g. confusing commas and periods are particularly prevalent
- are straightforward to fix in post-processing. When we apply a lightweight spellchecker [5], the
CER falls to 0.044. Spellchecking produces a slight increase in CER in headlines, likely due to a
higher concentration of proper nouns.
(1)
(2)
(3)
(4)
Overall
Headlines
Articles
Ads
Mean Average Precision
63.48
88.64
91.31
78.4
Overall CER (Spellchecked)
.044
.092
.038
-
Overall CER
.051
.089
.049
-
CER from OCR
.043
.071
.039
-
CER from layout detection
.012
.018
.010
-
Article Association F1
97.0
-
-
-
Table 2: Pipeline evaluation on ten labeled scans. CER is the character error rate, decomposed
into errors from OCR and from layout detection. Article association F1 evaluates the association of
headlines with each other and the first article bounding box. Spellchecking is applied after EffOCR,
using [5].
Figure 5 plots the non-word rate at the scan level on a day-per-decade sample, where non-word
rate measures the share of terms not in a lengthy dictionary with 82,765 terms [5]. Even with a
perfect OCR, the non-word rate could be appreciable, due to hyphenated words at the end of rows,
acronyms, proper nouns, and antiquated terms. The American Stories distribution is concen-
trated well to the left of Chronicling America’s distribution, underscoring the quality of our texts.
Differences in the non-word rate between Chronicling America and American Stories are likely to
reflect both differences in OCR quality and differences in filtering content based on legibility and
content region type, as Chronicling America digitizes all the texts it can localize on the page.
Figure 5: Non-Word Rate Distributions of American Stories and Chronicling America.
Layout and Line Detection Evaluation: mAP, reported in Table 2, is high, particularly for the
classes of central interest such as headlines (88.64) and articles (91.31). Confusing ads for articles -
as they often look similar in this period - is relatively common. The ads that look like articles tend
to OCR well and have natural language texts, so these errors are also tolerable. The overwhelming
majority of content regions in the ten labeled scans are articles, headlines, and advertisements, as
photographs - a rarity in this period - do not appear. The mAP for line detection is 86.20.
We also decompose the overall CER into errors due to OCR and errors due to line and layout detec-
tion. When the layout model fails to detect text regions, misclassifies them as another category such
as ads that isn’t OCR’ed, or when line detection misses or crops lines, this increases the CER. The
CER due to layout and line detection errors is 0.012.
7
Legibility Classification Evaluation: We want to avoid classifying legible texts as illegible and vice
versa, with the borderline class existing to encompass the grey zone between these two categories.
In a random sample of labeled texts - containing 81 legible texts - none of the legible texts are
misclassified as illegible. Of 16 illegible texts, only one is misclassified as legible. To further
evaluate this, we ran all content regions from a one-day-per-decade sample through OCR. The non-
word rate is more than three times higher for illegibly classified content as compared to legibly
classified content, and more than twice as high for illegibly classified content as for borderline
content.
OCR Evaluation: Table 2 reports the CER from running OCR on ground truth layouts and lines.
It is 0.043. The supplementary materials provide a much more detailed analysis of OCR quality.
Evaluation on a day per decade sample shows that CER ranges from 8.9% (1850s) to 1.8% (1910s),
with the bulk of content concentrated in the later period where scans are less challenging. The sup-
plementary materials also document that EffOCR [3] best meets our accuracy and cost requirements,
by comparing to a variety of open-source and proprietary OCR engines.
Content Association Evaluation: We achieve an F1 of 97 for associating headlines with articles on
our labeled evaluation dataset. We associate all bylines correctly.
6
Applications
Language Modeling: American Stories provides a massive amount of text that can be used to
continue pre-training large transformer language models, helping a language model to develop a
better understanding of 19th and early 20th century English and greater world knowledge about the
past. Moreover, a retrieval augmented language model (e.g. [12]), combined with longer context
windows, could provide a valuable tool for retrieving and summarizing vast information, whether it
be perspectives on paradigm-shifting historical events or the minutiae of the daily lives of people’s
ancestors. American Stories also provides extensive content for studying semantic change.
Multimodal Classification: The layouts and texts in American Stories comprise a rich multi-
modal dataset, providing vast silver quality data that could be used for developing novel methods
for multimodal layout analysis or multimodal classification - e.g., with image-caption pairs.
Topic Classification: Topic classification of texts in historical newspapers is a common social sci-
ence application, with the literature overwhelmingly using keyword searches to measure topics
[9]. To evaluate how American Stories can facilitate topic classification, relative to the exist-
ing Chronicling America page-level OCR, we use neural and sparse methods to classify whether a
randomly selected set of content is about politics, a frequently covered topic. We use a RoBERTa
large [20] classifier, applied to articles in American Stories and chunks of Chronicling America
(the page OCR is significantly longer than the context window). The training data were randomly
sampled at the article level and contain 2418 articles. The development set contains 15 randomly
selected full scans (498 articles) and the test set contains 62 randomly selected scans (1473 articles).
We also consider keywords, using two different approaches for selecting these: keyword mining
on the training set and asking ChatGPT, with careful prompting. All methods are described in the
supplementary materials.
American Stories supports article level classification, whereas Chronicling America only sup-
ports page level classification. A page is a positive example in the ground truth if any of the articles
are on topic, and article or chunk predictions can be aggregated to page level predictions using the
same definition. Retrieval at the scan level tends to retrieve a lot of extraneous content, as typically
only part of the page contains articles about politics.
On structured article texts, neural methods outperform keyword methods by a wide margin (F1 of
83.6 versus 58.1). All methods perform better at the page level, as there is a much lower chance of
false negatives, with the best performance by a wide margin coming from applying neural methods
to the American Stories corpus.
Content Dissemination Networks: Reproduced content is of considerable interest to social scien-
tists [7], but detecting it can be challenging due to OCR noise and abridgement. We evaluate this
task on a full-day sample of labeled front pages from March 1, 1916, a random day that consists of
113 reproduced articles (the median article is reproduced twice) as well as 1,994 singleton articles.
8
Topic classification
Reproduced content
Neural
Sparse
Neural
Sparse
F1
Mining
GPT
ARI
Viral Texts
(1)
(2)
(3)
(4)
(5)
Article Level
American Stories
83.6
56.4
58.1
75.1
32.3
Page Level
American Stories
96.0
82.8
79.6
86.2
74.6
Chronicling America
83.3
83.7
79.6
-
71.4
Table 3: Comparing American Stories to Library of Congress’s Chronicling America.
To detect reproduced content at the article level with American Stories, we deploy the pre-trained
neural model from [28]. They contrastively tuned a Sentence BERT model [26, 32] on a large,
hand-annotated sample of paired reproduced articles from a later period. At inference time, article
representations are clustered using single linkage clustering to detect reproduced content. To make
the American Stories result comparable with Chronicling America, we amalgamate the predic-
tions to the page level. A page-pair is counted as positive if the pages have any article in common,
making the task easier.
For detecting reproduced content with the Chronicling America full page scans, where we lack the
article texts required for the neural method, we deploy the sparse methods from Viral Texts [30].
Viral Texts was designed specifically for detecting reproduced texts in Chronicling America’s noisy
page-level OCR by looking for overlapping n-gram spans. We also apply Viral texts to American
Stories at the article and page level. Table 3 reports the adjusted rand index (ARI) for these
specifications. The Viral Texts method gives slightly better results on American Stories, but the
real advantage of American Stories is that the article structure allows the use of a neural method,
which dominates the sparse method by nearly 12 percentage points at the page level.
News Story Clustering: The structured nature of American Stories allows for further article-
level clustering of content. As a demonstration of this, we show how articles can be grouped into
news stories, with different articles that are part of the same unfolding news story clustering together.
This prediction is not possible with the unstructured page content in Chronicling America.
Year
Biggest story
Year
Biggest story
1885
Death of General Grant
1903
Panama Canal Treaty
1886
Southwest Railroad Strike
1904
Russo-Japanese War
1887
Vatican supports Knights of Labor
1905
Russo-Japanese Peace Process
1888
Rail strikes
1906
Hepburn Railroad Rate Bill
1889
Samoan Crisis
1907
Mining accidents
1890
1893 World’s Fair planning
1908
Taft presidential victory
1891
New Orleans Lynchings
1909
Race to the North Pole
1892
Homestead Steel Strike
1910
Rail strikes
1893
World’s Fair, Chicago
1911
Canadian Reciprocity Bill
1894
Wilson–Gorman Tariff Act
1912
Republican National Convention (Taft v Roosevelt)
1895
British occupation of Corinto, Nicaragua
1913
Underwood-Simmons Tariff Act
1896
Bimetallism Movement
1914
World War I
1897
Coal Miners’ Strike
1915
World War I
1898
Cuban War of Independence
1916
Pancho Villa Expedition
1899
Philippine-American War
1917
World War I
1900
Anglo-Boer War
1918
World War I
1901
U.S. Steel Recognition Strike
1919
Treaty of Versailles
1902
Anthracite Coal Strike
1920
Rail strikes
Table 4: Largest news story in each year, 1885-1920.
To create these clusters, we fine tune a contrastive biencoder on modern news texts, scraped from
allsides.com, a website which amalgamates different representations of the same news story from
different news outlets. Full details of the data, model and training are given in the supplementary
materials. We ran this model over all de-duplicated front page articles from 1885-1920. We read
20 random articles in the largest cluster for each year and named the story which the articles in the
cluster refer to. Table 4 shows the largest news story cluster by year.
9
This application demonstrates one of the many ways that the structured article texts in American
Stories can be used to unlock new ways of studying historical and social questions.
In addition to these tasks, image-caption pairs from layout analysis could be used for training and
assessing image captioning models, visual question-answering models, cross-modal retrieval mod-
els, image retrieval models, and multi-modal understanding (e.g., representation learning) models.
American Stories could also be leveraged to substantially lower the costs of creating new bench-
mark datasets for other common ML tasks, e.g., image and text classification, image retrieval, and
named entity recognition.
7
Limitations and Recommended Usage
American Stories contains historical language, that reflects the semantics and cultural biases of
the time. This is a distinguishing feature, that is core to many potential applications. We do not
filter texts that use antiquated terms or that may be considered offensive, as this would invalidate
the use of the dataset for studying semantic change and historical contexts. At the same time,
this makes American Stories less suited for tasks that require texts that fully conform to current
cultural standards or semantic norms. For these reasons, we recommend against the use of American
Stories for training generative models. While the OCR is high quality, American Stories is
also not well-suited to tasks requiring fully clean texts. Rather, American Stories can be used
for a wide variety of applications, ranging from elucidating social science questions to training
a historically-oriented language model to exploring world and family history. It also provides a
modular pipeline that can be customized for other document collections and scaled cheaply, offering
a blueprint for liberating large-scale historical text corpora.
10
Acknowledgement
Funding was provided by the Harvard Data Science Initiative, Harvard Catalyst, the Ken Griffin
Harvard Economics Fund, and Microsoft Azure compute credits. We thank Anoushka Ashwin,
Domenick Clark Regina, Chloe Combes, Will Cox, Connor Fogal, Brevin Franklin, Prabhav Kamo-
jjhala, Zachary Lee, Roberto Lopez-Irrisarry, Elan Pelegri, Krishna Prasad Srinivasan, and Sarah
Strohecker for research assistance.
References
[1] ALI, A., TOUVRON, H., CARON, M., BOJANOWSKI, P., DOUZE, M., JOULIN, A., LAPTEV,
I., NEVEROVA, N., SYNNAEVE, G., VERBEEK, J., ET AL. Xcit: Cross-covariance image
transformers. Advances in neural information processing systems 34 (2021).
[2] CAI, Z., AND VASCONCELOS, N. Cascade r-cnn: Delving into high quality object detection.
Proceedings of the IEEE conference on computer vision and pattern recognition (2018), 6154–
6162.
[3] CARLSON, J., BRYAN, T., AND DELL, M. Efficient ocr for building a diverse digital history.
arXiv preprint arXiv:2304.02737 (2023).
[4] DOSOVITSKIY, A., BEYER, L., KOLESNIKOV, A., WEISSENBORN, D., ZHAI, X., UN-
TERTHINER, T., DEHGHANI, M., MINDERER, M., HEIGOLD, G., GELLY, S., ET AL. An
image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint
arXiv:2010.11929 (2020).
[5] GARBE, W. SymSpell, June 2012.
[6] GEBRU, T., MORGENSTERN, J., VECCHIONE, B., VAUGHAN, J. W., WALLACH, H., AU2,
H. D. I., AND CRAWFORD, K. Datasheets for datasets, 2021.
[7] GUARNERI, J. Newsprint Metropolis. University of Chicago Press, 2017.
[8] HADSELL, R., CHOPRA, S., AND LECUN, Y. Dimensionality reduction by learning an in-
variant mapping. In 2006 IEEE Computer Society Conference on Computer Vision and Pattern
Recognition (CVPR’06) (2006), vol. 2, IEEE, pp. 1735–1742.
[9] HANLON, W. W., AND BEACH, B. Historical newspaper data: A researcher’s guide and
toolkit, 2022.
[10] HOWARD, A., SANDLER, M., CHU, G., CHEN, L.-C., CHEN, B., TAN, M., WANG, W.,
ZHU, Y., PANG, R., VASUDEVAN, V., ET AL. Searching for mobilenetv3. Proceedings of the
IEEE/CVF international conference on computer vision (2019), 1314–1324.
[11] JOHNSON, J., DOUZE, M., AND JÉGOU, H. Billion-scale similarity search with gpus. IEEE
Transactions on Big Data 7, 3 (2019), 535–547.
[12] KHATTAB, O., SANTHANAM, K., LI, X. L., HALL, D., LIANG, P., POTTS, C., AND
ZAHARIA, M. Demonstrate-search-predict: Composing retrieval and language models for
knowledge-intensive nlp. arXiv preprint arXiv:2212.14024 (2022).
[13] KHOSLA, P., TETERWAK, P., WANG, C., SARNA, A., TIAN, Y., ISOLA, P., MASCHINOT,
A., LIU, C.,
AND KRISHNAN, D.
Supervised contrastive learning.
arXiv preprint
arXiv:2004.11362 (2020).
[14] KIRILLOV, A., MINTUN, E., RAVI, N., MAO, H., ROLLAND, C., GUSTAFSON, L., XIAO,
T., WHITEHEAD, S., BERG, A. C., LO, W.-Y., ET AL. Segment anything. arXiv preprint
arXiv:2304.02643 (2023).
[15] LEE, B. C. G., MEARS, J., JAKEWAY, E., FERRITER, M., ADAMS, C., YARASAVAGE, N.,
THOMAS, D., ZWAARD, K., AND WELD, D. S. The newspaper navigator dataset: extracting
headlines and visual content from 16 million historic newspaper pages in chronicling amer-
ica. In Proceedings of the 29th ACM International Conference on Information & Knowledge
Management (2020), pp. 3055–3062.
[16] LEVENSHTEIN, V. I., ET AL. Binary codes capable of correcting deletions, insertions, and
reversals. In Soviet physics doklady (1966), vol. 10, Soviet Union, pp. 707–710.
11
[17] LI, L., JAMIESON, K., DESALVO, G., ROSTAMIZADEH, A., AND TALWALKAR, A. Hyper-
band: A novel bandit-based approach to hyperparameter optimization, 2018.
[18] LI, M., LV, T., CUI, L., LU, Y., FLORENCIO, D., ZHANG, C., LI, Z., AND WEI, F.
Trocr: Transformer-based optical character recognition with pre-trained models. arXiv preprint
arXiv:2109.10282 (2021).
[19] LIBRARY OF CONGRESS. Chronicling America: Historic American Newspapers, 2022.
[20] LIU, Y., OTT, M., GOYAL, N., DU, J., JOSHI, M., CHEN, D., LEVY, O., LEWIS, M.,
ZETTLEMOYER, L., AND STOYANOV, V.
Roberta: A robustly optimized bert pretraining
approach. arXiv preprint arXiv:1907.11692 (2019).
[21] LIU, Z., LIN, Y., CAO, Y., HU, H., WEI, Y., ZHANG, Z., LIN, S., AND GUO, B.
Swin transformer: Hierarchical vision transformer using shifted windows.
arXiv preprint
arXiv:2103.14030 (2021).
[22] MUSGRAVE, K., BELONGIE, S., AND LIM, S.-N. Pytorch metric learning, 2020.
[23] OCKERBLOOM, J. M. Newspaper copyrights, notices, and renewals, 2019.
[24] OORD, A. V. D., LI, Y., AND VINYALS, O. Representation learning with contrastive predic-
tive coding. arXiv preprint arXiv:1807.03748 (2018).
[25] PASZKE, A., GROSS, S., MASSA, F., LERER, A., BRADBURY, J., CHANAN, G., KILLEEN,
T., LIN, Z., GIMELSHEIN, N., ANTIGA, L., DESMAISON, A., KOPF, A., YANG, E., DE-
VITO, Z., RAISON, M., TEJANI, A., CHILAMKURTHY, S., STEINER, B., FANG, L., BAI,
J., AND CHINTALA, S. PyTorch: An Imperative Style, High-Performance Deep Learning
Library.
In Advances in Neural Information Processing Systems 32 (2019), H. Wallach,
H. Larochelle, A. Beygelzimer, F. d’Alché Buc, E. Fox, and R. Garnett, Eds., Curran As-
sociates, Inc., pp. 8024–8035.
[26] REIMERS, N., AND GUREVYCH, I. Sentence-bert: Sentence embeddings using siamese bert-
networks. arXiv preprint arXiv:1908.10084 (2019).
[27] SHEN, Z., ZHAO, J., DELL, M., YU, Y., AND LI, W. Olala: Object-level active learning for
efficient document layout annotation. arXiv preprint arXiv:2010.01762 (2020).
[28] SILCOCK, E., D’AMICO-WONG, L., YANG, J., AND DELL, M. Noise-robust de-duplication
at scale. International Conference on Learning Representations (2023).
[29] SILCOCK, E., AND DELL, M. A massive scale semantic similarity dataset of historical english,
2023.
[30] SMITH, D. A., CORDELL, R., AND MULLEN, A. Computational methods for uncovering
reprinted texts in antebellum newspapers. American Literary History 27, 3 (2015), E1–E15.
[31] SONG, G., LIU, Y., AND WANG, X. Revisiting the sibling head in object detector. Pro-
ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2020),
11563–11572.
[32] SONG, K., TAN, X., QIN, T., LU, J., AND LIU, T.-Y. Mpnet: Masked and permuted pre-
training for language understanding. Advances in Neural Information Processing Systems 33
(2020), 16857–16867.
[33] TRAAG, V. A., WALTMAN, L., AND VAN ECK, N. J. From Louvain to Leiden: guaranteeing
well-connected communities. Scientific Reports 9, 1 (Mar. 2019), 5233. Number: 1 Publisher:
Nature Publishing Group.
[34] ULTALYTICS.
Yolo v8 github repository.
https://github.com/ultralytics/
ultralytics, 2023.
[35] WIGHTMAN,
R.
Pytorch
image
models.
https://github.com/rwightman/
pytorch-image-models, 2019.
12
Supplementary Materials
Model Details
American Stories deploys a modular pipeline to digitize historical newspapers. This section
provides details for each component of the pipeline.
Layout Detection
To detect articles, headlines, ads, and other content regions in a newspaper scan, we deploy YOLOv8
(Medium) [34], initialized from the officially released YOLOv8m pretrained checkpoint. We train
for 100 epochs on 2,202 labeled newspaper scans with 48,874 total layout objects, using default
YOLOv8 hyperparameters except: {imgsz:
1280, iou:
0.2, max_det:
500}. The final
model achieved a 0.91 mAP50:95 on article bounding boxes and a 0.84 mAP50:95 on headline
bounding boxes. We decreased the confidence threshold to 0.1 to increase article and headline
recall.
Legibility Classification
Text image bounding boxes are classified as legible, borderline, or illegible, using MobileNetV3
(Small) [10] initialized from the PyTorch Image Models (""timm"") [35] pretrained checkpoint. We
train for 50 epochs on 979 labeled article, headline, and image caption examples. 678 of the labeled
examples were legible, 192 borderline, and 109 illegible. The model was trained with weighted
Cross Entropy Loss: weights [2.0, 1.0, 1.0] for legible, borderline, and illegible classes, respectively.
The following specifications were used: {resolution:
256, learning rate:
2e-3}. The
learning rate was multiplied by 0.1 every twenty epochs.
Text Line Detection
Line bounding boxes are detected using YOLOv8 (Small) [34] initialized from the official YOLOv8s
pretrained checkpoint. We train first for 100 epochs on 4000 synthetically generated articles, with
default YOLOv8 hyperparameters. After synthetic training, the model was additionally trained
for 50 epochs on 373 hand-annotated article and headline crops, with default YOLOv8 hyperpa-
rameters except for the following: {resolution:
640, initial learning rate:
0.02,
final learning rate:
0.002}.
Word and Character Localization
Words and characters are detected using YOLOv8 (Small) [34], initialized from the official
YOLOv8s pretrained checkpoint. We train first for 100 epochs on 8000 synthetically generated
textlines with default YOLOv8 hyperparameters. After synthetic training, the model was addi-
tionally trained for 100 epochs on 684 hand-annotated text line images, with default hyperpa-
rameters except for the following: {resolution:
640, initial learning rate:
0.02,
final learning rate:
0.001}. Each hand-annotated line image was replicated three times
with random augmentations along three axes: random rotation between -1°and 1°, random image
brightness shift from -30 to 30%, and randomly applied blur at the 0-4px level. On average, text line
examples contained 4.3 words and 23.6 characters.
Word Recognition
Building upon the architecture in [3], we train word recognition as a nearest neighbor image retrieval
problem. As described in the main text, the training dataset for the model consists of digital renders
of words created using 43 fonts, silver quality data from the target dataset created by applying the
EffOCR-C (Small) model from [3] to a random sample of days, and a small number of randomly
selected hand labeled word crops. We limited the number of crops with model-generated labels to
20 - so each word can have 0-20 silver-quality crops depending upon its frequency of occurrence in
our random sample. This limit is binding for common words, e.g., ""the"".
13
The recognizer is trained using the Supervised Contrastive (“SupCon"") loss function [13], a gener-
alization of the InfoNCE loss [24] that allows for multiple positive and negative pairs for a given
anchor. In particular, we work with the “outside"" SupCon loss formulation
Lsup
out =
X
i∈I
Lsup
out ,i =
X
i∈I
−1
|P(i)|
X
p∈P (i)
log
exp (zi · zp/τ)
P
a∈A(i) exp (zi · za/τ)
as implemented in PyTorch Metric Learning [22], where τ is a temperature parameter, i indexes a
sample in a “multiviewed"" batch (in this case multiple fonts/augmentations of the same word), P(i)
is the set of indices of all positives in the multiviewed batch that are distinct from i, A(i) is the set
of all indices excluding i, and z is an embedding of a sample in the batch [13].
To create training batches for the recognizer, we use a custom m per class sampling algorithm
without replacement, adapted from the PyTorch Metric Learning repository [22]. The m word
variants for each class (word) are drawn from both target documents and augmented digital fonts.
We select m = 4 and the batch size is 1024, meaning 4 styles of each of 256 different words appear
in each batch. For training without hard negatives, we define an epoch as letting the model see each
word (case-sensitive) exactly m = 4 times. Sampling for each class occurs without replacement
until all variants are exhausted.
In order to converge faster with limited compute, we also implement offline-hard negative mining,
batching similar negatives and their corresponding positive anchors together - thus making the con-
trasts between the positive and negative pairs within a batch especially informative. To create hard
negative sets, we render each word using a reference font (Noto-Serif Regular) and embed it to
create a reference index. We find k = 8 nearest neighbors for each word using this index and the
model trained without hard negatives, which yields sets of 8 words that have a similar appearance
when rendered with the reference font. We use only the reference font to create these sets because
using crops corresponding to all 43 fonts for each word is computationally costly and creates more
hard negative sets than we can use in training. We also use each word crop from the target dataset
(both silver quality annotations generated with model predictions and gold quality human-annotated
predictions) to create hard negative sets. Hence, the total number of hard-negative sets equals the
number of words in our dictionary (generated with the reference font) plus the number of word crops
from the newspaper data in the training set.
Each hard negative set contains 8 words, with m = 4 views per word, which means we can fit 32
randomly sampled hard negative sets within each batch. An epoch is defined as seeing each hard
negative set once. Since the number of synthetic views of an image is much larger than the number
of target newspaper crops, whenever newspaper crops are available we force the m views of a word
to contain an equal number of synthetic and target crops.
We use a MobileNetV3 (Small) encoder pre-trained on ImageNet1k sourced from the timm [35]
library, more specifically, the model mobilenetv3_small_050. We use 0.1 as the temperature for
SupCon loss and AdamW as the optimizer with Pytorch [25] defaults for all parameters other than
weight decay (5e-4) and learning rate. We used Cosine Annealing with Warm Restarts as the learn-
ing rate scheduler with a maximum learning rate of 2e −3, a minimum learning rate of 0, time
to first restart (T0) as the number of batches in an epoch, and restart factor, Tmult of 2 using the
implementation provided in Pytorch.
While fonts and newspaper crops for each word act as an augmentation on the skeleton of the word,
we also add more image-level transformations to improve generalization. These include Affine
transformation (only slight translation and scaling allowed), Random Color Jitter, Random Auto-
contrast, Random Gaussian Blurring, Random Grayscale, Random Solarize, Random Sharpness,
Random Invert, Random Equalize, Random Posterize and Randomly erasing a small number of pix-
els of the image. Additionally, we pad the word to make the image square while preserving the
aspect ratio of the word render. We do not use common augmentations like Random Cropping or
Center Cropping, to avoid destroying too much information.
The model trained without hard negatives was trained for 50 epochs and with hard negatives, it was
trained for 40 epochs. For selecting the best checkpoint, we use 1-CER (OCR Character Error Rate)
as the validation metric on the validation set from [3]. We chose the model that performed best in
terms of CER when detecting only words on the validation set. This means that if a word is outside
14
of our dictionary, it is forcefully matched to the nearest neighbor in the dictionary. The best model
achieved a CER of 4.9% with word-only recognition.
At inference time, words are recognized by retrieving their nearest neighbor from the offline em-
bedding index created with the reference font, using a Facebook Artificial Intelligence Similarity
Search backend [11]. The code to train the model and generate training data, as well as the model
checkpoints, are made available on our GitHub repo.4
Character Recognition
When the nearest neighbor to an embedded word crop in the offline word embedding index is below
a cosine similarity threshold of 0.82, we default to character-level recognition. We use the EffOCR-
C (Small) model that is developed in [3] for character recognition.
Content Association
This step associates headlines, bylines, and article bounding boxes. We use rule-based methods
that exploit the position of article and byline bounding boxes relative to headlines. Specifically, we
associated a headline bounding box with an article bounding box if they overlap vertically by more
than 1% of the page width, and the bottom of the headline is no greater than 10% of the page height
above the top of the article, and no greater than 2% of the page height below the top of the article.
If multiple article bounding boxes satisfy these rules for a given headline, then we take the highest.
The same rules are used to associate bylines.
Pipeline Evaluation
As discussed in the main paper, we evaluate the data processing pipeline in an end-to-end fashion,
as well as evaluating individual sections, particularly OCR. Here we provide additional details on
those evaluations.
OCR Evaluation
Processing 20 million scans required a cost-effective OCR solution, and downstream tasks require
highly accurate OCR. We compared custom, open-source, and commercial OCR solutions by accu-
racy, speed, and cost to determine our final architecture. Character Error Rate measurements were
made on two separate validation datasets:
• CER [3] Error rate on a dataset of 64 randomly selected Chronicling America textlines,
sampled from the entire collection. Textlines were randomly sampled from random scans,
then cropped and transcribed. This dataset and its construction is described in detail in [3].
• CER Day-Per-Decade Error rate on a sample of 225 total textlines, sampled from all scans
in the Chronicling America collection published on March 1st of years ending in ""6,"" from
1856-1926. Unlike the above sample from [3], this sample is balanced across the time pe-
riods the predominate the Chronicling America collection. 25 textlines were sampled ran-
domly from random pages published on each of the days. A selection of textlines from this
collection, along with their EffOCR transcriptions, are shown in Figure S-1. This dataset is
designed to be much more challenging than the first, weighting older, harder to read scans
more heavily despite their relative scarcity in the Chronicling America collection.
Comparisons are listed in Table S-1. Training procedures for EffOCR-Word are described above.
See [3] for training procedures, initialization checkpoints, and additional details on training and
evaluating comparison models.
Of the options we examined, EffOCR-Word (Small) was the clear best option, providing a Character
Error Rate under 5% on the hardest evaluation set while offering the cheapest rate per line on an
Microsoft Azure Fs4v2 instance.
4https://github.com/dell-research-harvard/AmericanStories.
15
Model/Engine
Seq2Seq?
Transformer?
Pretraining
Parameters
CER [3]
CER Day-Per-Decade
Lines Per Second
Cost Per 10K Lines
EffOCR-C (Base)
×
×
from scratch
112.5 M
0.023
0.062
0.27
$1.77
EffOCR-C (Small)
×
×
from scratch
9.3 M
0.028
0.080
7.28
$0.06
EffOCR-T (Base)
×
✓
from scratch
101.8 M
0.022
0.059
0.17
$2.80
EffOCR-Word (Small)
×
×
from scratch
10.6 M
0.015
0.043
11.60
$0.04
Google Cloud Vision OCR
?
?
off-the-shelf
?
0.005
0.019
?
$15.00
Tesseract OCR (Best)
✓
×
off-the-shelf
1.4 M
0.106
0.170
2.43
$0.19
EasyOCR CRNN
✓
×
off-the-shelf
3.8 M
0.170
0.274
10.75
$0.04
fine-tuned
0.036
0.157
from scratch
0.131
-
PaddleOCR SVTR
×
×
off-the-shelf
11 M
0.304
7.36
$0.06
fine-tuned
0.103
from scratch
0.104
TrOCR (Base)
✓
✓
off-the-shelf
334 M
0.015
0.038
0.23
$2.02
fine-tuned
0.013
0.027
from scratch
0.809
-
TrOCR (Small)
✓
✓
off-the-shelf
62 M
0.039
0.121
0.53
$0.90
fine-tuned
0.075
0.091
from scratch
0.773
-
Table S-1: Chronicling America Results and Comparisons. This table reports the performance
of different OCR architectures, off-the-shelf (without fine-tuning on target data), fine-tuned on the
Chronicling America training set from initialization on the best public, pre-trained OCR checkpoint,
and pre-trained from scratch on a consistent, standardized set of synthetic text lines and then fine-
tuned on the Chronicling America training set. “?” indicates that the field is unknown due to the
proprietary nature of the architecture. Inference speeds are based on an extrapolation from inference
speeds measured for EffOCR-Word (Small) to digitize the entire Chronicling America collection
using cloud compute.
Figure S-1: Examples of textlines in the Day-Per-Decade evaluation set. Image crops are shown
on the left, with their corresponding EffOCR transcriptions (using the final model set used in the
American Stories processing pipeline) on the right.
Legibility
Legibility classification was tested on a set of 100 image crops (50 articles and 50 headlines) sampled
randomly from the 1,094-image legibility training set. All legibility images were double-entered.
Since the goal was to be cautious in classifying images as illegible, where annotators disagreed the
more legible of the two labels was used.
Annotators were instructed to use the following definitions for legibility labeling:
16
• Legible: Greater than 95% of words in an image readable without context from adjacent
words.
• Borderline: Between 50 and 95% of words in an image readable without context from
adjacent words.
• Illegible: Less than 50% of words in an image readable without context from adjacent
words.
Inter-annotator agreement was 91% between the two annotators. A sample of annotator discrepan-
cies is presented in Figure S-2
(a) Legible/Borderline
(b) Borderline/Illegible
(c) Legible/Borderline
(d) Borderline/Illegible
Figure S-2: Examples of Inter-Annotator disagreement in legibility labeling. Images are labeled
""Class 1""/""Class 2"" to show the two labeled classes. In cases of disagreement, the more legible of
the two labels was used for training and evaluation.
Applications
The paper presents multiple applications that can be facilitated by the American Stories dataset.
This section provides details for each application given.
Topic Classification
To evaluate topic classification, we focused on the topic of politics. As we evaluate at both the
scan and article level, for development and test sets we sampled full scans (all articles on the same
scan). We took a random sample of up to three front page scans from each election year in our
sample. These scans were double-labelled by student research assistants and incongruences were
discussed and resolved. We place 20% of these (15 scans, 498 articles) into a development set and
the remaining 62 scans (1473 articles) into the test set. Training data was sampled at the article level,
rather than the scan level, from the same population of front page articles in election years. Training
17
data was single-labelled by the same research assistants. A sample were double-labelled to check
for consistency and they agreed on the labelling in 93% of cases.
To evaluate neural methods, we finetune RoBERTa large [20] on the training set for ten epochs, with
a batch size of 16, and a learning rate of 2e-6.
For evaluation of sparse methods, we use two different methods to select keywords. First, we use
the test and evaluation sets to mine keywords. We use TF-IDF to pull words and bigrams that are
most commonly found in train set articles about politics, but not found in off-topic articles. We take
the top 40 words and bigrams and then sequentially pick those that maximise F1 on the evaluation
set, until there is no remaining keyword that increases F1. Using this technique, the mined keywords
were: vote, election, republican, committee, united, party, president, congress.
Second, we prompted Chat-GPT to produce keywords. We used the prompt: “You have a large
number of 19th century US newspaper articles. You wish to classify these on whether they are
about politics or not. The only way that you can do this is by checking whether they match any
of a list of keywords or keyphrases. You can search for these keywords or phrases in each article,
and if it matches any of them it will be classified as about politics, but if it does not match any, it
will not. Please provide a list of keywords and phrases that will correctly classify as many of the
articles that are about politics as possible, with a minimal number of off-topic articles classified as
on topic” and received the following keywords: President, Congress, Election, Senator, Representa-
tive, Governor, Democratic Party, Whig Party, Republican Party, Suffrage, Legislation, Lawmakers,
Government, Policy, Bill, Campaign, Debate, Vote, Political Convention, Public Office, Political
Reform, Impeachment.
Using these lists of keywords, we consider any article to be predicted as on topic if it contains any
of these keywords. We do not take case into account.
The structured data in American Stories allows us to classify at the article level, a significant
advantage. However, for comparison with Chronicling America, we also evaluate the same methods
at the scan level. A scan is counted as on topic if any article on that page is on topic. For neural
methods on Chronicling America, we chunk the text into passages of 256 tokens, as the page OCR
is significantly longer than the context window.
Content Dissemination Networks
To detect reproduced content, we also compare neural and sparse methods. In this case, the neural
methods are only possible with American Stories, whereas sparse methods are possible with both
American Stories and Chronicling America.
We evaluate these methods on all front pages from March 1, 1916, a randomly selected day. A
single day is chosen because reproduced content tends to be published around the same time, so
a single day will have a far higher number of reproduced articles than a random selection of front
pages across time. On this day, American Stories contains 114 scans, with 2,354 articles. 1,994
of these were not reproduced, while 360 were reproduced. These 360 comprise 113 distinct articles,
with the median reproduced article being reprinted 2 times.
For the neural method, we use the pre-trained neural model from [28]. This is a contrastively-trained
bi-encoder finetuned from the MPNet Sentence BERT model [26, 32] on a large, hand-annotated
sample of pairs of reproduced historical newspaper articles. [28] find this biencoder is marginally
improved by running a cross-encoder over the outputs, but we do not reproduce these results as
the cross-encoder is computationally costly for a small gain in performance. They also find that
this fine-tuned biencoder model outperforms more generic semantic textual similarity models (eg.
[26] by up to 20 percentage points. Thus the model is chosen to maximise accuracy, within a
reasonable compute budget. At inference time, article representations are clustered using single
linkage clustering to detect reproduced content, and spurious links are pruned using community
detection. We use the same distance threshold as in [28].
To enable a comparison to Chronicling America, where the content is only available at a page level,
we amalgamate these results by page. A page-pair is counted as positive if they have any article in
common. Nonetheless, the page-level evaluation of the neural method requires the data to be split
into articles. It cannot be run over the unstructured text in Chronicling America.
18
Therefore for detecting reproduced content in Chronicling America, where we do not have article
texts, we deploy the sparse methods from Viral Texts [30]. Viral Texts was designed specifically for
detecting reproduced texts in Chronicling America’s noisy page-level OCR by looking for overlap-
ping n-gram spans. To compare this method between American Stories and Chronicling Amer-
ica, we also run it over the articles in American Stories and then amalgamate these results at the
page level.
Finally, we deploy the locality-sensitive hashing (LSH) specification from [28] to evaluate the per-
formance of sparse methods on American Stories, using the same parameters. In particular we
do this because the Viral Texts method is not designed to be run at the article level. As expected,
we find that LSH performs better than Viral Texts at the article level, but both methods perform
significantly worse than the neural methods, in line with the findings of [28].
Story Clustering
Finally, we demonstrate that the content in American Stories can be clustered into news stories,
following the same story between newspapers and across time. To create clusters of stories, we use
a contrastively-trained biencoder.
We train this biencoder using data from allsides.com, a modern news website which shows how
the same story is written by different newspapers. Articles on allsides.com are truncated. Groups
of articles on the same story on allsides.com were used to create positive pairs. For negatives,
we used the fact that each article is labelled with various tags, and also that we know which news
source each article came from. For each article we take the article from the same news source, with
different topic tags, that had the largest cosine similarity, using the biencoder before finetuning. In
the cases where there were no articles with different tags from the same news source, we use articles
from a news source which is lifted with the same political leaning. The specification that an article
has different tags is important for making sure that articles are actual negatives.
Overall this gave 26,194 unique articles, with 18,382 positive pairs and 18,445 negative pairs. We
featurized the data as “headline [sep] article” and we finetuned the biencoder from [28] as in ex-
periments we found that this outperformed finetuning an MPNet Sentence BERT model [26, 32]
directly. We optimised hyperparameters using hyperband [17]. The best model was trained fro 9
epochs, on a single GPU, with a batch size of 32, a warm up percent of 0.392. We optimised online
contrastive loss [8], with and a loss margin of 0.497.
At inference time, we cluster using single-linkage clustering, with a cosine similarity threshold of
0.92. We control cluster size using leiden community detection [33]. We deduplicate the content
using the method outlined in the section above. We take all articles that are reprinted at least five
times, and run same story clustering over a year at a time.
Dataset details
Dataset URL
The dataset can be found at https://huggingface.co/datasets/dell-research-harvard/
AmericanStories.
This dataset has structured metadata following schema.org, and is readily discoverable.5
Training
labels
for
the
individual
models
detailed
in
this
paper
are
also
available,
and
can
be
found
at
https://huggingface.co/datasets/dell-research-harvard/
AmericanStoriesTraining.
DOI
The DOI for this dataset is: 10.57967/hf/0757.
5See
https://search.google.com/test/rich-results/result?id=esZkoGgfOsLlnkrvwx9nSQ
for full metadata.
19
License
The dataset has a Creative Commons CC-BY license.
Dataset usage
The dataset is hosted on Hugging Face. Each year in the dataset is divided into a distinct file. The
dataset can be easily downloaded using the datasets library:
As the dataset is very large, files for specific years can be downloaded by specifying them or users
can download all data for all years. Additionally, we provide two options for the output type. The
first contains data at the article level, with features like newspaper name, page number, edition, date,
headline, byline, and article text. The second contains data at the scan level. It contains information
including the scan metadata; all detected content regions like articles, photographs, and adverts;
legibility information, and bounding box coordinates.
from datasets import load_dataset
#
Download data for the year 1809 at the associated article level (Default)
dataset = load_dataset(""dell-research-harvard/AmericanStories"",
""subset_years"",
year_list=[""1809"", ""1810""]
)
# Download and process data for all years at the article level
dataset = load_dataset(""dell-research-harvard/AmericanStories"",
""all_years""
)
# Download and process data for 1809 at the scan level
dataset = load_dataset(""dell-research-harvard/AmericanStories"",
""subset_years_content_regions"",
year_list=[""1809""]
)
# Download ad process data for all years at the scan level
dataset = load_dataset(""dell-research-harvard/AmericanStories"",
""all_years_content_regions"")
Users can find more information on accessing the dataset using the dataset card on Hugging Face.
Author statement
We bear all responsibility in case of violation of rights.
Maintenance Plan
We have chosen to host the dataset on huggingface as this ensures long-term access and preservation
of the dataset.
Dataset documentation and intended uses
We follow the datasheets for datasets template [6]. Additionally, we have completed the dataset card
on Hugging Face which can be accessed using the link to the dataset on Hugging Face hub 6
Reproducibility
Moreover, we have included our responses to The Machine Learning Reproducibility Checklist as
outlined in table S-2.
6https://huggingface.co/datasets/dell-research-harvard/AmericanStories
20
Motivation
For what purpose was the dataset created? Was there a specific task in mind? Was
there a specific gap that needed to be filled? Please provide a description.
The dataset was created to provide researchers with a large, high-quality corpus of structured and
transcribed newspaper article texts from historical local American newspapers. These texts provide a
massive repository of information about topics ranging from political polarization to the construction
of national and cultural identities to the minutiae of the daily lives of people’s ancestors. The dataset
will be useful to a wide variety of researchers including historians, other social scientists, and NLP
practitioners.
Who created this dataset (e.g., which team, research group) and on behalf of which
entity (e.g., company, institution, organization)?
The dataset was created by a team of researchers at Harvard University, New York University,
Northwestern Kellogg School, MIT, and Princeton University, led by Melissa Dell.
Who funded the creation of the dataset? If there is an associated grant, please provide
the name of the grantor and the grant name and number.
Funding was provided by the Harvard Data Science Initiative, compute credits that Microsoft Azure
provided to the Harvard Data Science Initiative, Harvard Catalyst, and the Harvard Economics De-
partment Ken Griffin Fund for Research on Development Economics and Political Economy.
Any other comments?
None.
Composition
What do the instances that comprise the dataset represent (e.g., documents, pho-
tos, people, countries)?
Are there multiple types of instances (e.g., movies, users,
and ratings; people and interactions between them; nodes and edges)? Please provide a
description.
Dataset instances are detected content regions in newspaper page scans from the Library of
Congress’s Chronicling America collection. In the cases of article, headline, image caption, and
byline regions, a text transcription is included if the page is written in English.
How many instances are there in total (of each type, if appropriate)?
Version 0.1.0 of American Stories contains 402 million content regions, 294 million of which
include a text transcription.
Does the dataset contain all possible instances or is it a sample (not necessarily
random) of instances from a larger set?
If the dataset is a sample, then what is the
larger set? Is the sample representative of the larger set (e.g., geographic coverage)? If
so, please describe how this representativeness was validated/verified. If it is not repre-
sentative of the larger set, please describe why not (e.g., to cover a more diverse range of
instances, because instances were withheld or unavailable).
The Version 1.0 of the dataset will contain all possible instances. Version 0.1.0 contains approxi-
mately 40% of all instances as of 6/7/23.
What data does each instance consist of? “Raw” data (e.g., unprocessed text or
images) or features? In either case, please provide a description.
Each instance includes: a unique content region id, its detected class (ARTICLE, HEADLINE, CAP-
TION, BYLINE, IMAGE, AD, TABLE, HEADER, PAGE NUMBER, or MASTHEAD), and the pixel co-
ordinates of the newspaper page bounding box for the identified region. If the content region is
classified as ARTICLE, HEADLINE, CAPTION, or BYLINE, the transcribed text is also provided.
21
Is there a label or target associated with each instance? If so, please provide a de-
scription.
Content regions are labeled by their model predicted class. Text article transcriptions have no label.
Is any information missing from individual instances? If so, please provide a descrip-
tion, explaining why this information is missing (e.g. because it was unavailable). This does
not include intentionally removed information but might include, e.g., redacted text.
No.
Are relationships between individual instances made explicit (e.g., users’ movie rat-
ings, social network links)? If so, please describe how these relationships are made
explicit.
All articles and other content regions include metadata that can definitively determine relationships
to other content regions. For example, two articles with the same lccn (newspaper identifier), edition,
and page number are from the same newspaper page scan.
Are there recommended data splits (e.g., training, development/validation, testing)?
If so, please provide a description of these splits, explaining the rationale behind them.
There are no recommended splits.
Are there any errors, sources of noise, or redundancies in the dataset? If so, please
provide a description.
Layout detection, OCR, and article association all introduce noise.
Is the dataset self-contained, or does it link to or otherwise rely on external resources
(e.g., websites, tweets, other datasets)? If it links to or relies on external resources, a)
are there guarantees that they will exist, and remain constant, over time; b) are there official
archival versions of the complete dataset (i.e., including the external resources as they ex-
isted at the time the dataset was created); c) are there any restrictions (e.g., licenses, fees)
associated with any of the external resources that might apply to a future user? Please
provide descriptions of all external resources and any restrictions associated with them, as
well as links or other access points, as appropriate.
The provided text data are self-contained. Some applications could require downloading the original
scans, which are at https://chroniclingamerica.loc.gov/. All scans are freely available and
in the public domain.
Does the dataset contain data that might be considered confidential (e.g., data that
is protected by legal privilege or by doctor-patient confidentiality, data that includes
the content of individuals non-public communications)? If so, please provide a de-
scription.
The dataset is drawn entirely from image scans in the public domain that are freely available for
download from the Library of Congress’s website.
Does the dataset contain data that, if viewed directly, might be offensive, insulting,
threatening, or might otherwise cause anxiety? If so, please describe why.
Texts in the dataset reflect attitudes and values of a large, diverse group of newspaper editors and
writers in the period they were written (1790-1960) and include content that may be considered
offenseive for a variety of reasons.
Does the dataset relate to people? If not, you may skip the remaining questions in this
section.
Yes. The dataset contains news about people.
22
Does the dataset identify any subpopulations (e.g., by age, gender)? If so, please de-
scribe how these subpopulations are identified and provide a description of their respective
distributions within the dataset.
It may be possible to infer certain characters about individuals covered in the news historically from
the data. The authors of the dataset do not identify any subpopulations.
Is it possible to identify individuals (i.e., one or more natural persons), either directly
or indirectly (i.e., in combination with other data) from the dataset? If so, please
describe how.
If an individual appeared in the news during this period, then texts may contain their name and
other information. In some cases, it may be possible to link individuals to information on ancestry
websites or Wikipedia (in the case of prominent historical figures). We do not attempt to do so in
this paper.
Does the dataset contain data that might be considered sensitive in any way (e.g.,
data that reveals racial or ethnic origins, sexual orientations, religious beliefs, politi-
cal opinions or union memberships, or locations; financial or health data; biometric
or genetic data; forms of government identification, such as social security num-
bers; criminal history)? If so, please provide a description.
The data are drawn entirely from newspaper scans in the public domain.
Any other comments?
None.
Collection Process
How was the data associated with each instance acquired? Was the data directly
observable (e.g., raw text, movie ratings), reported by subjects (e.g., survey responses), or
indirectly inferred/derived from other data (e.g., part-of-speech tags, model-based guesses
for age or language)? If data was reported by subjects or indirectly inferred/derived from
other data, was the data validated/verified? If so, please describe how.
The pipeline used to create layouts and article transcriptions from page images is described in detail
within the paper. The dataset described here is the output of that pipeline.
What mechanisms or procedures were used to collect the data (e.g., hardware ap-
paratus or sensor, manual human curation, software program, software API)? How
were these mechanisms or procedures validated?
The data extraction pipeline is described and evaluated in the main paper text.
If the dataset is a sample from a larger set, what was the sampling strategy (e.g.,
deterministic, probabilistic with specific sampling probabilities)?
Release 1.0 will include everything in the Chronicling America scan collection.
Who was involved in the data collection process (e.g., students, crowdworkers,
contractors) and how were they compensated (e.g., how much were crowdworkers
paid)?
A large group of professors, research assistants, and students collaborated on all aspects of the data
collection process, including labeling training data, training and validating models, data engineering,
and conceptual design. All were compensated for their work, according to the regulations of Harvard
University and New York University.
Over what timeframe was the data collected? Does this timeframe match the creation
timeframe of the data associated with the instances (e.g., recent crawl of old news
23
articles)? If not, please describe the timeframe in which the data associated with the
instances was created.
Scans from Chronicling America were processed between 6/1/23 and 6/7/23. The data associated
with the instances were created between 1780 and 1963, when they were published in local newspa-
pers.
Were any ethical review processes conducted (e.g., by an institutional review
board)? If so, please provide a description of these review processes, including the out-
comes, as well as a link or other access point to any supporting documentation.
The data are entirely in the public domain and hence do not fall under the jurisdiction of university
institutional review boards.
Does the dataset relate to people? If not, you may skip the remaining questions in this
section.
Yes, the articles in the dataset talk about people.
Did you collect the data from the individuals in question directly, or obtain it via third
parties or other sources (e.g., websites)?
We collected this data from a third party, the Library of Congress, which has verified that all data
are in the public domain.
Were the individuals in question notified about the data collection?
If so, please
describe (or show with screenshots or other information) how notice was provided, and
provide a link or other access point to, or otherwise reproduce, the exact language of the
notification itself.
The data are in the public domain and cover many millions of individuals, most of whom are
deceased.
Did the individuals in question consent to the collection and use of their data? If
so, please describe (or show with screenshots or other information) how consent was re-
quested and provided, and provide a link or other access point to, or otherwise reproduce,
the exact language to which the individuals consented.
The data are in the public domain and cover many millions of individuals, most of whom are
deceased.
If consent was obtained, were the consenting individuals provided with a mecha-
nism to revoke their consent in the future or for certain uses? If so, please provide a
description, as well as a link or other access point to the mechanism (if appropriate).
Not applicable.
Has an analysis of the potential impact of the dataset and its use on data subjects
(e.g., a data protection impact analysis) been conducted?
If so, please provide a
description of this analysis, including the outcomes, as well as a link or other access point
to any supporting documentation.
No such analysis has been conducted.
Any other comments?
None.
Preprocessing/cleaning/labeling
Was any preprocessing/cleaning/labeling of the data done (e.g., discretization or
bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of
24
instances, processing of missing values)? If so, please provide a description. If not,
you may skip the remainder of the questions in this section.
No preprocessing was conducted.
Uses
Has the dataset been used for any tasks already? If so, please provide a description.
Example uses are detailed in the main text.
Is there a repository that links to any or all papers or systems that use the dataset?
If so, please provide a link or other access point.
No such repository currently exists.
What (other) tasks could the dataset be used for?
There are a large number of potential uses in the social sciences, digital humanities, and deep
learning research, discussed in more detail in the main text.
Is there anything about the composition of the dataset or the way it was collected and
preprocessed/cleaned/labeled that might impact future uses? For example, is there
anything that a future user might need to know to avoid uses that could result in unfair
treatment of individuals or groups (e.g., stereotyping, quality of service issues) or other
undesirable harms (e.g., financial harms, legal risks) If so, please provide a description. Is
there anything a future user could do to mitigate these undesirable harms?
This dataset contains unfiltered content composed by newspaper editors, columnists, and other
sources. It reflects their biases and any factual errors that they made.
Are there tasks for which the dataset should not be used? If so, please provide a
description.
We would urge caution in using the data to train generative language models - without additional
filtering - as it contains content that many would consider toxic.
Any other comments?
None.
Distribution
Will the dataset be distributed to third parties outside of the entity (e.g., company,
institution, organization) on behalf of which the dataset was created? If so, please
provide a description.
Yes. The dataset is available for public use.
How will the dataset will be distributed (e.g., tarball on website, API, GitHub) Does
the dataset have a digital object identifier (DOI)?
The dataset is available via HuggingFace.
Download and instructions are at https:
//huggingface.co/datasets/dell-research-harvard/AmericanStories.
The dataset’s
DOI is: https://doi.org/10.57967/hf/0757
When will the dataset be distributed?
The dataset is currently available.
Will the dataset be distributed under a copyright or other intellectual property (IP)
license, and/or under applicable terms of use (ToU)? If so, please describe this license
25
and/or ToU, and provide a link or other access point to, or otherwise reproduce, any relevant
licensing terms or ToU, as well as any fees associated with these restrictions.
The dataset is distributed under a Creative Commons CC-BY license. The terms of this license can
be viewed at https://creativecommons.org/licenses/by/2.0/
Have any third parties imposed IP-based or other restrictions on the data associated
with the instances? If so, please describe these restrictions, and provide a link or other
access point to, or otherwise reproduce, any relevant licensing terms, as well as any fees
associated with these restrictions.
There are no third party IP-based or other restrictions on the data.
Do any export controls or other regulatory restrictions apply to the dataset or to
individual instances? If so, please describe these restrictions, and provide a link or other
access point to, or otherwise reproduce, any supporting documentation.
No export controls or other regulatory restrictions apply to the dataset or to individual instances.
Any other comments?
None.
Maintenance
Who will be supporting/hosting/maintaining the dataset?
HuggingFace will continue to host the dataset. The authors will provide support, updates, and
maintenance.
How can the owner/curator/manager of the dataset be contacted (e.g., email ad-
dress)?
Melissa Dell can be contacted via email at melissadell@fas.harvard.edu
Is there an erratum? If so, please provide a link or other access point.
There is no erratum.
Will the dataset be updated (e.g., to correct labeling errors, add new instances, delete
instances)? If so, please describe how often, by whom, and how updates will be commu-
nicated to users (e.g., mailing list, GitHub)?
The dataset will continue to be updated as new scans are processed. New versions will be added to
HuggingFace. Anyone can subscribe to notifications about the dataset via HuggingFace.
If the dataset relates to people, are there applicable limits on the retention of the data
associated with the instances (e.g., were individuals in question told that their data
would be retained for a fixed period of time and then deleted)? If so, please describe
these limits and explain how they will be enforced.
All data are in the public domain.
Will older versions of the dataset continue to be supported/hosted/maintained? If so,
please describe how. If not, please describe how its obsolescence will be communicated
to users.
Older versions of the dataset will still be visable via the HuggingFace repo.
If others want to extend/augment/build on/contribute to the dataset, is there a mech-
anism for them to do so? If so, please provide a description. Will these contributions
be validated/verified? If so, please describe how. If not, why not? Is there a process
26
for communicating/distributing these contributions to other users? If so, please provide a
description.
The dataset is privately created and maintained. There is no current plan to allow open source
contributions.
Any other comments?
None.
27
Table S-2: Reproducibility checklist
Item
Response
Comment
For all models and algorithms presented, check if you include:
A clear description of the mathematical set-
ting,
algorithm, and/or model.
Yes
A clear explanation of any assumptions.
Yes
An analysis of the complexity
(time, space, sample size) of any algorithm.
NA
Complexity can depend upon
application-specific architecture
and methods. We are using
transformer-based models within
our
framework and we have reported
the time profile and other related
details
For any theoretical claim, check if you include:
A clear statement of the claim.
Yes
A complete proof of the claim.
Yes
For all datasets used, check if you include:
The relevant statistics, such
as number of examples
Yes
The details of train / validation / test splits
Yes
An explanation of any data that
were excluded, and all pre-processing step.
Yes
A link to a downloadable version
of the dataset or simulation environment
Yes
Link to Hugging Face Hub repo
provided
For new data collected, a complete
description of the data collection process,
such as instructions to annotators
and methods for quality control.
Yes
For all shared code related to this work, check if you include:
Specification of dependencies.
Yes
Training code.
Yes
Evaluation codes
Yes
(Pre-)trained model(s).
Yes
Available on HuggingFace
README file includes table of results
accompanied by precise
command to run to produce those results
Yes
For all reported experimental results, check if you include:
The range of hyper-parameters considered,
method to select the best hyper-parameter
configuration, and specification of all
hyper-parameters used to generate results
Yes
The exact number of training and evaluation
runs.
Yes
A clear definition of the specific
measure or statistics used to report results.
Yes
Continued on next page
28
Table S-2: Reproducibility checklist (Continued)
A description of results with
central tendency (e.g. mean) variation (e.g.
error bars).
NA
The average runtime for each result,
or estimated energy cost.
Yes
Both training and inference times
have been reported
A description of the computing infrastructure
used
Yes
29
"
