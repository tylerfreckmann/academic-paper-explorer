{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "This notebook explores two aspects of the data:\n",
    "- The formatting of raw text in the papers\n",
    "- The number of tokens in the papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.read_csv('papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20286, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Bit-Serial Neural Networks</td>\n",
       "      <td>573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>Connectivity Versus Entropy</td>\n",
       "      <td>1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>The Hopfield Model with Multi-Level Neurons</td>\n",
       "      <td>278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>How Neural Nets Work</td>\n",
       "      <td>442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>Spatial Organization of Neural Networks: A Pro...</td>\n",
       "      <td>740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                               name  \\\n",
       "0  1987                         Bit-Serial Neural Networks   \n",
       "1  1987                        Connectivity Versus Entropy   \n",
       "2  1987        The Hopfield Model with Multi-Level Neurons   \n",
       "3  1987                               How Neural Nets Work   \n",
       "4  1987  Spatial Organization of Neural Networks: A Pro...   \n",
       "\n",
       "                                                text  \n",
       "0  573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...  \n",
       "1  1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...  \n",
       "2  278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...  \n",
       "3  442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...  \n",
       "4  740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20281</th>\n",
       "      <td>2023</td>\n",
       "      <td>Optimal testing using combined test statistics...</td>\n",
       "      <td>Optimal testing using combined test statistics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20282</th>\n",
       "      <td>2023</td>\n",
       "      <td>Regret-Optimal Model-Free Reinforcement Learni...</td>\n",
       "      <td>Regret-Optimal Model-Free Reinforcement Learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20283</th>\n",
       "      <td>2023</td>\n",
       "      <td>Convolutional State Space Models for Long-Rang...</td>\n",
       "      <td>Convolutional State Space Models for\\nLong-Ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20284</th>\n",
       "      <td>2023</td>\n",
       "      <td>CRoSS: Diffusion Model Makes Controllable, Rob...</td>\n",
       "      <td>CRoSS: Diffusion Model Makes\\nControllable, Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20285</th>\n",
       "      <td>2023</td>\n",
       "      <td>American Stories: A Large-Scale Structured Tex...</td>\n",
       "      <td>American Stories: A Large-Scale Structured Tex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year                                               name  \\\n",
       "20281  2023  Optimal testing using combined test statistics...   \n",
       "20282  2023  Regret-Optimal Model-Free Reinforcement Learni...   \n",
       "20283  2023  Convolutional State Space Models for Long-Rang...   \n",
       "20284  2023  CRoSS: Diffusion Model Makes Controllable, Rob...   \n",
       "20285  2023  American Stories: A Large-Scale Structured Tex...   \n",
       "\n",
       "                                                    text  \n",
       "20281  Optimal testing using combined test statistics...  \n",
       "20282  Regret-Optimal Model-Free Reinforcement Learni...  \n",
       "20283  Convolutional State Space Models for\\nLong-Ran...  \n",
       "20284  CRoSS: Diffusion Model Makes\\nControllable, Ro...  \n",
       "20285  American Stories: A Large-Scale Structured Tex...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Formatting of Papers in Plaintext\n",
    "\n",
    "Papers from 1987-2019 were downloaded as plaintext directly from the NeurIPS conference website. Papers from 2020 onward were downloaded as PDFs and then converted to plaintext using PyMuPDF. This may have resulted in some formatting differences. Let's take a look at the plaintext of a few papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDF-Converted Papers\n",
    "\n",
    "Let's take a look at the last paper in the dataset - one from 2023. This paper is representative of papers that were converted from PDFs. The PDF for this paper can be viewed [here](https://papers.nips.cc/paper_files/paper/2023/file/ffeb860479ccae44d84c0de32acd693d-Paper-Datasets_and_Benchmarks.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = papers.loc[len(papers)-1, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first just take a look at the general format of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Stories: A Large-Scale Structured Text\n",
      "Dataset of Historical U.S. Newspapers\n",
      "Melissa Dell1,2∗, Jacob Carlson1, Tom Bryan1, Emily Silcock1, Abhishek Arora1, Zejiang Shen3,\n",
      "Luca D’Amico-Wong1, Quan Le4, Pablo Querubin2,5, Leander Heldring6\n",
      "1Harvard University; Cambridge, MA, USA.\n",
      "2National Bureau of Economic Research; Cambridge, MA, USA.\n",
      "3Massachusetts Institute of Technology; Cambridge, MA, USA.\n",
      "4Princeton University; Princeton, NJ, USA.\n",
      "5New York University; New York, NY, USA.\n",
      "6Kellogg School of Management, Northwestern University, Evanston, IL, USA.\n",
      "∗Corresponding author: melissadell@fas.harvard.edu.\n",
      "Abstract\n",
      "Existing full text datasets of U.S. public domain newspapers do not recognize the\n",
      "often complex layouts of newspaper scans, and as a result the digitized content\n",
      "scrambles texts from articles, headlines, captions, advertisements, and other lay-\n",
      "out regions. OCR quality can also be low. This study develops a novel, deep learn-\n",
      "ing pipeline for extracting full article text\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the paper comes across pretty well with simple newlines in between sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images\n",
    "\n",
    "Let's take a look at how images were converted from the PDF. Using the PDF linked [here](https://papers.nips.cc/paper_files/paper/2023/file/ffeb860479ccae44d84c0de32acd693d-Paper-Datasets_and_Benchmarks.pdf), we can find a segment of the PDF that contains an image and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "into the public domain.\n",
      "(a) Scans Across Time\n",
      "(b) Scans Across Space\n",
      "Figure 1: Scans in the Chronicling America database across time and space.\n",
      "We sho\n"
     ]
    }
   ],
   "source": [
    "img_index = text.find('into the public domain')\n",
    "print(text[img_index:img_index+150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the image is completely skipped during the PDF conversion process. However, the image titles are present, and those are probably more relevant for the RAG. So we likely don't need to adjust the PDF-conversion for the images. Instead, we'll just have to make sure we display the PDF itself so users can see the images when exploring the results from the RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tables\n",
    "\n",
    "Now let's take a look at how tables were converted from the PDFs. Using the PDF linked [here](https://papers.nips.cc/paper_files/paper/2023/file/ffeb860479ccae44d84c0de32acd693d-Paper-Datasets_and_Benchmarks.pdf), we can find a segment of the PDF that contains a table and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "billion tokens.\n",
      "(1)\n",
      "(2)\n",
      "(3)\n",
      "(4)\n",
      "(5)\n",
      "(6)\n",
      "(7)\n",
      "(8)\n",
      "(9)\n",
      "Total\n",
      "Text Bounding Boxes\n",
      "Other Bounding Boxes\n",
      "Boxes\n",
      "Articles\n",
      "Headlines\n",
      "Captions\n",
      "Bylines\n",
      "Images\n",
      "Ads\n",
      "Tables\n",
      "Mastheads\n",
      "Legible\n",
      "-\n",
      "335M\n",
      "368M\n",
      "9.7M\n",
      "14.7M\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Illegible\n",
      "-\n",
      "26M\n",
      "27M\n",
      "0.9M\n",
      "2.5M\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Borderline\n",
      "-\n",
      "77M\n",
      "22M\n",
      "1.3M\n",
      "1.2M\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Total\n",
      "1.14B\n",
      "438M\n",
      "417M\n",
      "11.9M\n",
      "18.4M\n",
      "9.1M\n",
      "221M\n",
      "16.3M\n",
      "4.9M\n",
      "Table 1: American Stories dataset statistics.\n",
      "American Stories provides the classes and coordinates for all content regions. Using the provided\n",
      "metadata, it is \n"
     ]
    }
   ],
   "source": [
    "table_index = text.find('billion tokens')\n",
    "print(text[table_index:table_index+500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the tabular data is converted into text, however it is not formatted tabularly. This could potentially be useful to the RAG as-is, and if we display the PDF (so users can view the rendered table), then we might not need to adjust the PDF conversion process for tables. That being said, converting the tables so they contain more formatting and hence retain a bit more symantic information during the embedding process might provide better results for the RAG. We'll have to try both strategies out to see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equations\n",
    "\n",
    "Now let's take a look at how equations were converted from the PDFs. Using the PDF linked [here](https://papers.nips.cc/paper_files/paper/2023/file/ffeb860479ccae44d84c0de32acd693d-Paper-Datasets_and_Benchmarks.pdf), we can find a segment of the PDF that contains an equation and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formulation\n",
      "Lsup\n",
      "out =\n",
      "X\n",
      "i∈I\n",
      "Lsup\n",
      "out ,i =\n",
      "X\n",
      "i∈I\n",
      "−1\n",
      "|P(i)|\n",
      "X\n",
      "p∈P (i)\n",
      "log\n",
      "exp (zi · zp/τ)\n",
      "P\n",
      "a∈A(i) exp (zi · za/τ)\n",
      "as implemented in PyTorch Metric Learning [22], where τ is a temperature parameter, i \n"
     ]
    }
   ],
   "source": [
    "eq_index = text.find('formulation')\n",
    "print(text[eq_index:eq_index+200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to tables, equations were converted into text, but do not retain their formatting. This could be useful to the RAG as-is, but might be *more* useful if the equations are converted with some consistent formatting. In any case, we'll want to display the PDF itself as well so users can see the rendered equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papers with directly-provided plaintext\n",
    "\n",
    "The plaintext for papers pre-2020 is available directly from the NeurIPS website. Let's investigate how those papers' images, tables, and equations compare to the PDF-converted ones.\n",
    "\n",
    "Let's take a look at the very first paper in the dataset, one from 1987. This paper can be found [here](https://papers.nips.cc/paper_files/paper/1987/file/02e74f10e0327ad868d138f2b4fdd6f0-Paper.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = papers.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at how the paper comes across."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573 \n",
      "\n",
      "BIT - SERIAL NEURAL  NETWORKS \n",
      "\n",
      "Alan F.  Murray,  Anthony V . W.  Smith  and Zoe F.  Butler. \n",
      "\n",
      "Department of Electrical Engineering,  University of Edinburgh, \n",
      "\n",
      "The King's Buildings, Mayfield Road,  Edinburgh, \n",
      "\n",
      "Scotland,  EH93JL. \n",
      "\n",
      "ABSTRACT \n",
      "\n",
      "A  bit  - serial  VLSI  neural  network  is  described  from  an  initial  architecture  for  a \n",
      "synapse array through to silicon layout and board design.  The issues surrounding bit \n",
      "- serial  computation,  and  analog/digital  arithmetic  are  discussed  and  the  parallel \n",
      "development  of  a  hybrid  analog/digital  neural  network  is  outlined.  Learning  and \n",
      "recall  capabilities  are  reported  for  the  bit  - serial  network  along  with  a  projected \n",
      "specification  for  a  64  - neuron,  bit  - serial  board  operating  at 20 MHz.  This tech(cid:173)\n",
      "nique  is  extended  to  a  256  (2562  synapses)  network  with  an  update  time  of 3ms, \n",
      "using  a  \"paging\"  technique  to  time  - multiplex  calculations  through  the  synapse\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this paper includes page numbers (573), and has a bit more newline formatting for sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equations\n",
    "\n",
    "Now let's take a look at how equations are formatted with the directly-provided papers. Using the PDF linked [here](https://papers.nips.cc/paper_files/paper/1987/file/02e74f10e0327ad868d138f2b4fdd6f0-Paper.pdf), we can find a segment of the PDF that contains an equation and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The neural output state at time t, V[,  is related to x[ by \n",
      "\n",
      "V[  = F (xf) \n",
      "\n",
      "(1) \n",
      "\n",
      "The  activation  function  is  a  \"squashing\"  function  ensuring  \n"
     ]
    }
   ],
   "source": [
    "eq_index = text.find('The neural output')\n",
    "print(text[eq_index:eq_index+150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the equations from the directly-provided text has a similar structure to the PDF-converted text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images\n",
    "\n",
    "Now let's take a look at how images were converted for the directly-provided text. Using the PDF linked [here](https://papers.nips.cc/paper_files/paper/1987/file/02e74f10e0327ad868d138f2b4fdd6f0-Paper.pdf), we can find a segment of the PDF that contains an image and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream networks. \n",
      "\n",
      "Synapse \n",
      "\n",
      "States { Vj  } \n",
      "\n",
      "Figure 1. Generic architecture for  a  network of n to\n"
     ]
    }
   ],
   "source": [
    "img_index = text.find('stream networks')\n",
    "print(text[img_index: img_index+100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the PDF-generated text, the direclty-provided text simply omits the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tables\n",
    "\n",
    "We need to find another paper that has a table in it. We'll go with [this one](https://papers.nips.cc/paper_files/paper/2004/file/026a39ae63343c68b5223a95f3e17616-Paper.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_with_table = papers[papers['name'] == 'PAC-Bayes Learning of Conjunctions and Classification of Gene-Expression Data'].reset_index()\n",
    "text = paper_with_table.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find and print the table by referencing the PDF [here](https://papers.nips.cc/paper_files/paper/2004/file/026a39ae63343c68b5223a95f3e17616-Paper.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on the training set.\n",
      "\n",
      "\fData Set\n",
      "\n",
      "Name\n",
      "Colon\n",
      "B MD\n",
      "C MD\n",
      "ALL/AML\n",
      "\n",
      "#exs\n",
      "62\n",
      "34\n",
      "60\n",
      "72\n",
      "\n",
      "SVM SVM+gs\n",
      "size\n",
      "errs\n",
      "256\n",
      "12\n",
      "32\n",
      "12\n",
      "1024\n",
      "29\n",
      "18\n",
      "64\n",
      "\n",
      "errs\n",
      "11\n",
      "6\n",
      "21\n",
      "10\n",
      "\n",
      "ratio\n",
      "0.42\n",
      "0.10\n",
      "0.077\n",
      "0.002\n",
      "\n",
      "Soft Greedy\n",
      "\n",
      "size G-errs B-errs Bound\n",
      "1\n",
      "1\n",
      "3\n",
      "2\n",
      "\n",
      "9\n",
      "6\n",
      "22\n",
      "17\n",
      "\n",
      "18\n",
      "20\n",
      "40\n",
      "38\n",
      "\n",
      "12\n",
      "6\n",
      "24\n",
      "19\n",
      "\n",
      "Table 1: DNA micro-array data sets and results.\n",
      "\n",
      "For each algorithm, the “errs” columns of Table 1 contain the 5-fold CV error\n",
      "expresse\n"
     ]
    }
   ],
   "source": [
    "table_index = text.find('error on the training set')\n",
    "print(text[table_index:table_index+400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the PDF-generated papers, the directly-provided papers contain tabular data but it is not formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations regarding text formatting\n",
    "\n",
    "Given that there may be critical information in the images, tables, and equations of these papers, it might be worthwhile exploring the use of PyMuPDF's Markdown formatter - which converts PDFs into Markdown. This might aid in preserving some of the information. It also might make it easier to parse the papers into chunks - if we decide that would improve the RAG system.\n",
    "\n",
    "Also, considering that the plaintext of papers pre-2020 (provided directly from the NeurIPS website) and papers provided after 2020 (converted from PDFs using PyMuPDF) have different formatting - it might be worthwhile to consider using the same PDF conversion process for all the papers to try to make formatting slightly more standardized. Although, the underlying paper PDFs might not have consistent formatting from year to year.\n",
    "\n",
    "Of note, is that all of these would be preprocessing steps - which only happen once. Which provides us a bit more leeway as far as scalability is concerned. (I.e., adding more preprocessing steps make take longer for the preprocessing pipeline to run, but since it's only run once or on a batch basis, that might be worth it if it makes the RAG responses better)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of tokens\n",
    "\n",
    "This section explores how many tokens are in each raw, unprocessed paper - so that we can determine, at a minimum, how much chunking we'll need to do before we can fit the papers into OpenAI's embedding models (which have a max input of 8,191 tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.encoding_for_model('text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_tokens(text):\n",
    "    try:\n",
    "        n_tokens = len(tokenizer.encode(text))\n",
    "    except:\n",
    "        n_tokens = np.nan\n",
    "    return n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers['n_tokens'] = papers.text.apply(n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Bit-Serial Neural Networks</td>\n",
       "      <td>573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...</td>\n",
       "      <td>9136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>Connectivity Versus Entropy</td>\n",
       "      <td>1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...</td>\n",
       "      <td>5220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>The Hopfield Model with Multi-Level Neurons</td>\n",
       "      <td>278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...</td>\n",
       "      <td>4445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>How Neural Nets Work</td>\n",
       "      <td>442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...</td>\n",
       "      <td>11220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>Spatial Organization of Neural Networks: A Pro...</td>\n",
       "      <td>740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...</td>\n",
       "      <td>8575.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                               name  \\\n",
       "0  1987                         Bit-Serial Neural Networks   \n",
       "1  1987                        Connectivity Versus Entropy   \n",
       "2  1987        The Hopfield Model with Multi-Level Neurons   \n",
       "3  1987                               How Neural Nets Work   \n",
       "4  1987  Spatial Organization of Neural Networks: A Pro...   \n",
       "\n",
       "                                                text  n_tokens  \n",
       "0  573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...    9136.0  \n",
       "1  1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...    5220.0  \n",
       "2  278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...    4445.0  \n",
       "3  442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...   11220.0  \n",
       "4  740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...    8575.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also drop any rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year        0\n",
       "name        0\n",
       "text        3\n",
       "n_tokens    9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year        0\n",
       "name        0\n",
       "text        0\n",
       "n_tokens    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.dropna(inplace=True)\n",
    "papers.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     20277.000000\n",
       "mean      10168.549835\n",
       "std        6816.756597\n",
       "min           1.000000\n",
       "25%        6374.000000\n",
       "50%        9823.000000\n",
       "75%       12609.000000\n",
       "max      299550.000000\n",
       "Name: n_tokens, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.n_tokens.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are plenty of papers whose `n_tokens` is larger than the max input for the OpenAI embedding models (8,191 tokens). We'll definitely have to chunk these down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers.to_csv('papers_with_n_tokens.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academic-paper-explorer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
