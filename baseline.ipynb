{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survey Existing Research and Reproduce Available Solutions\n",
    "\n",
    "[Here](https://docs.google.com/document/d/1m6uXRaL1lH2Z0_-un1YRI107AuSMUeoYCemiAFAVfFU/edit?usp=sharing) is a brief Google doc surveying existing solutions. Below is a reproduction of one existing solution - [OpenAI's tutorial on creating a question answering system](https://platform.openai.com/docs/tutorials/web-qa-embeddings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline RAG Model\n",
    "\n",
    "This notebook implements a baseline RAG model - based [OpenAI's tutorial on creating a question answering system](https://platform.openai.com/docs/tutorials/web-qa-embeddings).\n",
    "\n",
    "It uses the raw plaintext generated from `paper_scraper.py` and a naive chunking strategy that simply splits the papers if they are longer than OpenAI's embedding model max input (~8,000 tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Bit-Serial Neural Networks</td>\n",
       "      <td>573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...</td>\n",
       "      <td>9136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>Connectivity Versus Entropy</td>\n",
       "      <td>1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...</td>\n",
       "      <td>5220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>The Hopfield Model with Multi-Level Neurons</td>\n",
       "      <td>278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...</td>\n",
       "      <td>4445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>How Neural Nets Work</td>\n",
       "      <td>442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...</td>\n",
       "      <td>11220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>Spatial Organization of Neural Networks: A Pro...</td>\n",
       "      <td>740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...</td>\n",
       "      <td>8575.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                               name  \\\n",
       "0  1987                         Bit-Serial Neural Networks   \n",
       "1  1987                        Connectivity Versus Entropy   \n",
       "2  1987        The Hopfield Model with Multi-Level Neurons   \n",
       "3  1987                               How Neural Nets Work   \n",
       "4  1987  Spatial Organization of Neural Networks: A Pro...   \n",
       "\n",
       "                                                text  n_tokens  \n",
       "0  573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...    9136.0  \n",
       "1  1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...    5220.0  \n",
       "2  278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...    4445.0  \n",
       "3  442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...   11220.0  \n",
       "4  740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...    8575.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_n_tokens = pd.read_csv('papers_with_n_tokens.csv')\n",
    "papers_with_n_tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "\n",
    "First, let's chunk the papers down so they will all fit in OpenAI's embedding model max input (~8,000 tokens).\n",
    "\n",
    "This function is adapted from [OpenAI's tutorial](https://platform.openai.com/docs/tutorials/web-qa-embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split a row into chunks of a maximum number of tokens\n",
    "def split_row(row, tokenizer, max_tokens):\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'\\.\\s+', row['text'])\n",
    "\n",
    "    # Get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenizer.encode(' ' + sentence)) for sentence in sentences]\n",
    "\n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, tokens in zip(sentences, n_tokens):\n",
    "\n",
    "        # If the number of tokens so far plus the number of tokens in the current sentence is greater\n",
    "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + tokens > max_tokens:\n",
    "            chunks.append('. '.join(chunk) + '.')\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        # If the number of tokens in the current sentence is greater than the max number of\n",
    "        # tokens, go to the next sentence\n",
    "        if tokens > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += tokens + 1\n",
    "    \n",
    "    # Append the last chunk\n",
    "    chunks.append('. '.join(chunk) + '.')\n",
    "\n",
    "    # Loop through the chunks and create new rows out of them (copying the data of the non-text columns)\n",
    "    new_rows = []\n",
    "    for chunk in chunks:\n",
    "        new_row = row.copy()\n",
    "        new_row['text'] = chunk\n",
    "        new_row['n_tokens'] = len(tokenizer.encode(new_row['text']))\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "    return new_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply split_into_many against all the rows of a DataFrame and return a new DataFrame with the new chunks\n",
    "def chunk_df(df, tokenizer, max_tokens = 8000):\n",
    "    split_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        split_rows.extend(split_row(row, tokenizer, max_tokens))\n",
    "\n",
    "    # Create a new DataFrame from the split rows\n",
    "    return pd.DataFrame(split_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Bit-Serial Neural Networks</td>\n",
       "      <td>573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...</td>\n",
       "      <td>7959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Bit-Serial Neural Networks</td>\n",
       "      <td>Graf,  and  J. S. Denker,  \"Microelectronic  I...</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>Connectivity Versus Entropy</td>\n",
       "      <td>1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...</td>\n",
       "      <td>5116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>The Hopfield Model with Multi-Level Neurons</td>\n",
       "      <td>278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...</td>\n",
       "      <td>4337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>How Neural Nets Work</td>\n",
       "      <td>442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...</td>\n",
       "      <td>7942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>How Neural Nets Work</td>\n",
       "      <td>One  never  needs  more  than  two  layers,  o...</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>Spatial Organization of Neural Networks: A Pro...</td>\n",
       "      <td>740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...</td>\n",
       "      <td>7980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>Spatial Organization of Neural Networks: A Pro...</td>\n",
       "      <td>Weisbuch,  \"Random \\n\\nBoolean  Networks\",  Cy...</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1987</td>\n",
       "      <td>A Neural-Network Solution to the Concentrator ...</td>\n",
       "      <td>775 \\n\\nA  NEURAL-NETWORK  SOLUTION TO  THE  C...</td>\n",
       "      <td>5343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1987</td>\n",
       "      <td>LEARNING BY STATE RECURRENCE DETECTION</td>\n",
       "      <td>642 \\n\\nLEARNING BY ST ATE RECURRENCE DETECfIO...</td>\n",
       "      <td>6030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                               name  \\\n",
       "0  1987                         Bit-Serial Neural Networks   \n",
       "0  1987                         Bit-Serial Neural Networks   \n",
       "1  1987                        Connectivity Versus Entropy   \n",
       "2  1987        The Hopfield Model with Multi-Level Neurons   \n",
       "3  1987                               How Neural Nets Work   \n",
       "3  1987                               How Neural Nets Work   \n",
       "4  1987  Spatial Organization of Neural Networks: A Pro...   \n",
       "4  1987  Spatial Organization of Neural Networks: A Pro...   \n",
       "5  1987  A Neural-Network Solution to the Concentrator ...   \n",
       "6  1987             LEARNING BY STATE RECURRENCE DETECTION   \n",
       "\n",
       "                                                text  n_tokens  \n",
       "0  573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...      7959  \n",
       "0  Graf,  and  J. S. Denker,  \"Microelectronic  I...       892  \n",
       "1  1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...      5116  \n",
       "2  278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...      4337  \n",
       "3  442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...      7942  \n",
       "3  One  never  needs  more  than  two  layers,  o...      2967  \n",
       "4  740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...      7980  \n",
       "4  Weisbuch,  \"Random \\n\\nBoolean  Networks\",  Cy...       380  \n",
       "5  775 \\n\\nA  NEURAL-NETWORK  SOLUTION TO  THE  C...      5343  \n",
       "6  642 \\n\\nLEARNING BY ST ATE RECURRENCE DETECfIO...      6030  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tiktoken.encoding_for_model('text-embedding-3-small')\n",
    "chunked_papers = chunk_df(papers_with_n_tokens, tokenizer)\n",
    "chunked_papers.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36198.000000\n",
       "mean      5589.083264\n",
       "std       2574.888267\n",
       "min          1.000000\n",
       "25%       3366.000000\n",
       "50%       6630.000000\n",
       "75%       7924.000000\n",
       "max       8001.000000\n",
       "Name: n_tokens, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_papers.n_tokens.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The papers have now been naively chunked so that each chunk (or row of the dataset) is below the max number of tokens that the OpenAI embeddings API accepts (8,191 tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n",
    "Because embedding ~36,000 documents takes a long time, this notebook just loads the embeddings from a saved file. Here is the code that was used to generate the embeddings:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   try:\n",
    "      embedding = client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "   except:\n",
    "      embedding = None\n",
    "   return embedding\n",
    "\n",
    "chunked_papers['embedding'] = chunked_papers.text.apply(lambda x: get_embedding(x))\n",
    "chunked_papers.to_csv('papers_with_embeddings.csv', index=False, header=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Bit-Serial Neural Networks</td>\n",
       "      <td>573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...</td>\n",
       "      <td>7959</td>\n",
       "      <td>[0.007057549431920052, 0.022557897493243217, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>Bit-Serial Neural Networks</td>\n",
       "      <td>Graf,  and  J. S. Denker,  \"Microelectronic  I...</td>\n",
       "      <td>892</td>\n",
       "      <td>[-0.015091345645487309, -0.006406506057828665,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>Connectivity Versus Entropy</td>\n",
       "      <td>1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...</td>\n",
       "      <td>5116</td>\n",
       "      <td>[0.014461712911725044, -0.022812657058238983, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>The Hopfield Model with Multi-Level Neurons</td>\n",
       "      <td>278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...</td>\n",
       "      <td>4337</td>\n",
       "      <td>[0.017370466142892838, -0.003854247974231839, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>How Neural Nets Work</td>\n",
       "      <td>442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...</td>\n",
       "      <td>7942</td>\n",
       "      <td>[0.006703744176775217, -0.002929536160081625, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                         name  \\\n",
       "0  1987                   Bit-Serial Neural Networks   \n",
       "1  1987                   Bit-Serial Neural Networks   \n",
       "2  1987                  Connectivity Versus Entropy   \n",
       "3  1987  The Hopfield Model with Multi-Level Neurons   \n",
       "4  1987                         How Neural Nets Work   \n",
       "\n",
       "                                                text  n_tokens  \\\n",
       "0  573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...      7959   \n",
       "1  Graf,  and  J. S. Denker,  \"Microelectronic  I...       892   \n",
       "2  1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...      5116   \n",
       "3  278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...      4337   \n",
       "4  442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...      7942   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.007057549431920052, 0.022557897493243217, -...  \n",
       "1  [-0.015091345645487309, -0.006406506057828665,...  \n",
       "2  [0.014461712911725044, -0.022812657058238983, ...  \n",
       "3  [0.017370466142892838, -0.003854247974231839, ...  \n",
       "4  [0.006703744176775217, -0.002929536160081625, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_embeddings = pd.read_csv('papers_with_embeddings.csv')\n",
    "papers_with_embeddings['embedding'] = papers_with_embeddings['embedding'].apply(eval).apply(np.array)\n",
    "papers_with_embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving relevant information\n",
    "\n",
    "Now we'll write a function to retrieve paper chunks that are most relevant to the user's question. We'll use the _cosine similarity_ metric on the embedding of the user's question and the embeddings of all the papers.\n",
    "\n",
    "We'll include as many papers as we can that fit into OpenAI's `gpt-4o-mini`'s context window (128,000 tokens) - with some buffer to account for padding between the papers and the user's question - bringing it down to ~127,000 tokens.\n",
    "\n",
    "This function is adapted from [OpenAI's tutorial](https://platform.openai.com/docs/tutorials/web-qa-embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(client, df, question, max_len=127000):\n",
    "    \"\"\"\n",
    "    Return a DataFrame of the chunks whose tokens fit within the `max_len` provided.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the embeddings for the question\n",
    "    q_embedding = client.embeddings.create(input=question, model='text-embedding-3-small').data[0].embedding\n",
    "\n",
    "    # Get the distances from the embeddings\n",
    "    df['distance'] = df.embedding.apply(lambda x: cosine_similarity(q_embedding, x))\n",
    "\n",
    "    # Sort by distance\n",
    "    df.sort_values('distance', ascending=False, inplace=True)\n",
    "\n",
    "    # Account for padding at the end of each paper\n",
    "    df['n_tokens'] += 4\n",
    "\n",
    "    # Create an expanding window sum of tokens\n",
    "    df['expanding_sum'] = df.n_tokens.expanding().sum()\n",
    "\n",
    "    # Return rows whose expanding sum is less than the max length of the context\n",
    "    return df[df['expanding_sum'] <= max_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this on a few questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks selected: 28\n"
     ]
    }
   ],
   "source": [
    "relevant_paper_chunks = retrieve_relevant_chunks(\n",
    "                    client,\n",
    "                    papers_with_embeddings,\n",
    "                    \"Can you summarize the key findings of 'Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder'?\")\n",
    "\n",
    "print(f'Number of chunks selected: {len(relevant_paper_chunks)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant selected chunks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance</th>\n",
       "      <th>expanding_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28409</th>\n",
       "      <td>2023</td>\n",
       "      <td>Modelling Cellular Perturbations with the Spar...</td>\n",
       "      <td>Finally, the formal link to\\nsparse mechanism ...</td>\n",
       "      <td>2505</td>\n",
       "      <td>[-0.012617362663149834, 0.032124001532793045, ...</td>\n",
       "      <td>0.615885</td>\n",
       "      <td>2505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28408</th>\n",
       "      <td>2023</td>\n",
       "      <td>Modelling Cellular Perturbations with the Spar...</td>\n",
       "      <td>Modelling Cellular Perturbations with the Spar...</td>\n",
       "      <td>7975</td>\n",
       "      <td>[0.004742556717246771, 0.0179368294775486, 0.0...</td>\n",
       "      <td>0.596355</td>\n",
       "      <td>10480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24390</th>\n",
       "      <td>2022</td>\n",
       "      <td>Alleviating Adversarial Attacks on Variational...</td>\n",
       "      <td>Alleviating Adversarial Attacks on Variational...</td>\n",
       "      <td>1651</td>\n",
       "      <td>[0.005380531772971153, 0.011847461573779583, 0...</td>\n",
       "      <td>0.571067</td>\n",
       "      <td>12131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18268</th>\n",
       "      <td>2020</td>\n",
       "      <td>The Autoencoding Variational Autoencoder</td>\n",
       "      <td>AVAE\\nSE5\\nSE20 [5]\\nSE5 AVAE\\nAVAE SS\\nTask /...</td>\n",
       "      <td>3162</td>\n",
       "      <td>[0.01375912968069315, -0.0035207539331167936, ...</td>\n",
       "      <td>0.563902</td>\n",
       "      <td>15293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17582</th>\n",
       "      <td>2020</td>\n",
       "      <td>Evidential Sparsification of Multimodal Latent...</td>\n",
       "      <td>Direct sampling metrics were\\ncomputed over 20...</td>\n",
       "      <td>3231</td>\n",
       "      <td>[0.0006273535545915365, 0.00663420045748353, 0...</td>\n",
       "      <td>0.549324</td>\n",
       "      <td>18524.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year                                               name  \\\n",
       "28409  2023  Modelling Cellular Perturbations with the Spar...   \n",
       "28408  2023  Modelling Cellular Perturbations with the Spar...   \n",
       "24390  2022  Alleviating Adversarial Attacks on Variational...   \n",
       "18268  2020           The Autoencoding Variational Autoencoder   \n",
       "17582  2020  Evidential Sparsification of Multimodal Latent...   \n",
       "\n",
       "                                                    text  n_tokens  \\\n",
       "28409  Finally, the formal link to\\nsparse mechanism ...      2505   \n",
       "28408  Modelling Cellular Perturbations with the Spar...      7975   \n",
       "24390  Alleviating Adversarial Attacks on Variational...      1651   \n",
       "18268  AVAE\\nSE5\\nSE20 [5]\\nSE5 AVAE\\nAVAE SS\\nTask /...      3162   \n",
       "17582  Direct sampling metrics were\\ncomputed over 20...      3231   \n",
       "\n",
       "                                               embedding  distance  \\\n",
       "28409  [-0.012617362663149834, 0.032124001532793045, ...  0.615885   \n",
       "28408  [0.004742556717246771, 0.0179368294775486, 0.0...  0.596355   \n",
       "24390  [0.005380531772971153, 0.011847461573779583, 0...  0.571067   \n",
       "18268  [0.01375912968069315, -0.0035207539331167936, ...  0.563902   \n",
       "17582  [0.0006273535545915365, 0.00663420045748353, 0...  0.549324   \n",
       "\n",
       "       expanding_sum  \n",
       "28409         2505.0  \n",
       "28408        10480.0  \n",
       "24390        12131.0  \n",
       "18268        15293.0  \n",
       "17582        18524.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Most relevant selected chunks:')\n",
    "relevant_paper_chunks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least relevant selected chunks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance</th>\n",
       "      <th>expanding_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17648</th>\n",
       "      <td>2020</td>\n",
       "      <td>Constraining Variational Inference with Geomet...</td>\n",
       "      <td>Although we accept that use of “vanilla” VAEs ...</td>\n",
       "      <td>2741</td>\n",
       "      <td>[-0.007083908189088106, 0.013144437223672867, ...</td>\n",
       "      <td>0.520358</td>\n",
       "      <td>106996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>2007</td>\n",
       "      <td>On Sparsity and Overcompleteness in Image Models</td>\n",
       "      <td>On Sparsity and Overcompleteness in Image Mode...</td>\n",
       "      <td>7350</td>\n",
       "      <td>[-0.015349962748587132, 0.024404319003224373, ...</td>\n",
       "      <td>0.519380</td>\n",
       "      <td>114346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26099</th>\n",
       "      <td>2022</td>\n",
       "      <td>Exploring the Latent Space of Autoencoders wit...</td>\n",
       "      <td>This may be explained by the DCI-D metric\\nNam...</td>\n",
       "      <td>6698</td>\n",
       "      <td>[-0.017867492511868477, 0.018746009096503258, ...</td>\n",
       "      <td>0.519336</td>\n",
       "      <td>121044.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16887</th>\n",
       "      <td>2020</td>\n",
       "      <td>Dirichlet Graph Variational Autoencoder</td>\n",
       "      <td>81–88. [3]\\nSophie Burkhardt and Stefan Kramer...</td>\n",
       "      <td>1990</td>\n",
       "      <td>[-0.020206132903695107, -0.0012961796019226313...</td>\n",
       "      <td>0.519259</td>\n",
       "      <td>123034.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26100</th>\n",
       "      <td>2022</td>\n",
       "      <td>Pythae: Unifying Generative Autoencoders in Py...</td>\n",
       "      <td>Pythae: Unifying Generative Autoencoders in Py...</td>\n",
       "      <td>1648</td>\n",
       "      <td>[0.008975673466920853, -0.0222366601228714, 0....</td>\n",
       "      <td>0.519003</td>\n",
       "      <td>124682.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year                                               name  \\\n",
       "17648  2020  Constraining Variational Inference with Geomet...   \n",
       "3612   2007   On Sparsity and Overcompleteness in Image Models   \n",
       "26099  2022  Exploring the Latent Space of Autoencoders wit...   \n",
       "16887  2020            Dirichlet Graph Variational Autoencoder   \n",
       "26100  2022  Pythae: Unifying Generative Autoencoders in Py...   \n",
       "\n",
       "                                                    text  n_tokens  \\\n",
       "17648  Although we accept that use of “vanilla” VAEs ...      2741   \n",
       "3612   On Sparsity and Overcompleteness in Image Mode...      7350   \n",
       "26099  This may be explained by the DCI-D metric\\nNam...      6698   \n",
       "16887  81–88. [3]\\nSophie Burkhardt and Stefan Kramer...      1990   \n",
       "26100  Pythae: Unifying Generative Autoencoders in Py...      1648   \n",
       "\n",
       "                                               embedding  distance  \\\n",
       "17648  [-0.007083908189088106, 0.013144437223672867, ...  0.520358   \n",
       "3612   [-0.015349962748587132, 0.024404319003224373, ...  0.519380   \n",
       "26099  [-0.017867492511868477, 0.018746009096503258, ...  0.519336   \n",
       "16887  [-0.020206132903695107, -0.0012961796019226313...  0.519259   \n",
       "26100  [0.008975673466920853, -0.0222366601228714, 0....  0.519003   \n",
       "\n",
       "       expanding_sum  \n",
       "17648       106996.0  \n",
       "3612        114346.0  \n",
       "26099       121044.0  \n",
       "16887       123034.0  \n",
       "26100       124682.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Least relevant selected chunks:')\n",
    "relevant_paper_chunks.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 2 chunks came from the paper referenced in the user's question, which is great! The rest of the chunks seem to be generally related (about Autoencoders or sparse data), which will be important if the user asks a question that might require many papers to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do another test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks selected: 28\n"
     ]
    }
   ],
   "source": [
    "relevant_paper_chunks = retrieve_relevant_chunks(\n",
    "                    client,\n",
    "                    papers_with_embeddings,\n",
    "                    \"How do the performance of different types of variational auto-encoders (VAEs) compare?\")\n",
    "\n",
    "print(f'Number of chunks selected: {len(relevant_paper_chunks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant selected chunks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance</th>\n",
       "      <th>expanding_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24390</th>\n",
       "      <td>2022</td>\n",
       "      <td>Alleviating Adversarial Attacks on Variational...</td>\n",
       "      <td>Alleviating Adversarial Attacks on Variational...</td>\n",
       "      <td>1655</td>\n",
       "      <td>[0.005380531772971153, 0.011847461573779583, 0...</td>\n",
       "      <td>0.606672</td>\n",
       "      <td>1655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26100</th>\n",
       "      <td>2022</td>\n",
       "      <td>Pythae: Unifying Generative Autoencoders in Py...</td>\n",
       "      <td>Pythae: Unifying Generative Autoencoders in Py...</td>\n",
       "      <td>1652</td>\n",
       "      <td>[0.008975673466920853, -0.0222366601228714, 0....</td>\n",
       "      <td>0.593998</td>\n",
       "      <td>3307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29780</th>\n",
       "      <td>2023</td>\n",
       "      <td>AdaVAE: Bayesian Structural Adaptation for Var...</td>\n",
       "      <td>AdaVAE: Bayesian Structural Adaptation for\\nVa...</td>\n",
       "      <td>7857</td>\n",
       "      <td>[0.02144601009786129, 0.015637459233403206, 0....</td>\n",
       "      <td>0.572955</td>\n",
       "      <td>11164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25839</th>\n",
       "      <td>2022</td>\n",
       "      <td>A Geometric Perspective on Variational Autoenc...</td>\n",
       "      <td>MODEL\\nMNIST (16)\\nSVHN (16)\\nCIFAR 10 (32)\\nC...</td>\n",
       "      <td>4747</td>\n",
       "      <td>[-0.02092185989022255, 0.017854847013950348, 0...</td>\n",
       "      <td>0.572759</td>\n",
       "      <td>15911.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32154</th>\n",
       "      <td>2023</td>\n",
       "      <td>Isometric Quotient Variational Auto-Encoders f...</td>\n",
       "      <td>Isometric Quotient Variational Auto-Encoders f...</td>\n",
       "      <td>2800</td>\n",
       "      <td>[0.004320634063333273, 0.0066658128052949905, ...</td>\n",
       "      <td>0.568576</td>\n",
       "      <td>18711.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year                                               name  \\\n",
       "24390  2022  Alleviating Adversarial Attacks on Variational...   \n",
       "26100  2022  Pythae: Unifying Generative Autoencoders in Py...   \n",
       "29780  2023  AdaVAE: Bayesian Structural Adaptation for Var...   \n",
       "25839  2022  A Geometric Perspective on Variational Autoenc...   \n",
       "32154  2023  Isometric Quotient Variational Auto-Encoders f...   \n",
       "\n",
       "                                                    text  n_tokens  \\\n",
       "24390  Alleviating Adversarial Attacks on Variational...      1655   \n",
       "26100  Pythae: Unifying Generative Autoencoders in Py...      1652   \n",
       "29780  AdaVAE: Bayesian Structural Adaptation for\\nVa...      7857   \n",
       "25839  MODEL\\nMNIST (16)\\nSVHN (16)\\nCIFAR 10 (32)\\nC...      4747   \n",
       "32154  Isometric Quotient Variational Auto-Encoders f...      2800   \n",
       "\n",
       "                                               embedding  distance  \\\n",
       "24390  [0.005380531772971153, 0.011847461573779583, 0...  0.606672   \n",
       "26100  [0.008975673466920853, -0.0222366601228714, 0....  0.593998   \n",
       "29780  [0.02144601009786129, 0.015637459233403206, 0....  0.572955   \n",
       "25839  [-0.02092185989022255, 0.017854847013950348, 0...  0.572759   \n",
       "32154  [0.004320634063333273, 0.0066658128052949905, ...  0.568576   \n",
       "\n",
       "       expanding_sum  \n",
       "24390         1655.0  \n",
       "26100         3307.0  \n",
       "29780        11164.0  \n",
       "25839        15911.0  \n",
       "32154        18711.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Most relevant selected chunks:')\n",
    "relevant_paper_chunks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least relevant selected chunks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embedding</th>\n",
       "      <th>distance</th>\n",
       "      <th>expanding_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31251</th>\n",
       "      <td>2023</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>Complexity Matters: Rethinking the Latent Spac...</td>\n",
       "      <td>7946</td>\n",
       "      <td>[0.006931154523044825, -0.00225873407907784, 0...</td>\n",
       "      <td>0.531068</td>\n",
       "      <td>94520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10240</th>\n",
       "      <td>2017</td>\n",
       "      <td>VAE Learning via Stein Variational Gradient De...</td>\n",
       "      <td>VAE Learning via Stein Variational Gradient De...</td>\n",
       "      <td>7931</td>\n",
       "      <td>[-0.0016620290698483586, 0.014140750281512737,...</td>\n",
       "      <td>0.526778</td>\n",
       "      <td>102451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>2019</td>\n",
       "      <td>Copulas as High-Dimensional Generative Models:...</td>\n",
       "      <td>Copulas as High-Dimensional Generative Models:...</td>\n",
       "      <td>7894</td>\n",
       "      <td>[0.02679332345724106, -0.0021856760140508413, ...</td>\n",
       "      <td>0.525333</td>\n",
       "      <td>110345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15808</th>\n",
       "      <td>2019</td>\n",
       "      <td>D-VAE: A Variational Autoencoder for Directed ...</td>\n",
       "      <td>D-VAE: A Variational Autoencoder for Directed\\...</td>\n",
       "      <td>7939</td>\n",
       "      <td>[0.002114873146638274, -0.0012863284209743142,...</td>\n",
       "      <td>0.522984</td>\n",
       "      <td>118284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10289</th>\n",
       "      <td>2017</td>\n",
       "      <td>Adversarial Symmetric Variational Autoencoder</td>\n",
       "      <td>Adversarial Symmetric Variational Autoencoder\\...</td>\n",
       "      <td>7928</td>\n",
       "      <td>[0.03652070835232735, 0.007922451011836529, 0....</td>\n",
       "      <td>0.522859</td>\n",
       "      <td>126212.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year                                               name  \\\n",
       "31251  2023  Complexity Matters: Rethinking the Latent Spac...   \n",
       "10240  2017  VAE Learning via Stein Variational Gradient De...   \n",
       "13510  2019  Copulas as High-Dimensional Generative Models:...   \n",
       "15808  2019  D-VAE: A Variational Autoencoder for Directed ...   \n",
       "10289  2017      Adversarial Symmetric Variational Autoencoder   \n",
       "\n",
       "                                                    text  n_tokens  \\\n",
       "31251  Complexity Matters: Rethinking the Latent Spac...      7946   \n",
       "10240  VAE Learning via Stein Variational Gradient De...      7931   \n",
       "13510  Copulas as High-Dimensional Generative Models:...      7894   \n",
       "15808  D-VAE: A Variational Autoencoder for Directed\\...      7939   \n",
       "10289  Adversarial Symmetric Variational Autoencoder\\...      7928   \n",
       "\n",
       "                                               embedding  distance  \\\n",
       "31251  [0.006931154523044825, -0.00225873407907784, 0...  0.531068   \n",
       "10240  [-0.0016620290698483586, 0.014140750281512737,...  0.526778   \n",
       "13510  [0.02679332345724106, -0.0021856760140508413, ...  0.525333   \n",
       "15808  [0.002114873146638274, -0.0012863284209743142,...  0.522984   \n",
       "10289  [0.03652070835232735, 0.007922451011836529, 0....  0.522859   \n",
       "\n",
       "       expanding_sum  \n",
       "31251        94520.0  \n",
       "10240       102451.0  \n",
       "13510       110345.0  \n",
       "15808       118284.0  \n",
       "10289       126212.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Least relevant selected chunks:')\n",
    "relevant_paper_chunks.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question was about a certain class of models (variational auto-encoders (VAEs)) - so selecting 28 chunks all discussing different types of this model seems appropriate for generating an answer comparing the different types of this model.\n",
    "\n",
    "Next, let's look at generating a response based on the selected chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Retrieval-Augemented Response\n",
    "\n",
    "Now, we'll include the retreived paper chunks as context to the user's question, and send the user's question and the context to OpenAI's generative model - specifying that the model should only use the provided context in generating the response.\n",
    "\n",
    "This function has been adapted from [OpenAI's tutorial](https://platform.openai.com/docs/tutorials/web-qa-embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(client, df, question, max_len=127000):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = '\\n\\n###\\n\\n'.join(retrieve_relevant_chunks(client, df, question, max_len=max_len)['text'].tolist())\n",
    "\n",
    "    try:\n",
    "        # Create a chat completion using the question and context\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\n\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\"}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out with the same questions we used in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper \"Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder\" proposes the Sparse Additive Mechanism Shift Variational Autoencoder (SAMS-VAE) to analyze cellular perturbation data. The key findings of the study include:\n",
      "\n",
      "1. **Model Development**: The SAMS-VAE combines principles from generative modeling and sparse mechanisms to disentangle the effects of basal and perturbation states in cellular data, facilitating a better understanding of biological mechanisms.\n",
      "\n",
      "2. **Improved Predictive Performance**: SAMS-VAE outperforms traditional models by including a sparsity mechanism that enhances predictive accuracy and allows for more robust inference of latent variables related to gene expression and cellular responses.\n",
      "\n",
      "3. **Factorization of Variation**: The proposed model enables the effective factorization of variation in biological data, isolating the specific contributions of different perturbations on the observed cellular responses.\n",
      "\n",
      "4. **Causal Inference Framework**: The SAMS-VAE effectively serves as a causal inference framework, enhancing the interpretation of perturbational screening data and contributing to a more profound understanding of genetic mechanisms and drug discovery.\n",
      "\n",
      "5. **Future Directions**: The work identifies exciting avenues for future research, particularly focusing on integrating prior information on perturbations and investigating the interactions between perturbations in more complex biological contexts.\n",
      "\n",
      "Overall, the research asserts that SAMS-VAE is a significant advancement in modeling cellular perturbations, providing insights that are both technically sound and practically applicable in biological research.\n"
     ]
    }
   ],
   "source": [
    "print(answer_question(client,\n",
    "                      papers_with_embeddings,\n",
    "                      \"Can you summarize the key findings of 'Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder'?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good!\n",
    "\n",
    "Let's try another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of different types of variational auto-encoders (VAEs) can vary significantly based on their architectures, training methodologies, and the specific datasets they are applied to. Several studies and experiments have highlighted the distinctions in performance among various VAE models. Here are some key observations:\n",
      "\n",
      "1. **Standard VAE**: Typically serves as a baseline, but often generates blurry images and exhibits limitations in terms of reconstruction quality and sample diversity.\n",
      "\n",
      "2. **β-VAE**: Incorporates a hyperparameter (β) that can adjust the balance between reconstruction and the KL divergence term, leading to better disentangled representations but may still suffer from blurry reconstructions.\n",
      "\n",
      "3. **Variations like LVAE, SkipVAE, and NVAE**: These models enhance the architecture of the VAE to improve generative performance. For instance, NVAE introduces more complex networks with skip connections, which generally result in sharper images and better adherence to the data structure.\n",
      "\n",
      "4. **Adversarial Variational Autoencoders (AVAEs)**: By integrating adversarial training, AVAEs can provide better sample quality and can mitigate some issues like posterior collapse found in standard VAEs.\n",
      "\n",
      "5. **Semi-Supervised Variants**: These types utilize weakly labeled data alongside unlabeled data, leading to improved performance for specific tasks, such as trajectory prediction or classification, by leveraging both labeled and unlabeled information.\n",
      "\n",
      "6. **Post-Variational Processing**: Methods like incorporating mixture models or using advanced decoding strategies significantly improve the generative capabilities of VAEs.\n",
      "\n",
      "7. **Performance Metrics**: Performance is often measured using metrics like Negative Log-Likelihood (NLL), Inception Score (IS), and Fréchet Inception Distance (FID) to compare sample quality across VAE variants. For instance, studies show improved FID scores and IS with modified VAEs like VAEGAN and those utilizing auxiliary decoders or better latent space distributions.\n",
      "\n",
      "Overall, modified or advanced VAEs tend to outperform the standard model in terms of both reconstruction accuracy and the quality of generated samples, with more specialized instances showing competitive performance against GANs and other state-of-the-art generative models.\n"
     ]
    }
   ],
   "source": [
    "print(answer_question(client,\n",
    "                      papers_with_embeddings,\n",
    "                      \"How do the performance of different types of variational auto-encoders (VAEs) compare?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sounds pretty good, but that answer did not mention the SAMS-VAE model we had explored in the earlier question. Let's ask about that model specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of the Sparse Additive Mechanism Shift Variational Autoencoder (SAMS-VAE) is demonstrated to outperform comparable models in terms of generalization across both in-distribution and out-of-distribution tasks. This includes improved predictive capabilities and the ability to recover factors that correlate strongly with known biological mechanisms when applied to single-cell RNA-sequencing datasets. SAMS-VAE combines sparse perturbation-specific latent effects, perturbation-independent natural variations of cells, and additive composition of perturbation effects into a joint model, leading to insights that potentially surpass those provided by other types of VAEs. Specific comparisons to other VAE variants, such as CPA-VAE and SVAE+, emphasize SAMS-VAE's superior performance in various quantitative and qualitative evaluations, indicating its efficacy in modeling cellular perturbations.\n"
     ]
    }
   ],
   "source": [
    "print(answer_question(client,\n",
    "                      papers_with_embeddings,\n",
    "                      \"How does the performance of the Sparse Additive Mechanism Shift Variational Autoencoder (SAMS-VAE) compare to other types of variational auto-encoders (VAEs)?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what happens if we ask a question outside the scope of the NeurIPS conference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know\n"
     ]
    }
   ],
   "source": [
    "print(answer_question(client,\n",
    "                      papers_with_embeddings,\n",
    "                      \"What battles took place in New York City in the American Revolution?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's pretty good! It doesn't answer a question completely unrelated to the the content of the NeurIPS conference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a super broad question, but one that's still relevant to the NeurIPS conference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know\n"
     ]
    }
   ],
   "source": [
    "print(answer_question(client,\n",
    "                      papers_with_embeddings,\n",
    "                      \"What are the major research trends in NeurIPS this year?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that we only have papers up to 2023, and it's currently 2024 - this is probably a good answer. But let's see what happens if we ask about a specific year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "print(answer_question(client,\n",
    "                      papers_with_embeddings,\n",
    "                      \"What are the major research trends in NeurIPS in 2023?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like it could be an opportunity for improvement, since we do have all the papers from 2023 available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opportunities for Improvement\n",
    "\n",
    "Here are the areas where we could potentially improve the RAG model:\n",
    "- **Developing a standard list of questions and responses to evaluate the model** - this notebook just tests a few quick and dirty questions to get a general sense of whether the model is working. If we develop a more robust list of questions and potential answers, we can get a better idea of whether the model is truly using the context as desired - as opposed to generating a response based on the LLM's general knowledge and/or hallucinating. This would also allow us to determine whether any sort of tuning we do (to chunking, prompts, etc.) provides noticeable improvement to the responses of the model.\n",
    "- **Better PDF conversion** - the raw plaintext from the PDF conversion currently do not contain structured versions of the papers' tables, equations, graphs, and images. If we convert more of this information in a structured way, the source data for the RAG may contain even more useful context to draw from.\n",
    "- **More intelligent chunking** - Currently the chunks contain no overlaps and are naively cut off at 8000 tokens. Because we will include up to 127,000 tokens in our context for the response, more than likely a full paper will be included in the context - even if it was broken into chunks. However there are no guarantees the chunks of the paper will be in a logical order, nor that all the chunks of a paper will actually be included. One strategy could be to include overlap in the chunks to make sure that there is not too much context lost between chunks. Another potential strategy could be to use a generative LLM to summarize the papers down to 8000 characters rather than chunking (thus ensuring that a full paper is included in each embedding). However, information could be lost during that summarization, and it would take more compute resources to generate (using the `gpt-4o-mini` for every single paper) which might not be worth it.\n",
    "- **Ranking papers during the retrieval step** - we might want to rank more recent papers as more important to the context as those papers have the most up-to-date information.\n",
    "- **Prompt engineering** - We could experiment different ways of structuring our prompt to ensure the _only_ the context provided will be used in the response. Additionally, perhaps we might want to experiment with extracting key pieces of information from the prompt, such as phrases like \"this year\", to filter which papers are selected as candidates for the context. If we include more structured information in the DataFrame, such as subfield (e.g, reinforcement learning, NLP, computer vision), authors, citations, etc., we also might be able to use that information in conjuction with the users' question to make sure we have"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academic-paper-explorer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
